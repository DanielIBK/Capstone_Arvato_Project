{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import  SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import learning_curve,  ShuffleSplit, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "# azdias = pd.read_csv(r'./data/Udacity_AZDIAS_052018.csv', sep=';', low_memory=False)\n",
    "# customers = pd.read_csv(r'./data/Udacity_CUSTOMERS_052018.csv', sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891221, 366)\n",
      "(191652, 369)\n"
     ]
    }
   ],
   "source": [
    "# Pickle the data downloaded from the Udacity workspace\n",
    "# azdias.to_pickle('./data/azdias.pickle')\n",
    "# customers.to_pickle('./data/customers.pickle')\n",
    "\n",
    "# Load as pickle\n",
    "azdias = pd.read_pickle('./data/azdias.pickle')\n",
    "print(azdias.shape)\n",
    "customers =pd.read_pickle('./data/customers.pickle')\n",
    "print(customers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LNR                       int64\n",
       "AGER_TYP                  int64\n",
       "AKT_DAT_KL              float64\n",
       "ALTER_HH                float64\n",
       "ALTER_KIND1             float64\n",
       "                         ...   \n",
       "WOHNDAUER_2008          float64\n",
       "WOHNLAGE                float64\n",
       "ZABEOTYP                  int64\n",
       "ANREDE_KZ                 int64\n",
       "ALTERSKATEGORIE_GROB      int64\n",
       "Length: 366, dtype: object"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Be sure to add in a lot more cells (both markdown and code) to document your\n",
    "# approach and findings!\n",
    "azdias.head(10)\n",
    "azdias.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias['EINGEFUEGT_AM'].head(5)\n",
    "pd.to_datetime(azdias['EINGEFUEGT_AM'][2], format='%Y-%m-%d ').year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LNR                          0\n",
       "AGER_TYP                     0\n",
       "AKT_DAT_KL               73499\n",
       "ALTER_HH                 73499\n",
       "ALTER_KIND1             810163\n",
       "                         ...  \n",
       "WOHNDAUER_2008           73499\n",
       "WOHNLAGE                 93148\n",
       "ZABEOTYP                     0\n",
       "ANREDE_KZ                    0\n",
       "ALTERSKATEGORIE_GROB         0\n",
       "Length: 366, dtype: int64"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias.isna().sum(axis=1)\n",
    "azdias.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP'}"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Differences in columns\n",
    "set(customers.columns) - set(azdias.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMEO_DEU_2015</th>\n",
       "      <th>CAMEO_DEUG_2015</th>\n",
       "      <th>CAMEO_INTL_2015</th>\n",
       "      <th>D19_LETZTER_KAUF_BRANCHE</th>\n",
       "      <th>EINGEFUEGT_AM</th>\n",
       "      <th>OST_WEST_KZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8A</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>D19_UNBEKANNT</td>\n",
       "      <td>1992-02-12 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>D19_UNBEKANNT</td>\n",
       "      <td>1997-04-21 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6B</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>D19_SCHUHE</td>\n",
       "      <td>1992-02-12 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891216</th>\n",
       "      <td>7A</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>D19_HAUS_DEKO</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891217</th>\n",
       "      <td>9D</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>D19_UNBEKANNT</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891218</th>\n",
       "      <td>4C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>D19_BEKLEIDUNG_GEH</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891219</th>\n",
       "      <td>9D</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>D19_UNBEKANNT</td>\n",
       "      <td>1992-02-12 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891220</th>\n",
       "      <td>6B</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891221 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CAMEO_DEU_2015 CAMEO_DEUG_2015 CAMEO_INTL_2015  \\\n",
       "0                 NaN             NaN             NaN   \n",
       "1                  8A             8.0            51.0   \n",
       "2                  4C             4.0            24.0   \n",
       "3                  2A             2.0            12.0   \n",
       "4                  6B             6.0            43.0   \n",
       "...               ...             ...             ...   \n",
       "891216             7A             7.0            41.0   \n",
       "891217             9D             9.0            51.0   \n",
       "891218             4C             4.0            24.0   \n",
       "891219             9D             9.0            51.0   \n",
       "891220             6B             6.0            43.0   \n",
       "\n",
       "       D19_LETZTER_KAUF_BRANCHE        EINGEFUEGT_AM OST_WEST_KZ  \n",
       "0                           NaN                  NaN         NaN  \n",
       "1                           NaN  1992-02-10 00:00:00           W  \n",
       "2                 D19_UNBEKANNT  1992-02-12 00:00:00           W  \n",
       "3                 D19_UNBEKANNT  1997-04-21 00:00:00           W  \n",
       "4                    D19_SCHUHE  1992-02-12 00:00:00           W  \n",
       "...                         ...                  ...         ...  \n",
       "891216            D19_HAUS_DEKO  1992-02-10 00:00:00           W  \n",
       "891217            D19_UNBEKANNT  1992-02-10 00:00:00           W  \n",
       "891218       D19_BEKLEIDUNG_GEH  1992-02-10 00:00:00           W  \n",
       "891219            D19_UNBEKANNT  1992-02-12 00:00:00           W  \n",
       "891220                      NaN  1992-02-10 00:00:00           W  \n",
       "\n",
       "[891221 rows x 6 columns]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show object dtypes\n",
    "azdias.select_dtypes(['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMEO_DEU_2015\n",
      "CAMEO_DEUG_2015\n",
      "CAMEO_INTL_2015\n",
      "D19_LETZTER_KAUF_BRANCHE\n",
      "EINGEFUEGT_AM\n",
      "OST_WEST_KZ\n"
     ]
    }
   ],
   "source": [
    "for c in azdias.select_dtypes(['object']).columns:\n",
    "    print(c)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Data Wrangling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_col(df, cols_drop):\n",
    "    \"\"\"Returns a cleaned dataframe object. And also a summary of the retured df is printed.\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): The input dataframe that should be cleaned.\n",
    "        cols_drop (list): A list of columns that should be dropped_description_\n",
    "        test (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        df: A dataframe cleaned by the input cols_drop\n",
    "    \"\"\"\n",
    "    df_clean = df.drop(cols_drop, axis=1, inplace=True)\n",
    "    #df_clean.isna\n",
    "\n",
    "    # Print summary\n",
    "    # print('From an input shape of: {} the returned shape is: {}'.format(df.shape, df_clean.shape))\n",
    "    # print('The initial datatype were: {}'.format(df.dtypes))\n",
    "    # print('The output datatype are: {}'.format(df_clean.dtypes))\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_learning_curves(X, y, estimator, num_trainings):\n",
    "    \"\"\"\n",
    "    Draw learning curve that shows the validation and training auc_score of an estimator \n",
    "    for varying numbers of training samples.\n",
    "    \n",
    "    Input:\n",
    "        X: array like sample\n",
    "        y: array like target relative to X2 sample\n",
    "        estimator: object type that implements the “fit” and “predict” methods\n",
    "        num_trainings (int): number of training samples to plot\n",
    "        \n",
    "    Output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, scoring = 'roc_auc', \n",
    "        train_sizes=np.linspace(.1, 1.0, num_trainings),\n",
    "        cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=random_state),\n",
    "        )\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    print(\"AUC train score = {}\".format(train_scores_mean[-1].round(2)))\n",
    "    print(\"AUC validation score = {}\".format(test_scores_mean[-1].round(2)))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.xlabel(\"% of training set\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    plt.plot(np.linspace(.1, 1.0, num_trainings)*100, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(np.linspace(.1, 1.0, num_trainings)*100, test_scores_mean, 'o-', color=\"b\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.yticks(np.arange(0.45, 1.02, 0.05))\n",
    "    plt.xticks(np.arange(0., 100.05, 10))\n",
    "    plt.legend(loc=\"best\")\n",
    "    print(\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values for a given threshold\n",
    "\n",
    "def drop_col_based_thres(df, threshold = 0.25):\n",
    "    \"\"\"A function that drops all columns based on missing values by a given threshold in percent.\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): A input dataframe that should be cleaned for missing values by rows\n",
    "        threshold (lilst): The threshold in decimal number percent 40% -> 0.4\n",
    "\n",
    "    Returns:\n",
    "        df_clean (dataframe): A cleaned version of the input dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the share of null values for each column                     \n",
    "    null_shares = df.isnull().sum()/len(df)\n",
    "    # Get the columns with a null share over the threshold\n",
    "    drop_cols = list(null_shares[null_shares>threshold].index)\n",
    "    # Clean the df by the identified columns\n",
    "    df_clean = df.drop(drop_cols, axis=1)\n",
    "    print('Shape before cleaning {}/nShape after cleaning {}'.format(df.shape, df_clean.shape))            \n",
    "    return df_clean\n",
    "\n",
    "def replace_nans(df, col_names: list , col_values:list , replace_value:list ):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): Input dataframe\n",
    "        col_names (list): A list of columns which should be proceeded for the replacement\n",
    "        col_values (list): Search values that should be replaced by replace_value in the same order \n",
    "        replace_value (list): A list in the same order als col_values which these should be replaced with\n",
    "\n",
    "    Returns:\n",
    "        df_replaced (dataframe): The output dataframe after replacing the values in the columns by the replacement values\n",
    "    \"\"\"\n",
    "    df_replaced = df\n",
    "    df_new_cols = df[col_names].replace(col_values,-1).fillna(-1).astype(int)\n",
    "    df_replaced[col_names] = df_new_cols\n",
    "    #### Handle the remaining categorical variables\n",
    "    df_replaced['OST_WEST_KZ'].replace('O', 0, inplace=True)\n",
    "    df_replaced['OST_WEST_KZ'].replace('W', 1, inplace=True)\n",
    "    df_replaced['OST_WEST_KZ'] = pd.to_numeric(df_replaced['OST_WEST_KZ'], errors = 'coerce')\n",
    "    \n",
    "    \n",
    "    return df_replaced\n",
    "\n",
    "\n",
    "def timeseries_to_year(df):\n",
    "    \"\"\"Converts a columns in a df to datetime type and keeps only the year.\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): Input dataframe\n",
    "        #col_names (list): A list of columns which should be proceeded for converting. Timeseries format is '%Y-%m-%d '\n",
    "\n",
    "    Returns:\n",
    "        df_clean (dataframe): A dataframe where the column is converted as a time series with only the year\n",
    "    \"\"\"\n",
    "    df_cleaned = df\n",
    "    df_cleaned['EINGEFUEGT_AM'] = pd.to_datetime(df['EINGEFUEGT_AM'], format='%Y-%m-%d ').dt.year\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['CAMEO_DEUG_2015','CAMEO_INTL_2015'] #Replace and fill na\n",
    "col_names_2 = ['CAMEO_DEU_2015','OST_WEST_KZ'] #Fill na\n",
    "col_values  = ['X', 'XX']\n",
    "col_replace_values = [-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Azdias dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before cleaning (891221, 366)/nShape after cleaning (891221, 350)\n",
      "   CAMEO_DEUG_2015  CAMEO_INTL_2015\n",
      "0               -1               -1\n",
      "1                8               51\n",
      "2                4               24\n",
      "3                2               12\n",
      "4                6               43\n",
      "5                8               54\n",
      "6                4               22\n",
      "7                2               14\n",
      "8                1               13\n",
      "9                1               15\n"
     ]
    }
   ],
   "source": [
    "# Clean azdias\n",
    "# Drop columns with not enough data\n",
    "azdias_cleaned = drop_col_based_thres(azdias)\n",
    "\n",
    "# Replace nan in cleaned dataframe\n",
    "# Replace nan in cleaned dataframe\n",
    "azdias_cleaned = replace_nans(azdias_cleaned, col_names, col_values, col_replace_values)\n",
    "print(azdias_cleaned[col_names].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_cleaned = timeseries_to_year(azdias_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_cleaned['OST_WEST_KZ'].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Customers dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CAMEO_DEUG_2015  CAMEO_INTL_2015\n",
      "0                1               13\n",
      "1               -1               -1\n",
      "2                5               34\n",
      "3                4               24\n",
      "4                7               41\n",
      "5                5               34\n",
      "6                3               23\n",
      "7                1               15\n",
      "8                9               55\n",
      "9                1               15\n"
     ]
    }
   ],
   "source": [
    "# Clean customers\n",
    "# Drop the same values as in azdias for later analysis.\n",
    "\n",
    "drop_cust_cols  = set(customers.columns) - set(azdias_cleaned.columns)\n",
    "customers_cleaned = customers.drop( drop_cust_cols, axis=1)\n",
    "# The columns are dropped in customer dataset due to to many missing values\n",
    "#customers_cleaned = drop_col_based_thres(customers)\n",
    "\n",
    "\n",
    "# Replace nan in cleaned dataframe\n",
    "customers_cleaned = replace_nans(customers_cleaned, col_names, col_values, col_replace_values)\n",
    "print(customers_cleaned[col_names].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191652, 350)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_cleaned = timeseries_to_year(customers_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customers_cleaned = drop_col(customers_cleaned,['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several Preprocessing steps need to be done\n",
    "\n",
    "We genereate a pipeline for each preprocessing. The approach here used is to split the Pipeline by the column data types.\n",
    "Some data adjustements as well replacements of missing values are needed.\n",
    "\n",
    "#### Continous Variables:\n",
    "   + Impute with median since it is more robust to outliers\n",
    "   + StandardScaler\n",
    "\n",
    "#### Binary:\n",
    "   + Clean\n",
    "   \n",
    "#### Categorical: \n",
    "   + Impute with most frequent since others methods are only for numeric\n",
    "   + One-Hot Encode the variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of the datatype columns\n",
    "numerical_cols = list(azdias_cleaned.select_dtypes(['float64','int64']))\n",
    "categorical_cols = list(azdias_cleaned.select_dtypes(['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Pipeline \n",
    "num_pipe = Pipeline([\n",
    "    ('num_impute', SimpleImputer(strategy='median')),\n",
    "    ('num_scalar', StandardScaler())\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Pipeline \n",
    "cat_pipe = Pipeline([\n",
    "    ('bin_impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one_hot_encoding', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Pipeline\n",
    "pre_pipe = [\n",
    "    #('bin', binary_pipeline, binary_cols),\n",
    "    ('cat', cat_pipe, categorical_cols),\n",
    "    ('num', num_pipe, numerical_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pipe_columntransformer = ColumnTransformer(transformers = pre_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMEO_DEU_2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891216</th>\n",
       "      <td>7A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891217</th>\n",
       "      <td>9D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891218</th>\n",
       "      <td>4C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891219</th>\n",
       "      <td>9D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891220</th>\n",
       "      <td>6B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891221 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CAMEO_DEU_2015\n",
       "0                 NaN\n",
       "1                  8A\n",
       "2                  4C\n",
       "3                  2A\n",
       "4                  6B\n",
       "...               ...\n",
       "891216             7A\n",
       "891217             9D\n",
       "891218             4C\n",
       "891219             9D\n",
       "891220             6B\n",
       "\n",
       "[891221 rows x 1 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_cleaned[categorical_cols]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pipelines to transform datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_transformed = pre_pipe_columntransformer.fit_transform(azdias_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "azdias_transformed = pre_pipe_columntransformer.fit_transform(azdias_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names after the One Hot Encoding\n",
    "dummy_cols = list(pre_pipe_columntransformer.transformers_[0][1]\\\n",
    "   .named_steps['one_hot_encoding'].get_feature_names(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols =  dummy_cols +  numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transformation into a new dataframe\n",
    "azdias_transformed_df = pd.DataFrame(azdias_transformed, columns= all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    392\n",
       "dtype: int64"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if datatypes are all numeric for further processing\n",
    "azdias_transformed_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "As learned in Udacity course with a high dimension data input there a high chanced that the same information is provided\n",
    "in diffrent columns. To reduce complexity for later modelling a PCA is done at first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#  Fit PCA such that 95% of the variance is retained.\n",
    "pca = PCA(.95)\n",
    "azdias_reduced = pca.fit_transform(azdias_transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 790 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Show how many data columns are required to retain the given variance\n",
    "print(pca.n_components_)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Components Count')\n",
    "plt.ylabel('Explained Variannce (in %)')\n",
    "plt.title('PCA Dimension reduction (Variance goal 95%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_reduced_df = pd.DataFrame(azdias_reduced)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with k-means \n",
    "To cluster unlabeled data this approach is very usefull. To determine the final number of clusters the elbow-method will be used (https://predictivehacks.com/k-means-elbow-method-code-for-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "list_k = list(range(1,15))\n",
    "\n",
    "for k in list_k:\n",
    "    clustering = KMeans(n_clusters = k, init='k-means++')\n",
    "    clustering.fit(azdias_transformed_df.sample(10000))\n",
    "    distortions.append(clustering.inertia_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Elbow for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(list_k, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Transform colums, Reduce PCA, Cluster kMeans Pipleine\n",
    "T_R_C_pipeline = Pipeline([\n",
    "    ('transform', pre_pipe_columntransformer),\n",
    "    ('reduce', pca),\n",
    "    ('cluster', KMeans(n_clusters = 6, init='k-means++'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_259872/918029371.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the pipeline on the azdias df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mT_R_C_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mazdias_cleaned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[1;31m# Setup the memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \"\"\"Access the steps by name.\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mRead\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0monly\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0mto\u001b[0m \u001b[0maccess\u001b[0m \u001b[0many\u001b[0m \u001b[0mstep\u001b[0m \u001b[0mby\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         Keys are steps names and values are the steps objects.\"\"\"\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# Use Bunch object to improve autocomplete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m                 raise AttributeError(\n\u001b[0;32m    753\u001b[0m                     \u001b[1;34m\"Estimator {} does not provide get_feature_names_out. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m                     \u001b[1;34m\"Did you mean to call pipeline[:-1].get_feature_names_out\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m                     \u001b[1;34m\"()?\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0minput_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_feature_names_in\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[1;31m# List of tuples (name, feature_names_out)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[0mtransformer_with_feature_names_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitted\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mValidates\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mremainder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdefines\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_remainder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtargeting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \"\"\"\n\u001b[0m\u001b[0;32m    435\u001b[0m         is_transformer = (\n\u001b[0;32m    436\u001b[0m             \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremainder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremainder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m         \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'all'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;31m# queue, _ready_batches, that is looked-up prior to re-consuming\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;31m# tasks from the origal iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                 warnings.warn(\n\u001b[1;32m--> 779\u001b[1;33m                     \u001b[1;34m'The backend class {!r} does not support timeout. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                     \u001b[1;34m\"You have set 'timeout={}' in Parallel but \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                     \"the 'timeout' parameter will not be used.\".format(\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[1;31m# Don't terminate the workers as we want to reuse them in later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[1;31m# calls, but cleanup the temporary resources that the Parallel call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;31m# of causing semantic changes and some additional pool instantiation overhead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[0mDEFAULT_MP_CONTEXT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_context'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'JOBLIB_START_METHOD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;31m# of causing semantic changes and some additional pool instantiation overhead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[0mDEFAULT_MP_CONTEXT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_context'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'JOBLIB_START_METHOD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m                 raise AttributeError(\n\u001b[0;32m    753\u001b[0m                     \u001b[1;34m\"Estimator {} does not provide get_feature_names_out. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m                     \u001b[1;34m\"Did you mean to call pipeline[:-1].get_feature_names_out\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m                     \u001b[1;34m\"()?\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \"\"\"Fit the model.\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[0mFit\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0mone\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mother\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mFinally\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mdata\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \"\"\"Access the steps by name.\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mRead\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0monly\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0mto\u001b[0m \u001b[0maccess\u001b[0m \u001b[0many\u001b[0m \u001b[0mstep\u001b[0m \u001b[0mby\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         Keys are steps names and values are the steps objects.\"\"\"\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# Use Bunch object to improve autocomplete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m                 raise AttributeError(\n\u001b[0;32m    753\u001b[0m                     \u001b[1;34m\"Estimator {} does not provide get_feature_names_out. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m                     \u001b[1;34m\"Did you mean to call pipeline[:-1].get_feature_names_out\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m                     \u001b[1;34m\"()?\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mClusterMixin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m     \u001b[1;34m\"\"\"Mixin class for all cluster estimators in scikit-learn.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_na\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_scalar_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, strategy, missing_values, fill_value)\u001b[0m\n\u001b[0;32m    385\u001b[0m                 \u001b[1;34m\"in the future version.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                 \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             )\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\numpy\\ma\\extras.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0m\u001b[0;32m    710\u001b[0m                     overwrite_input=overwrite_input)\n\u001b[0;32m    711\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3515\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3516\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\numpy\\ma\\extras.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0masorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m         \u001b[0masorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36msort\u001b[1;34m(a, axis, kind, order, endwith, fill_value)\u001b[0m\n\u001b[0;32m   6899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6900\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6901\u001b[1;33m         a.sort(axis=axis, kind=kind, order=order,\n\u001b[0m\u001b[0;32m   6902\u001b[0m                endwith=endwith, fill_value=fill_value)\n\u001b[0;32m   6903\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36msort\u001b[1;34m(self, axis, kind, order, endwith, fill_value)\u001b[0m\n\u001b[0;32m   5653\u001b[0m                             fill_value=fill_value, endwith=endwith)\n\u001b[0;32m   5654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5655\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msidx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5657\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, indx, value)\u001b[0m\n\u001b[0;32m   3379\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hardmask\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3380\u001b[0m             \u001b[1;31m# Set the data, then the mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3381\u001b[1;33m             \u001b[0m_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3382\u001b[0m             \u001b[0m_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3383\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dtype'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mMaskType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the azdias df\n",
    "T_R_C_pipeline.fit(azdias_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_cluster = pd.DataFrame(T_R_C_pipeline.predict(azdias_cleaned), columns= ['Cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_259872/708292290.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the pipeline on the customer df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcustomers_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT_R_C_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustomers_cleaned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Cluster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelegate_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelegate_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         warnings.warn(\n\u001b[0;32m    122\u001b[0m             \u001b[1;34m\"if_delegate_has_method was deprecated in version 1.1 and will be \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mParameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[0mTraining\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMust\u001b[0m \u001b[0mfulfill\u001b[0m \u001b[0minput\u001b[0m \u001b[0mrequirements\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mstep\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 \u001b[0mnames_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_6_overlap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    565\u001b[0m                 \u001b[1;34mf\"Output feature names: {names_repr} are not unique. Please set \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                 \u001b[1;34m\"verbose_feature_names_out=True to add prefixes to feature names\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mValidates\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mremainder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdefines\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_remainder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtargeting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \"\"\"\n\u001b[0m\u001b[0;32m    435\u001b[0m         is_transformer = (\n\u001b[0;32m    436\u001b[0m             \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremainder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremainder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m         \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'all'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[1;31m# queue, _ready_batches, that is looked-up prior to re-consuming\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;31m# tasks from the origal iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m                 warnings.warn(\n\u001b[1;32m--> 779\u001b[1;33m                     \u001b[1;34m'The backend class {!r} does not support timeout. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                     \u001b[1;34m\"You have set 'timeout={}' in Parallel but \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m                     \"the 'timeout' parameter will not be used.\".format(\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[1;31m# Don't terminate the workers as we want to reuse them in later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[1;31m# calls, but cleanup the temporary resources that the Parallel call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;31m# of causing semantic changes and some additional pool instantiation overhead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[0mDEFAULT_MP_CONTEXT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_context'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'JOBLIB_START_METHOD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;31m# of causing semantic changes and some additional pool instantiation overhead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[0mDEFAULT_MP_CONTEXT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_context'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'JOBLIB_START_METHOD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[1;31m# check if first estimator expects pairwise input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"pairwise\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_safe_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pairwise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_feature_names_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \"\"\"Get output feature names for transformation.\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mParameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mData\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMust\u001b[0m \u001b[0mfulfill\u001b[0m \u001b[0minput\u001b[0m \u001b[0mrequirements\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    430\u001b[0m             )\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sparse_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mupon\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;34m\"constant\"\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[0mIn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimple\u001b[0m \u001b[0mimputation\u001b[0m \u001b[0musually\u001b[0m \u001b[0mperforms\u001b[0m \u001b[0mpoorly\u001b[0m \u001b[0mwhen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[0massociated\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweak\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHowever\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpowerful\u001b[0m \u001b[0mlearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0mlead\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgood\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbetter\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mcomplex\u001b[0m \u001b[0mimputation\u001b[0m \u001b[0msuch\u001b[0m \u001b[1;32mas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             message = (\n\u001b[0;32m    420\u001b[0m                 \u001b[1;34m\"The feature names should match those that were passed during fit.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             )\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mfitted_feature_names_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitted_feature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mX_feature_names_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_feature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[0mall_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKEYWORD_ONLY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mkwonly_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    737\u001b[0m         raise TypeError(\n\u001b[0;32m    738\u001b[0m             \u001b[1;34m\"np.matrix is not supported. Please convert to a numpy array with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             \u001b[1;34m\"np.asarray. For more information see: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m             \u001b[1;34m\"https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m         )\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmay_share_memory\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  10662\u001b[0m         \"\"\"\n\u001b[0;32m  10663\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10664\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10666\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1464\u001b[0m                     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1466\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1467\u001b[0m             \u001b[1;31m# The underlying data was copied within _interleave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\heuse\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 \u001b[1;31m# \"Union[dtype[Any], ExtensionDtype, None]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1521\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1522\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the customer df\n",
    "customers_cluster = pd.DataFrame(T_R_C_pipeline.predict(customers_cleaned), columns= ['Cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape {} before '.format(customers_cleaned.shape))\n",
    "customers_cleaned['Cluster'] = customers_cluster\n",
    "print('shape {} after '.format(customers_cleaned.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe results to pickle for later loadings\n",
    "# azdias_cluster.to_pickle('.\\data\\\\azdias_cluster.pickle')\n",
    "# customers_cluster.to_pickle('.\\data\\\\customer_cluster.pickle')\n",
    "\n",
    "azdias_cluster = pd.read_pickle('.\\data\\\\azdias_cluster.pickle')\n",
    "customers_cluster = pd.read_pickle('.\\data\\\\customer_cluster.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (191652, 350) before \n",
      "shape (191652, 351) after \n"
     ]
    }
   ],
   "source": [
    "azdias_cleaned['Cluster'] = azdias_cluster\n",
    "\n",
    "print('shape {} before '.format(customers_cleaned.shape))\n",
    "customers_cleaned['Cluster'] = customers_cluster\n",
    "print('shape {} after '.format(customers_cleaned.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891221, 366)\n",
      "(191652, 369)\n"
     ]
    }
   ],
   "source": [
    "# Pickle the data downloaded from the Udacity workspace\n",
    "# azdias.to_pickle('./data/azdias.pickle')\n",
    "# customers.to_pickle('./data/customers.pickle')\n",
    "\n",
    "# Load as pickle\n",
    "azdias = pd.read_pickle('./data/azdias.pickle')\n",
    "print(azdias.shape)\n",
    "customers =pd.read_pickle('./data/customers.pickle')\n",
    "print(customers.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all cluster sizes\n",
    "population_clusters = azdias_cleaned['Cluster'].value_counts().sort_index()\n",
    "customer_clusters = customers_cleaned['Cluster'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat both df to one for viz.\n",
    "df_cluster = pd.concat([population_clusters, customer_clusters], axis=1).reset_index()\n",
    "df_cluster.columns = ['cluster_n', 'population_count', 'customers_count']\n",
    "# df_cluster['cluster']+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate share of each cluster\n",
    "df_cluster['population_share'] = df_cluster.population_count / df_cluster.population_count.sum()\n",
    "df_cluster['customers_share'] = df_cluster.customers_count / df_cluster.customers_count.sum()\n",
    "df_cluster['share_diff'] = df_cluster['customers_share'] - df_cluster['population_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot clusters \n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "ind = np.arange(6)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "\n",
    "p1 = ax.bar(ind, df_cluster['population_share'], width, bottom=0, color='c' )\n",
    "p2 = ax.bar(ind + width, df_cluster['customers_share'], width, bottom=0, color='g')\n",
    "\n",
    "ax.set_title('Share of clusters in the datasets')\n",
    "ax.set_ylabel('Share of total')\n",
    "ax.set_xlabel('Cluster_n')\n",
    "\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(df_cluster['cluster_n'])\n",
    "ax.legend((p1[0], p2[0]), ('Population', 'Customers'))\n",
    "ax.autoscale_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot diffrence between cluster and dataframes\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ind = np.arange(6)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "\n",
    "bar_colors = ('grey','green','grey','red','red','grey')\n",
    "\n",
    "p1 = ax.bar(ind, df_cluster['share_diff'], width, color = bar_colors)\n",
    "\n",
    "ax.set_title('Representation of clusters in the Customer dataset vs Population dataset \\n (Overrepresnetation:green and Underrepresentation: red)')\n",
    "\n",
    "ax.set_ylabel('Difference in share (%)')\n",
    "ax.set_xlabel('Cluster_n')\n",
    "ax.axhline(linewidth=.5, color='black')\n",
    "\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(df_cluster['cluster_n']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "mailout_train = pd.read_csv('./data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALTERSKATEGORIE_FEIN',\n",
       " 'ALTER_KIND1',\n",
       " 'ALTER_KIND2',\n",
       " 'ALTER_KIND3',\n",
       " 'ALTER_KIND4',\n",
       " 'D19_BANKEN_ONLINE_QUOTE_12',\n",
       " 'D19_GESAMT_ONLINE_QUOTE_12',\n",
       " 'D19_KONSUMTYP',\n",
       " 'D19_LETZTER_KAUF_BRANCHE',\n",
       " 'D19_LOTTO',\n",
       " 'D19_SOZIALES',\n",
       " 'D19_TELKO_ONLINE_QUOTE_12',\n",
       " 'D19_VERSAND_ONLINE_QUOTE_12',\n",
       " 'D19_VERSI_ONLINE_QUOTE_12',\n",
       " 'EXTSEL992',\n",
       " 'KK_KUNDENTYP',\n",
       " 'RESPONSE'}"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mailout_train.columns) - set(azdias_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and Merge mail train\n",
    "# Clean mail\n",
    "# Drop the same values as in azdias for later analysis.\n",
    "\n",
    "drop_mail_cols  = set(mailout_train.columns) - set(azdias_cleaned.columns)\n",
    "mailout_train_cleaned = mailout_train.drop(drop_mail_cols, axis=1)\n",
    "mailout_train_cleaned['RESPONSE'] = mailout_train['RESPONSE']\n",
    "\n",
    "# The columns are dropped in customer dataset due to to many missing values\n",
    "\n",
    "\n",
    "\n",
    "# Replace nan in cleaned dataframe\n",
    "mailout_train_cleaned = replace_nans(mailout_train_cleaned, col_names, col_values, col_replace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_cleaned = timeseries_to_year(mailout_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42962, 351)"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train_cleaned.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data matrix X and output array y\n",
    "X = mailout_train_cleaned.drop('RESPONSE', axis=1)\n",
    "y = mailout_train_cleaned['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train several models for the RESPONSE column\n",
    "unsupervised_models = {\n",
    "    # 'HistGradientBoostingClassifier' : HistGradientBoostingClassifier(\n",
    "    #         verbose=1,\n",
    "    #         random_state=random_state, \n",
    "    #         warm_start=True),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(verbose=1,\n",
    "         random_state=random_state,\n",
    "         n_estimators = 10,\n",
    "         subsample=0.6,\n",
    "         tol=0.01),\n",
    "    'RandomForestClassifier': RandomForestClassifier(\n",
    "        random_state=random_state,\n",
    "        verbose=1,\n",
    "        max_samples= 0.5,\n",
    "        n_jobs=4,\n",
    "        warm_start=True)\n",
    "#      'XGBClassifier': xgb.XGBClassifier(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name is:    GradientBoostingClassifier\n",
      "Object is:  GradientBoostingClassifier(n_estimators=10, random_state=42, subsample=0.6,\n",
      "                           tol=0.01, verbose=1)\n",
      "Name is:    RandomForestClassifier\n",
      "Object is:  RandomForestClassifier(max_samples=0.5, n_jobs=4, random_state=42, verbose=1,\n",
      "                       warm_start=True)\n"
     ]
    }
   ],
   "source": [
    "for m_key, m_value in unsupervised_models.items():\n",
    "    print('Name is:    {}\\nObject is:  {}'.format(m_key, m_value ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0997          -0.0194            0.75s\n",
      "         2           0.0906          -0.0012            0.59s\n",
      "         3           0.1104          -0.0074            0.49s\n",
      "         4           0.1070          -0.0028            0.41s\n",
      "         5           0.0796          -0.0004            0.34s\n",
      "         6           0.0756          -0.0036            0.27s\n",
      "         7           0.0935           0.0001            0.21s\n",
      "         8           0.0850           0.0003            0.14s\n",
      "         9           0.0807          -0.0137            0.07s\n",
      "        10           0.0728           0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1110           0.0001            1.77s\n",
      "         2           0.1079          -0.0126            1.41s\n",
      "         3           0.1093          -0.0011            1.18s\n",
      "         4           0.1102           0.0006            1.07s\n",
      "         5           0.1198          -0.0110            0.89s\n",
      "         6           0.1197          -0.0015            0.70s\n",
      "         7           0.1181           0.0011            0.53s\n",
      "         8           0.1207           0.0001            0.35s\n",
      "         9           0.1014           0.0015            0.17s\n",
      "        10           0.1118          -0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1075          -0.0089            2.26s\n",
      "         2           0.1158          -0.0022            2.00s\n",
      "         3           0.1254           0.0005            1.77s\n",
      "         4           0.1022          -0.0070            1.51s\n",
      "         5           0.1003          -0.0022            1.23s\n",
      "         6           0.1351          -0.0015            1.02s\n",
      "         7           0.1077          -0.0019            0.83s\n",
      "         8           0.1134          -0.0001            0.59s\n",
      "         9           0.1187           0.0003            0.30s\n",
      "        10           0.0894          -0.0003            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1025           0.0001            2.84s\n",
      "         2           0.1142           0.0002            2.58s\n",
      "         3           0.1184          -0.0026            2.01s\n",
      "         4           0.1041           0.0005            1.67s\n",
      "         5           0.1260          -0.0004            1.36s\n",
      "         6           0.0971          -0.0018            1.05s\n",
      "         7           0.1056          -0.0001            0.81s\n",
      "         8           0.0951          -0.0042            0.55s\n",
      "         9           0.1031          -0.0006            0.31s\n",
      "        10           0.1010           0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1122          -0.0037            3.55s\n",
      "         2           0.1214           0.0005            3.51s\n",
      "         3           0.1216          -0.0022            2.99s\n",
      "         4           0.1065          -0.0002            2.35s\n",
      "         5           0.1121           0.0009            1.85s\n",
      "         6           0.1113           0.0004            1.43s\n",
      "         7           0.1308          -0.0001            1.19s\n",
      "         8           0.1278          -0.0003            0.82s\n",
      "         9           0.1192          -0.0002            0.43s\n",
      "        10           0.1147          -0.0015            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1225          -0.0005            3.47s\n",
      "         2           0.1315           0.0002            2.83s\n",
      "         3           0.1277           0.0006            2.40s\n",
      "         4           0.1218          -0.0010            2.13s\n",
      "         5           0.1218          -0.0001            1.84s\n",
      "         6           0.1217          -0.0001            1.57s\n",
      "         7           0.1177          -0.0001            1.21s\n",
      "         8           0.1280          -0.0000            0.84s\n",
      "         9           0.1236          -0.0002            0.43s\n",
      "        10           0.1263          -0.0029            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1257          -0.0014            4.92s\n",
      "         2           0.1319           0.0008            4.30s\n",
      "         3           0.1325          -0.0078            3.83s\n",
      "         4           0.1300           0.0004            4.30s\n",
      "         5           0.1302           0.0006            3.49s\n",
      "         6           0.1217           0.0003            2.70s\n",
      "         7           0.1255           0.0004            1.96s\n",
      "         8           0.1279           0.0004            1.26s\n",
      "         9           0.1268          -0.0017            0.60s\n",
      "        10           0.1246          -0.0625            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1242           0.0005           11.57s\n",
      "         2           0.1215           0.0006            9.11s\n",
      "         3           0.1222          -0.0004            7.98s\n",
      "         4           0.1368          -0.0000            6.44s\n",
      "         5           0.1259           0.0006            5.54s\n",
      "         6           0.1278          -0.0001            4.30s\n",
      "         7           0.1236          -0.0012            3.17s\n",
      "         8           0.1287          -0.0007            2.01s\n",
      "         9           0.1213          -0.0016            0.98s\n",
      "        10           0.1200          -0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1232           0.0012            9.31s\n",
      "         2           0.1332          -0.0000            6.60s\n",
      "         3           0.1210           0.0006            7.63s\n",
      "         4           0.1197           0.0007            5.98s\n",
      "         5           0.1250           0.0004            4.80s\n",
      "         6           0.1245          -0.0016            3.61s\n",
      "         7           0.1227          -0.0044            2.70s\n",
      "         8           0.1164           0.0010            1.76s\n",
      "         9           0.1246           0.0001            0.85s\n",
      "        10           0.1242           0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1233           0.0013            9.63s\n",
      "         2           0.1249           0.0004            7.63s\n",
      "         3           0.1173           0.0000            6.89s\n",
      "         4           0.1219           0.0007            7.62s\n",
      "         5           0.1223           0.0004            5.92s\n",
      "         6           0.1173          -0.0004            4.67s\n",
      "         7           0.1220           0.0001            3.69s\n",
      "         8           0.1209           0.0002            2.39s\n",
      "         9           0.1244           0.0001            1.19s\n",
      "        10           0.1169          -0.0012            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1441           0.0003            0.57s\n",
      "         2           0.1336          -0.0106            0.60s\n",
      "         3           0.1388          -0.0014            0.78s\n",
      "         4           0.1547          -0.0004            0.66s\n",
      "         5           0.1483          -0.0007            0.55s\n",
      "         6           0.1247          -0.0004            0.45s\n",
      "         7           0.0884          -0.0008            0.35s\n",
      "         8           0.1254          -0.0002            0.24s\n",
      "         9           0.1108           0.0008            0.12s\n",
      "        10           0.0978          -0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1498           0.0001            3.40s\n",
      "         2           0.1294          -0.0008            2.39s\n",
      "         3           0.1380          -0.0002            1.93s\n",
      "         4           0.1300           0.0024            1.62s\n",
      "         5           0.1350          -0.0119            1.27s\n",
      "         6           0.1242          -0.0014            1.01s\n",
      "         7           0.1175          -0.0014            0.75s\n",
      "         8           0.1152          -0.0013            0.50s\n",
      "         9           0.1071          -0.0017            0.24s\n",
      "        10           0.1135          -0.0038            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1394          -0.0023            6.24s\n",
      "         2           0.1509           0.0005            5.44s\n",
      "         3           0.1407           0.0006            6.07s\n",
      "         4           0.1232          -0.0006            5.17s\n",
      "         5           0.1305           0.0001            4.29s\n",
      "         6           0.1402          -0.0006            3.38s\n",
      "         7           0.1408           0.0007            2.35s\n",
      "         8           0.1415           0.0000            1.45s\n",
      "         9           0.1458           0.0000            0.68s\n",
      "        10           0.1274          -0.0033            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1363           0.0003            7.34s\n",
      "         2           0.1428          -0.0025            5.32s\n",
      "         3           0.1449           0.0002            4.01s\n",
      "         4           0.1406           0.0010            3.22s\n",
      "         5           0.1342           0.0007            2.66s\n",
      "         6           0.1454          -0.0030            2.06s\n",
      "         7           0.1310          -0.0000            1.47s\n",
      "         8           0.1327           0.0000            0.94s\n",
      "         9           0.1503          -0.0005            0.46s\n",
      "        10           0.1271          -0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1398           0.0015            4.86s\n",
      "         2           0.1279           0.0003            4.77s\n",
      "         3           0.1366          -0.0015            4.99s\n",
      "         4           0.1318          -0.0001            4.19s\n",
      "         5           0.1305          -0.0011            3.32s\n",
      "         6           0.1233          -0.0002            2.58s\n",
      "         7           0.1352          -0.0004            1.90s\n",
      "         8           0.1377           0.0012            1.22s\n",
      "         9           0.1319           0.0000            0.60s\n",
      "        10           0.1289          -0.0004            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1345           0.0007            5.82s\n",
      "         2           0.1374          -0.0011            5.58s\n",
      "         3           0.1302           0.0003            4.47s\n",
      "         4           0.1274           0.0002            3.74s\n",
      "         5           0.1358           0.0006            3.19s\n",
      "         6           0.1312          -0.0007            2.48s\n",
      "         7           0.1259          -0.0000            1.80s\n",
      "         8           0.1210          -0.0002            1.18s\n",
      "         9           0.1292          -0.0006            0.58s\n",
      "        10           0.1243          -0.0004            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1387           0.0004            5.25s\n",
      "         2           0.1413           0.0010            5.73s\n",
      "         3           0.1380          -0.0029            4.81s\n",
      "         4           0.1301           0.0004            4.08s\n",
      "         5           0.1353           0.0013            3.59s\n",
      "         6           0.1285           0.0004            2.79s\n",
      "         7           0.1224           0.0001            2.08s\n",
      "         8           0.1280          -0.0053            1.42s\n",
      "         9           0.1373           0.0001            0.70s\n",
      "        10           0.1255           0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1356          -0.0005            9.54s\n",
      "         2           0.1382           0.0009            6.72s\n",
      "         3           0.1322           0.0008            5.65s\n",
      "         4           0.1303           0.0005            4.79s\n",
      "         5           0.1345           0.0002            3.78s\n",
      "         6           0.1313           0.0005            3.16s\n",
      "         7           0.1306           0.0002            2.26s\n",
      "         8           0.1263          -0.0001            1.44s\n",
      "         9           0.1288           0.0001            0.74s\n",
      "        10           0.1315          -0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1315           0.0005           17.70s\n",
      "         2           0.1266           0.0007           14.11s\n",
      "         3           0.1373           0.0004           13.66s\n",
      "         4           0.1346           0.0004           13.48s\n",
      "         5           0.1254          -0.0019           10.28s\n",
      "         6           0.1320          -0.0030            7.78s\n",
      "         7           0.1228           0.0000            5.47s\n",
      "         8           0.1301           0.0001            3.43s\n",
      "         9           0.1268           0.0000            1.61s\n",
      "        10           0.1212           0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1327          -0.0004            7.83s\n",
      "         2           0.1372           0.0011            6.15s\n",
      "         3           0.1320           0.0001            5.66s\n",
      "         4           0.1318          -0.0005            5.14s\n",
      "         5           0.1260           0.0001            4.37s\n",
      "         6           0.1325          -0.0025            3.66s\n",
      "         7           0.1293          -0.0002            2.75s\n",
      "         8           0.1271          -0.0001            1.81s\n",
      "         9           0.1256          -0.0001            0.91s\n",
      "        10           0.1235           0.0002            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1036          -0.0075            1.09s\n",
      "         2           0.0893          -0.0534            0.82s\n",
      "         3           0.0909          -0.0056            0.73s\n",
      "         4           0.1062           0.0007            0.59s\n",
      "         5           0.0853          -0.0011            0.47s\n",
      "         6           0.0985          -0.0130            0.36s\n",
      "         7           0.0809          -0.0003            0.26s\n",
      "         8           0.0875          -0.0001            0.17s\n",
      "         9           0.0802           0.0000            0.08s\n",
      "        10           0.0800          -0.0074            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0903          -0.0130            1.44s\n",
      "         2           0.0967          -0.0504            1.27s\n",
      "         3           0.0921 -3503042977.0277            1.17s\n",
      "         4  2336494830.7254          -0.0005            1.01s\n",
      "         5           0.0789           0.0004            0.88s\n",
      "         6           0.0803          -0.0007            0.77s\n",
      "         7  2336494830.7124          -0.0183            0.59s\n",
      "         8           0.0925           0.0000            0.40s\n",
      "         9           0.0745          -0.0016            0.20s\n",
      "        10  2336494830.7190          -0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1132          -0.0006            2.70s\n",
      "         2           0.1125          -0.0008            2.25s\n",
      "         3           0.1338          -0.0086            1.83s\n",
      "         4           0.1227          -0.0023            1.48s\n",
      "         5           0.1236          -0.0045            1.20s\n",
      "         6           0.1139           0.0002            0.95s\n",
      "         7           0.1321          -0.0002            0.70s\n",
      "         8           0.1232          -0.0027            0.46s\n",
      "         9           0.1095           0.0001            0.23s\n",
      "        10           0.1157           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1226           0.0000            3.30s\n",
      "         2           0.1122           0.0012            2.86s\n",
      "         3           0.1223           0.0006            2.46s\n",
      "         4           0.1181          -0.0082            2.14s\n",
      "         5           0.1055           0.0002            1.73s\n",
      "         6           0.1090          -0.0001            1.34s\n",
      "         7           0.1178          -0.0002            0.99s\n",
      "         8           0.1186           0.0001            0.66s\n",
      "         9           0.1144           0.0002            0.33s\n",
      "        10           0.1204           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1314           0.0009            3.79s\n",
      "         2           0.1293          -0.0018            3.52s\n",
      "         3           0.1261          -0.0001            3.14s\n",
      "         4           0.1312          -0.0025            2.65s\n",
      "         5           0.1241           0.0004            2.17s\n",
      "         6           0.1294           0.0002            1.74s\n",
      "         7           0.1157           0.0000            1.31s\n",
      "         8           0.1248          -0.0006            0.86s\n",
      "         9           0.1212          -0.0003            0.42s\n",
      "        10           0.1241          -0.0008            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1268           0.0002            5.20s\n",
      "         2           0.1296          -0.0011            5.01s\n",
      "         3           0.1278           0.0003            4.44s\n",
      "         4           0.1169          -0.0000            3.46s\n",
      "         5           0.1252           0.0010            2.86s\n",
      "         6           0.1174          -0.0002            2.23s\n",
      "         7           0.1210           0.0003            1.65s\n",
      "         8           0.1111          -0.0004            1.06s\n",
      "         9           0.1088          -0.0001            0.52s\n",
      "        10           0.1182           0.0006            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1319           0.0008            6.07s\n",
      "         2           0.1311          -0.0003            4.60s\n",
      "         3           0.1268           0.0004            3.89s\n",
      "         4           0.1232          -0.0016            3.27s\n",
      "         5           0.1303           0.0001            2.63s\n",
      "         6           0.1236          -0.0002            2.04s\n",
      "         7           0.1347           0.0001            1.55s\n",
      "         8           0.1219           0.0000            1.03s\n",
      "         9           0.1273           0.0002            0.52s\n",
      "        10           0.1178          -0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1326           0.0009            6.48s\n",
      "         2           0.1329           0.0002            5.03s\n",
      "         3           0.1203          -0.0015            4.34s\n",
      "         4           0.1181           0.0002            3.70s\n",
      "         5           0.1205          -0.0004            3.06s\n",
      "         6           0.1270          -0.0037            2.44s\n",
      "         7           0.1159           0.0002            1.81s\n",
      "         8           0.1249           0.0002            1.20s\n",
      "         9           0.1146           0.0007            0.59s\n",
      "        10           0.1277          -0.0005            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1320           0.0004            6.20s\n",
      "         2           0.1230           0.0008            5.79s\n",
      "         3           0.1224           0.0005            5.20s\n",
      "         4           0.1264           0.0007            4.50s\n",
      "         5           0.1323           0.0004            3.73s\n",
      "         6           0.1308           0.0001            2.96s\n",
      "         7           0.1285           0.0001            2.14s\n",
      "         8           0.1220          -0.0001            1.39s\n",
      "         9           0.1250           0.0002            0.69s\n",
      "        10           0.1231           0.0001            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1322           0.0010            6.93s\n",
      "         2           0.1230           0.0001            6.84s\n",
      "         3           0.1258           0.0008            5.97s\n",
      "         4           0.1349           0.0005            5.14s\n",
      "         5           0.1225           0.0003            4.11s\n",
      "         6           0.1261           0.0002            3.08s\n",
      "         7           0.1378           0.0001            2.26s\n",
      "         8           0.1178          -0.0017            1.47s\n",
      "         9           0.1186           0.0000            0.72s\n",
      "        10           0.1246           0.0001            0.00s\n",
      "AUC train score = 0.75\n",
      "AUC validation score = 0.7\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done  93 out of 100 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   14.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   17.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done  93 out of 100 | elapsed:    2.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=4)]: Done  93 out of 100 | elapsed:    3.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   17.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "c:\\Users\\heuse\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  if hasattr(base_class, \"_more_tags\"):\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   15.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train score = 1.0\n",
      "AUC validation score = 0.58\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key_m, m_value in unsupervised_models.items():\n",
    "    print(key_m)\n",
    "    ml_pipeline = Pipeline([\n",
    "        ('transform', pre_pipe_columntransformer),\n",
    "        ('model', m_value)\n",
    "    ])\n",
    "    #X, y = randomize(mailout_train_cleaned)\n",
    "    draw_learning_curves(X, y, ml_pipeline, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter tunig for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparamters\n",
    "final_pipeline = gbc_pipeline = Pipeline([\n",
    "    ('transform', pre_pipe_columntransformer),\n",
    "    ('classifier', GradientBoostingClassifier(max_depth=2 ,verbose=2))\n",
    "])\n",
    "tuning_paramters = {\n",
    "    'classifier__subsample' : [0.5, 0.75],\n",
    "    'classifier__n_estimators': [100],\n",
    "    'classifier__max_depth': [2,3],\n",
    "    'classifier__min_samples_split': [2,4]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search parameters\n",
    "# \n",
    "randSCV =  RandomizedSearchCV(final_pipeline, tuning_paramters, \n",
    "    scoring = 'roc_auc',\n",
    "    n_iter = 5,\n",
    "    verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1292           0.0012            1.84m\n",
      "         2           0.1255           0.0011            1.92m\n",
      "         3           0.1260           0.0009            1.95m\n",
      "         4           0.1284           0.0006            1.84m\n",
      "         5           0.1257           0.0005            1.81m\n",
      "         6           0.1275           0.0002            1.74m\n",
      "         7           0.1285           0.0003            1.72m\n",
      "         8           0.1292          -0.0001            1.65m\n",
      "         9           0.1235           0.0003            1.63m\n",
      "        10           0.1231           0.0000            1.69m\n",
      "        11           0.1234           0.0000            1.67m\n",
      "        12           0.1214          -0.0000            1.64m\n",
      "        13           0.1210          -0.0003            1.67m\n",
      "        14           0.1226          -0.0011            1.63m\n",
      "        15           0.1234           0.0000            1.61m\n",
      "        16           0.1209          -0.0001            1.57m\n",
      "        17           0.1190           0.0000            1.53m\n",
      "        18           0.1212           0.0001            1.49m\n",
      "        19           0.1146          -0.0001            1.49m\n",
      "        20           0.1209          -0.0000            1.49m\n",
      "        21           0.1175          -0.0000            1.50m\n",
      "        22           0.1182          -0.0003            1.48m\n",
      "        23           0.1259          -0.0000            1.45m\n",
      "        24           0.1199          -0.0000            1.45m\n",
      "        25           0.1170          -0.0001            1.49m\n",
      "        26           0.1169          -0.0002            1.48m\n",
      "        27           0.1179          -0.0001            1.45m\n",
      "        28           0.1155          -0.0002            1.43m\n",
      "        29           0.1156          -0.0001            1.40m\n",
      "        30           0.1198          -0.0001            1.36m\n",
      "        31           0.1180          -0.0005            1.34m\n",
      "        32           0.1204          -0.0001            1.32m\n",
      "        33           0.1105          -0.0005            1.30m\n",
      "        34           0.1181          -0.0000            1.29m\n",
      "        35           0.1148          -0.0001            1.26m\n",
      "        36           0.1187          -0.0002            1.24m\n",
      "        37           0.1195          -0.0001            1.22m\n",
      "        38           0.1082          -0.0002            1.20m\n",
      "        39           0.1140          -0.0001            1.17m\n",
      "        40           0.1143          -0.0003            1.14m\n",
      "        41           0.1110          -0.0001            1.12m\n",
      "        42           0.1106          -0.0000            1.09m\n",
      "        43           0.1145          -0.0001            1.07m\n",
      "        44           0.1200          -0.0001            1.04m\n",
      "        45           0.1135          -0.0002            1.02m\n",
      "        46           0.1122          -0.0001           59.61s\n",
      "        47           0.1088          -0.0001           58.08s\n",
      "        48           0.1047          -0.0002           56.91s\n",
      "        49           0.1084          -0.0002           55.55s\n",
      "        50           0.1078          -0.0002           54.33s\n",
      "        51           0.1074          -0.0003           52.97s\n",
      "        52           0.1120          -0.0001           51.82s\n",
      "        53           0.1071          -0.0002           50.46s\n",
      "        54           0.1116           0.0001           49.66s\n",
      "        55           0.1129          -0.0002           48.38s\n",
      "        56           0.1101           0.0000           47.27s\n",
      "        57           0.1112          -0.0000           45.95s\n",
      "        58           0.1078          -0.0001           44.85s\n",
      "        59           0.1052          -0.0000           43.59s\n",
      "        60           0.1013          -0.0002           42.62s\n",
      "        61           0.1070          -0.0001           41.39s\n",
      "        62           0.1116          -0.0002           40.20s\n",
      "        63           0.1086          -0.0000           38.92s\n",
      "        64           0.1043          -0.0021           37.71s\n",
      "        65           0.1060          -0.0001           36.48s\n",
      "        66           0.1085          -0.0000           35.23s\n",
      "        67           0.1047          -0.0029           34.05s\n",
      "        68           0.1022          -0.0000           32.83s\n",
      "        69           0.1089          -0.0001           31.71s\n",
      "        70           0.1023          -0.0001           30.56s\n",
      "        71           0.1042          -0.0001           29.43s\n",
      "        72           0.1031          -0.0003           28.31s\n",
      "        73           0.1024          -0.0000           27.16s\n",
      "        74           0.1039          -0.0001           26.15s\n",
      "        75           0.0987          -0.0002           25.10s\n",
      "        76           0.1009          -0.0001           24.11s\n",
      "        77           0.1004          -0.0002           23.01s\n",
      "        78           0.0985           0.0001           21.97s\n",
      "        79           0.0991          -0.0002           20.89s\n",
      "        80           0.0982          -0.0000           19.87s\n",
      "        81           0.1020          -0.0001           18.84s\n",
      "        82           0.0989          -0.0002           17.86s\n",
      "        83           0.1029          -0.0001           16.83s\n",
      "        84           0.1018          -0.0002           15.82s\n",
      "        85           0.0981          -0.0002           14.79s\n",
      "        86           0.0922          -0.0002           13.82s\n",
      "        87           0.0971          -0.0001           12.81s\n",
      "        88           0.0984          -0.0001           11.83s\n",
      "        89           0.1000          -0.0001           10.83s\n",
      "        90           0.0973          -0.0001            9.82s\n",
      "        91           0.1013          -0.0001            8.82s\n",
      "        92           0.0958          -0.0000            7.83s\n",
      "        93           0.0987          -0.0001            6.85s\n",
      "        94           0.0944          -0.0002            5.86s\n",
      "        95           0.0955          -0.0002            4.89s\n",
      "        96           0.0958          -0.0001            3.90s\n",
      "        97           0.0928          -0.0002            2.92s\n",
      "        98           0.0959          -0.0000            1.95s\n",
      "        99           0.0934          -0.0001            0.97s\n",
      "       100           0.0946          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.7min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1328           0.0003            1.94m\n",
      "         2           0.1294           0.0000            1.70m\n",
      "         3           0.1264           0.0007            1.68m\n",
      "         4           0.1275           0.0009            1.55m\n",
      "         5           0.1252           0.0004            1.53m\n",
      "         6           0.1213           0.0005            1.46m\n",
      "         7           0.1301          -0.0000            1.43m\n",
      "         8           0.1270           0.0003            1.39m\n",
      "         9           0.1241           0.0003            1.36m\n",
      "        10           0.1222          -0.0001            1.33m\n",
      "        11           0.1233          -0.0002            1.30m\n",
      "        12           0.1273          -0.0001            1.31m\n",
      "        13           0.1240           0.0001            1.31m\n",
      "        14           0.1252           0.0001            1.29m\n",
      "        15           0.1244          -0.0002            1.26m\n",
      "        16           0.1247           0.0001            1.25m\n",
      "        17           0.1251          -0.0001            1.23m\n",
      "        18           0.1213          -0.0001            1.21m\n",
      "        19           0.1229          -0.0001            1.20m\n",
      "        20           0.1226           0.0000            1.19m\n",
      "        21           0.1179          -0.0000            1.18m\n",
      "        22           0.1160           0.0001            1.15m\n",
      "        23           0.1188          -0.0009            1.14m\n",
      "        24           0.1218          -0.0000            1.12m\n",
      "        25           0.1207          -0.0000            1.11m\n",
      "        26           0.1147          -0.0001            1.10m\n",
      "        27           0.1159           0.0002            1.11m\n",
      "        28           0.1163          -0.0006            1.10m\n",
      "        29           0.1146           0.0001            1.11m\n",
      "        30           0.1161          -0.0001            1.11m\n",
      "        31           0.1169           0.0000            1.10m\n",
      "        32           0.1127          -0.0001            1.09m\n",
      "        33           0.1148          -0.0003            1.09m\n",
      "        34           0.1091          -0.0002            1.10m\n",
      "        35           0.1176           0.0001            1.10m\n",
      "        36           0.1126          -0.0001            1.09m\n",
      "        37           0.1133          -0.0001            1.07m\n",
      "        38           0.1133          -0.0001            1.05m\n",
      "        39           0.1113          -0.0000            1.03m\n",
      "        40           0.1132          -0.0001            1.02m\n",
      "        41           0.1148          -0.0008            1.01m\n",
      "        42           0.1134          -0.0002           59.84s\n",
      "        43           0.1060          -0.0002           58.68s\n",
      "        44           0.1116          -0.0002           57.70s\n",
      "        45           0.1145           0.0000           56.74s\n",
      "        46           0.1139          -0.0001           55.68s\n",
      "        47           0.1134          -0.0001           54.53s\n",
      "        48           0.1111          -0.0001           53.39s\n",
      "        49           0.1155          -0.0002           52.32s\n",
      "        50           0.1112          -0.0001           51.32s\n",
      "        51           0.1126          -0.0002           50.42s\n",
      "        52           0.1084          -0.0001           49.77s\n",
      "        53           0.1124          -0.0001           48.81s\n",
      "        54           0.1089          -0.0002           47.66s\n",
      "        55           0.1076          -0.0001           46.57s\n",
      "        56           0.1110          -0.0000           45.47s\n",
      "        57           0.1058          -0.0002           44.44s\n",
      "        58           0.1063          -0.0023           43.31s\n",
      "        59           0.1081          -0.0007           42.43s\n",
      "        60           0.1106          -0.0001           41.64s\n",
      "        61           0.1072          -0.0000           40.74s\n",
      "        62           0.1034          -0.0002           39.68s\n",
      "        63           0.1063          -0.0003           38.54s\n",
      "        64           0.1068          -0.0000           37.50s\n",
      "        65           0.1044          -0.0003           36.69s\n",
      "        66           0.1047          -0.0000           35.70s\n",
      "        67           0.1002          -0.0002           34.65s\n",
      "        68           0.1072          -0.0000           33.59s\n",
      "        69           0.1029          -0.0001           32.44s\n",
      "        70           0.1067          -0.0001           31.35s\n",
      "        71           0.1041          -0.0001           30.21s\n",
      "        72           0.1057          -0.0000           29.13s\n",
      "        73           0.1023          -0.0002           28.04s\n",
      "        74           0.1027          -0.0001           26.96s\n",
      "        75           0.1027          -0.0001           25.90s\n",
      "        76           0.1050          -0.0001           24.84s\n",
      "        77           0.1027          -0.0001           23.80s\n",
      "        78           0.0998          -0.0002           22.70s\n",
      "        79           0.1014          -0.0001           21.64s\n",
      "        80           0.1047          -0.0006           20.55s\n",
      "        81           0.1023          -0.0001           19.46s\n",
      "        82           0.1034          -0.0001           18.39s\n",
      "        83           0.1029          -0.0004           17.37s\n",
      "        84           0.0987          -0.0001           16.36s\n",
      "        85           0.0986          -0.0001           15.32s\n",
      "        86           0.1010          -0.0001           14.28s\n",
      "        87           0.1003          -0.0001           13.24s\n",
      "        88           0.0976          -0.0001           12.20s\n",
      "        89           0.0990          -0.0007           11.18s\n",
      "        90           0.1011          -0.0002           10.17s\n",
      "        91           0.0984          -0.0010            9.17s\n",
      "        92           0.0969          -0.0002            8.14s\n",
      "        93           0.1019          -0.0002            7.11s\n",
      "        94           0.0959          -0.0001            6.09s\n",
      "        95           0.1005          -0.0001            5.08s\n",
      "        96           0.0981          -0.0001            4.07s\n",
      "        97           0.0989          -0.0001            3.06s\n",
      "        98           0.0937          -0.0002            2.04s\n",
      "        99           0.0995          -0.0001            1.02s\n",
      "       100           0.0971          -0.0002            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.8min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1300          -0.0016            1.63m\n",
      "         2           0.1333           0.0004            1.64m\n",
      "         3           0.1330           0.0004            1.62m\n",
      "         4           0.1304           0.0006            1.67m\n",
      "         5           0.1317           0.0003            1.63m\n",
      "         6           0.1282           0.0001            1.57m\n",
      "         7           0.1278           0.0001            1.55m\n",
      "         8           0.1281           0.0001            1.50m\n",
      "         9           0.1238           0.0001            1.51m\n",
      "        10           0.1280           0.0001            1.50m\n",
      "        11           0.1256          -0.0000            1.49m\n",
      "        12           0.1204          -0.0029            1.44m\n",
      "        13           0.1245          -0.0003            1.42m\n",
      "        14           0.1256          -0.0001            1.39m\n",
      "        15           0.1242           0.0001            1.37m\n",
      "        16           0.1252          -0.0018            1.36m\n",
      "        17           0.1214          -0.0005            1.36m\n",
      "        18           0.1257          -0.0009            1.35m\n",
      "        19           0.1168          -0.0013            1.33m\n",
      "        20           0.1205          -0.0001            1.31m\n",
      "        21           0.1248          -0.0003            1.29m\n",
      "        22           0.1180          -0.0003            1.28m\n",
      "        23           0.1190          -0.0001            1.29m\n",
      "        24           0.1212          -0.0005            1.28m\n",
      "        25           0.1195          -0.0030            1.26m\n",
      "        26           0.1172          -0.0000            1.24m\n",
      "        27           0.1184          -0.0008            1.21m\n",
      "        28           0.1214          -0.0001            1.20m\n",
      "        29           0.1167          -0.0002            1.20m\n",
      "        30           0.1143          -0.0018            1.18m\n",
      "        31           0.1165          -0.0001            1.17m\n",
      "        32           0.1188          -0.0001            1.15m\n",
      "        33           0.1176          -0.0001            1.13m\n",
      "        34           0.1185          -0.0002            1.11m\n",
      "        35           0.1199           0.0000            1.09m\n",
      "        36           0.1165          -0.0000            1.07m\n",
      "        37           0.1157          -0.0001            1.05m\n",
      "        38           0.1167          -0.0000            1.04m\n",
      "        39           0.1095          -0.0001            1.02m\n",
      "        40           0.1157          -0.0000           59.75s\n",
      "        41           0.1162          -0.0000           58.55s\n",
      "        42           0.1133          -0.0006           57.39s\n",
      "        43           0.1139          -0.0000           56.52s\n",
      "        44           0.1142          -0.0002           55.72s\n",
      "        45           0.1128           0.0001           54.70s\n",
      "        46           0.1100          -0.0001           53.61s\n",
      "        47           0.1111          -0.0001           52.64s\n",
      "        48           0.1148          -0.0001           51.60s\n",
      "        49           0.1113          -0.0002           50.59s\n",
      "        50           0.1116          -0.0001           49.78s\n",
      "        51           0.1099          -0.0001           48.71s\n",
      "        52           0.1048          -0.0002           47.66s\n",
      "        53           0.1094          -0.0002           46.70s\n",
      "        54           0.1103          -0.0000           45.75s\n",
      "        55           0.1096          -0.0001           44.76s\n",
      "        56           0.1102          -0.0002           43.69s\n",
      "        57           0.1094          -0.0001           42.57s\n",
      "        58           0.1069          -0.0000           41.56s\n",
      "        59           0.1062          -0.0002           40.48s\n",
      "        60           0.1099          -0.0001           39.40s\n",
      "        61           0.1122          -0.0001           38.36s\n",
      "        62           0.1060          -0.0001           37.41s\n",
      "        63           0.1074          -0.0002           36.41s\n",
      "        64           0.1063           0.0000           35.31s\n",
      "        65           0.1055          -0.0002           34.32s\n",
      "        66           0.1065          -0.0001           33.28s\n",
      "        67           0.1049          -0.0001           32.37s\n",
      "        68           0.1065          -0.0002           31.60s\n",
      "        69           0.1063          -0.0001           30.63s\n",
      "        70           0.1016          -0.0002           29.72s\n",
      "        71           0.1016          -0.0009           28.75s\n",
      "        72           0.1061          -0.0001           27.81s\n",
      "        73           0.1058          -0.0002           26.92s\n",
      "        74           0.1010          -0.0001           25.92s\n",
      "        75           0.1007          -0.0001           24.89s\n",
      "        76           0.1032          -0.0001           23.93s\n",
      "        77           0.1011           0.0000           22.97s\n",
      "        78           0.1046          -0.0001           22.01s\n",
      "        79           0.1011          -0.0002           21.02s\n",
      "        80           0.1008          -0.0001           20.02s\n",
      "        81           0.0978          -0.0001           19.00s\n",
      "        82           0.1008          -0.0000           18.00s\n",
      "        83           0.0996          -0.0000           17.02s\n",
      "        84           0.1027           0.0000           16.04s\n",
      "        85           0.1009          -0.0002           15.06s\n",
      "        86           0.0989          -0.0001           14.04s\n",
      "        87           0.1010          -0.0002           13.03s\n",
      "        88           0.1002          -0.0003           12.03s\n",
      "        89           0.0985           0.0000           11.03s\n",
      "        90           0.1008          -0.0002           10.02s\n",
      "        91           0.1022          -0.0001            9.01s\n",
      "        92           0.0956          -0.0002            7.99s\n",
      "        93           0.1010          -0.0000            6.98s\n",
      "        94           0.0983          -0.0002            5.96s\n",
      "        95           0.0959          -0.0001            4.96s\n",
      "        96           0.0956          -0.0002            3.97s\n",
      "        97           0.0987          -0.0001            2.97s\n",
      "        98           0.0986          -0.0001            1.98s\n",
      "        99           0.0967          -0.0002            0.99s\n",
      "       100           0.0929          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.7min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1365           0.0009            1.94m\n",
      "         2           0.1374           0.0009            1.83m\n",
      "         3           0.1290           0.0006            1.62m\n",
      "         4           0.1295           0.0008            1.57m\n",
      "         5           0.1258          -0.0000            1.55m\n",
      "         6           0.1212           0.0003            1.54m\n",
      "         7           0.1240           0.0001            1.51m\n",
      "         8           0.1274          -0.0013            1.45m\n",
      "         9           0.1250           0.0001            1.41m\n",
      "        10           0.1257           0.0000            1.37m\n",
      "        11           0.1247           0.0001            1.35m\n",
      "        12           0.1237          -0.0005            1.34m\n",
      "        13           0.1244          -0.0000            1.33m\n",
      "        14           0.1201          -0.0000            1.31m\n",
      "        15           0.1190          -0.0001            1.27m\n",
      "        16           0.1139          -0.0001            1.25m\n",
      "        17           0.1212          -0.0001            1.22m\n",
      "        18           0.1224          -0.0001            1.19m\n",
      "        19           0.1195          -0.0005            1.17m\n",
      "        20           0.1259          -0.0008            1.14m\n",
      "        21           0.1172          -0.0001            1.12m\n",
      "        22           0.1147          -0.0001            1.10m\n",
      "        23           0.1164          -0.0000            1.08m\n",
      "        24           0.1153          -0.0013            1.06m\n",
      "        25           0.1203          -0.0007            1.04m\n",
      "        26           0.1160           0.0001            1.02m\n",
      "        27           0.1107          -0.0001            1.01m\n",
      "        28           0.1157           0.0000           59.50s\n",
      "        29           0.1187          -0.0001           58.41s\n",
      "        30           0.1175          -0.0005           57.95s\n",
      "        31           0.1149          -0.0001           57.08s\n",
      "        32           0.1117          -0.0000           56.14s\n",
      "        33           0.1198          -0.0002           55.19s\n",
      "        34           0.1153          -0.0001           54.21s\n",
      "        35           0.1150           0.0000           53.27s\n",
      "        36           0.1150          -0.0000           52.42s\n",
      "        37           0.1139          -0.0001           51.55s\n",
      "        38           0.1138          -0.0001           50.70s\n",
      "        39           0.1126          -0.0000           49.73s\n",
      "        40           0.1108          -0.0001           48.87s\n",
      "        41           0.1105          -0.0000           47.97s\n",
      "        42           0.1126           0.0000           47.22s\n",
      "        43           0.1087          -0.0001           46.38s\n",
      "        44           0.1131          -0.0002           45.49s\n",
      "        45           0.1092          -0.0002           44.63s\n",
      "        46           0.1120          -0.0003           43.81s\n",
      "        47           0.1110          -0.0000           43.01s\n",
      "        48           0.1085          -0.0001           42.20s\n",
      "        49           0.1105           0.0000           41.43s\n",
      "        50           0.1075           0.0001           40.61s\n",
      "        51           0.1035          -0.0001           39.99s\n",
      "        52           0.1073          -0.0002           39.25s\n",
      "        53           0.1095          -0.0002           38.47s\n",
      "        54           0.1078          -0.0002           37.72s\n",
      "        55           0.1038          -0.0001           37.03s\n",
      "        56           0.1113          -0.0001           36.34s\n",
      "        57           0.1046           0.0001           35.60s\n",
      "        58           0.1027          -0.0001           34.81s\n",
      "        59           0.1077          -0.0002           34.05s\n",
      "        60           0.1100          -0.0001           33.24s\n",
      "        61           0.1064          -0.0002           32.49s\n",
      "        62           0.1037          -0.0056           31.70s\n",
      "        63           0.1030          -0.0002           30.92s\n",
      "        64           0.1091          -0.0001           30.10s\n",
      "        65           0.1074          -0.0001           29.20s\n",
      "        66           0.1090          -0.0001           28.37s\n",
      "        67           0.1056          -0.0002           27.47s\n",
      "        68           0.1042          -0.0000           26.60s\n",
      "        69           0.1021          -0.0001           25.78s\n",
      "        70           0.1019          -0.0004           24.97s\n",
      "        71           0.0992          -0.0004           24.22s\n",
      "        72           0.1014          -0.0000           23.43s\n",
      "        73           0.1000          -0.0001           22.72s\n",
      "        74           0.0995          -0.0001           22.01s\n",
      "        75           0.0997          -0.0001           21.28s\n",
      "        76           0.1019          -0.0001           20.49s\n",
      "        77           0.0980          -0.0001           19.74s\n",
      "        78           0.1016          -0.0001           19.03s\n",
      "        79           0.1018          -0.0001           18.40s\n",
      "        80           0.0999          -0.0001           17.68s\n",
      "        81           0.1041          -0.0001           16.83s\n",
      "        82           0.0961          -0.0004           16.02s\n",
      "        83           0.0989          -0.0001           15.22s\n",
      "        84           0.1009          -0.0001           14.41s\n",
      "        85           0.0949          -0.0002           13.56s\n",
      "        86           0.0981          -0.0001           12.68s\n",
      "        87           0.0991          -0.0001           11.80s\n",
      "        88           0.0971           0.0002           10.92s\n",
      "        89           0.0940          -0.0002           10.04s\n",
      "        90           0.0949          -0.0000            9.21s\n",
      "        91           0.0970          -0.0001            8.34s\n",
      "        92           0.0983          -0.0023            7.49s\n",
      "        93           0.0933          -0.0000            6.58s\n",
      "        94           0.0969          -0.0001            5.65s\n",
      "        95           0.0920          -0.0000            4.71s\n",
      "        96           0.0991          -0.0001            3.77s\n",
      "        97           0.0952          -0.0002            2.82s\n",
      "        98           0.0952          -0.0001            1.89s\n",
      "        99           0.0916          -0.0001            0.95s\n",
      "       100           0.0955          -0.0002            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.6min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1360           0.0005            1.52m\n",
      "         2           0.1247           0.0011            1.44m\n",
      "         3           0.1277           0.0007            1.40m\n",
      "         4           0.1253           0.0005            1.51m\n",
      "         5           0.1268           0.0002            1.71m\n",
      "         6           0.1201           0.0004            1.68m\n",
      "         7           0.1260           0.0003            1.73m\n",
      "         8           0.1253           0.0001            1.81m\n",
      "         9           0.1244          -0.0001            1.79m\n",
      "        10           0.1289           0.0000            1.77m\n",
      "        11           0.1270           0.0000            1.78m\n",
      "        12           0.1213          -0.0001            1.72m\n",
      "        13           0.1204           0.0000            1.70m\n",
      "        14           0.1194          -0.0001            1.70m\n",
      "        15           0.1266           0.0000            1.72m\n",
      "        16           0.1222          -0.0013            1.71m\n",
      "        17           0.1224          -0.0002            1.69m\n",
      "        18           0.1215           0.0004            1.71m\n",
      "        19           0.1207          -0.0002            1.70m\n",
      "        20           0.1199          -0.0002            1.69m\n",
      "        21           0.1176          -0.0000            1.68m\n",
      "        22           0.1218          -0.0001            1.64m\n",
      "        23           0.1182           0.0004            1.61m\n",
      "        24           0.1182          -0.0001            1.58m\n",
      "        25           0.1202          -0.0000            1.56m\n",
      "        26           0.1155          -0.0002            1.57m\n",
      "        27           0.1171          -0.0001            1.55m\n",
      "        28           0.1129          -0.0001            1.52m\n",
      "        29           0.1154          -0.0000            1.50m\n",
      "        30           0.1149          -0.0001            1.47m\n",
      "        31           0.1149          -0.0000            1.45m\n",
      "        32           0.1123           0.0000            1.42m\n",
      "        33           0.1178          -0.0001            1.39m\n",
      "        34           0.1116          -0.0001            1.36m\n",
      "        35           0.1085          -0.0001            1.33m\n",
      "        36           0.1127          -0.0001            1.31m\n",
      "        37           0.1142          -0.0001            1.30m\n",
      "        38           0.1094          -0.0001            1.28m\n",
      "        39           0.1126          -0.0001            1.26m\n",
      "        40           0.1111           0.0000            1.23m\n",
      "        41           0.1109          -0.0000            1.21m\n",
      "        42           0.1064           0.0001            1.18m\n",
      "        43           0.1102          -0.0001            1.16m\n",
      "        44           0.1108          -0.0001            1.14m\n",
      "        45           0.1057          -0.0002            1.12m\n",
      "        46           0.1128          -0.0001            1.10m\n",
      "        47           0.1066          -0.0002            1.08m\n",
      "        48           0.1077          -0.0002            1.05m\n",
      "        49           0.1106          -0.0001            1.03m\n",
      "        50           0.1077          -0.0002            1.01m\n",
      "        51           0.1083           0.0000           59.27s\n",
      "        52           0.1070          -0.0001           58.49s\n",
      "        53           0.1096          -0.0001           57.22s\n",
      "        54           0.1044          -0.0001           55.84s\n",
      "        55           0.1048          -0.0002           54.62s\n",
      "        56           0.1066          -0.0001           53.41s\n",
      "        57           0.1059          -0.0001           52.19s\n",
      "        58           0.1045          -0.0001           50.85s\n",
      "        59           0.1069          -0.0001           49.59s\n",
      "        60           0.1057          -0.0001           48.29s\n",
      "        61           0.1033          -0.0001           47.04s\n",
      "        62           0.1020          -0.0001           45.80s\n",
      "        63           0.1008          -0.0002           44.55s\n",
      "        64           0.1001          -0.0002           43.26s\n",
      "        65           0.1027          -0.0001           42.02s\n",
      "        66           0.1003          -0.0001           40.97s\n",
      "        67           0.1058          -0.0001           39.90s\n",
      "        68           0.1006          -0.0001           38.59s\n",
      "        69           0.1046          -0.0001           37.28s\n",
      "        70           0.1042          -0.0000           36.02s\n",
      "        71           0.0990          -0.0000           34.80s\n",
      "        72           0.0984          -0.0001           33.61s\n",
      "        73           0.1000          -0.0001           32.38s\n",
      "        74           0.1026          -0.0002           31.07s\n",
      "        75           0.1023           0.0000           29.78s\n",
      "        76           0.0947          -0.0002           28.51s\n",
      "        77           0.1000          -0.0001           27.28s\n",
      "        78           0.0977          -0.0002           26.10s\n",
      "        79           0.1017          -0.0002           24.90s\n",
      "        80           0.0966          -0.0002           23.71s\n",
      "        81           0.0983          -0.0002           22.54s\n",
      "        82           0.1020          -0.0002           21.44s\n",
      "        83           0.0976          -0.0000           20.50s\n",
      "        84           0.0996          -0.0002           19.37s\n",
      "        85           0.0935          -0.0001           18.19s\n",
      "        86           0.0906          -0.0017           17.14s\n",
      "        87           0.0974          -0.0001           16.01s\n",
      "        88           0.0986          -0.0001           14.85s\n",
      "        89           0.0970          -0.0001           13.61s\n",
      "        90           0.0991          -0.0002           12.51s\n",
      "        91           0.0987          -0.0001           11.33s\n",
      "        92           0.0950          -0.0004           10.06s\n",
      "        93           0.0958          -0.0001            8.78s\n",
      "        94           0.0946           0.0000            7.51s\n",
      "        95           0.0955          -0.0001            6.26s\n",
      "        96           0.0968          -0.0002            5.05s\n",
      "        97           0.0992          -0.0002            3.78s\n",
      "        98           0.0940          -0.0001            2.53s\n",
      "        99           0.0908          -0.0001            1.27s\n",
      "       100           0.0920          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 2.2min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1378           0.0010            1.32m\n",
      "         2           0.1295          -0.0004            1.33m\n",
      "         3           0.1253           0.0006            1.49m\n",
      "         4           0.1257           0.0006            1.49m\n",
      "         5           0.1151           0.0001            1.45m\n",
      "         6           0.1267           0.0003            1.44m\n",
      "         7           0.1268          -0.0001            1.39m\n",
      "         8           0.1196           0.0004            1.34m\n",
      "         9           0.1261          -0.0000            1.29m\n",
      "        10           0.1220          -0.0027            1.25m\n",
      "        11           0.1217           0.0002            1.22m\n",
      "        12           0.1227           0.0000            1.19m\n",
      "        13           0.1245           0.0002            1.17m\n",
      "        14           0.1278          -0.0000            1.15m\n",
      "        15           0.1260          -0.0002            1.14m\n",
      "        16           0.1209          -0.0006            1.12m\n",
      "        17           0.1187          -0.0001            1.12m\n",
      "        18           0.1316          -0.0012            1.10m\n",
      "        19           0.1222          -0.0000            1.08m\n",
      "        20           0.1232           0.0001            1.06m\n",
      "        21           0.1137          -0.0003            1.05m\n",
      "        22           0.1171          -0.0000            1.02m\n",
      "        23           0.1202          -0.0002            1.01m\n",
      "        24           0.1149          -0.0002           59.56s\n",
      "        25           0.1251           0.0000           58.42s\n",
      "        26           0.1164          -0.0001           57.62s\n",
      "        27           0.1117          -0.0002           57.01s\n",
      "        28           0.1101          -0.0001           56.01s\n",
      "        29           0.1231          -0.0000           55.05s\n",
      "        30           0.1218          -0.0047           54.29s\n",
      "        31           0.1154          -0.0003           53.31s\n",
      "        32           0.1133          -0.0000           52.50s\n",
      "        33           0.1157          -0.0009           51.57s\n",
      "        34           0.1130          -0.0001           50.62s\n",
      "        35           0.1119          -0.2848           49.70s\n",
      "        36           0.3911          -0.0021           49.01s\n",
      "        37           0.1076          -0.0003           48.35s\n",
      "        38           0.1074          -0.0002           47.56s\n",
      "        39           0.3998          -0.0000           46.75s\n",
      "        40           0.3968           0.0000           45.80s\n",
      "        41           0.1031          -0.0003           44.94s\n",
      "        42           0.1119          -0.0001           44.03s\n",
      "        43           0.1057          -0.0003           43.41s\n",
      "        44           0.1049          -0.0000           42.66s\n",
      "        45           0.1138          -0.0010           41.97s\n",
      "        46           0.1135           0.0000           41.13s\n",
      "        47           0.1091          -0.0000           40.29s\n",
      "        48           0.3932          -0.0000           39.67s\n",
      "        49           0.3897          -0.0000           39.06s\n",
      "        50           0.1072          -0.0001           38.33s\n",
      "        51           0.3952          -0.0000           37.55s\n",
      "        52           0.3933          -0.0000           36.71s\n",
      "        53           0.1094          -0.0002           35.79s\n",
      "        54           0.3932           0.0001           35.00s\n",
      "        55           0.1042          -0.0003           34.31s\n",
      "        56           0.3858          -0.0002           33.66s\n",
      "        57           0.1005          -0.0001           32.83s\n",
      "        58           0.4016          -0.0002           32.00s\n",
      "        59           0.3896           0.0000           31.14s\n",
      "        60           0.3894          -0.0000           30.31s\n",
      "        61           0.3915          -0.0001           29.53s\n",
      "        62           0.3889          -0.0000           28.68s\n",
      "        63           0.1073          -0.0002           27.91s\n",
      "        64           0.1010           0.0000           27.15s\n",
      "        65           0.3839          -0.0001           26.41s\n",
      "        66           0.3880          -0.0002           25.91s\n",
      "        67           0.3803          -0.0005           25.24s\n",
      "        68           0.3851          -0.0002           24.54s\n",
      "        69           0.3881          -0.0001           23.85s\n",
      "        70           0.3873          -0.0003           23.15s\n",
      "        71           0.0922          -0.0002           22.50s\n",
      "        72           0.3776          -0.0001           21.83s\n",
      "        73           0.3811          -0.0001           21.04s\n",
      "        74           0.1049          -0.0002           20.28s\n",
      "        75           0.3809          -0.0001           19.46s\n",
      "        76           0.3842          -0.0001           18.65s\n",
      "        77           0.1087          -0.0000           17.91s\n",
      "        78           0.3908          -0.0004           17.19s\n",
      "        79           0.3716          -0.0000           16.45s\n",
      "        80           0.1031          -0.0001           15.64s\n",
      "        81           0.3871          -0.0000           14.88s\n",
      "        82           0.3763          -0.0002           14.14s\n",
      "        83           0.3894          -0.0001           13.40s\n",
      "        84           0.3861          -0.0018           12.61s\n",
      "        85           0.3754          -0.0001           11.82s\n",
      "        86           0.3809          -0.0001           11.02s\n",
      "        87           0.3829          -0.0001           10.23s\n",
      "        88           0.3859          -0.0002            9.41s\n",
      "        89           0.1000          -0.0001            8.63s\n",
      "        90           0.1006          -0.0001            7.83s\n",
      "        91           0.3762          -0.0000            7.05s\n",
      "        92           0.0957          -0.0001            6.26s\n",
      "        93           0.0921          -0.0002            5.47s\n",
      "        94           0.3756          -0.0001            4.70s\n",
      "        95           0.3865          -0.0002            3.91s\n",
      "        96           0.0936          -0.0000            3.13s\n",
      "        97           0.0890           0.0000            2.34s\n",
      "        98           0.3809          -0.0001            1.56s\n",
      "        99           0.0922          -0.0001            0.78s\n",
      "       100           0.0909          -0.0002            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.5; total time= 1.3min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1270           0.0005            1.32m\n",
      "         2           0.1272           0.0010            1.58m\n",
      "         3           0.1235           0.0008            1.70m\n",
      "         4           0.1263          -0.0002            1.70m\n",
      "         5           0.1267           0.0003            1.74m\n",
      "         6           0.1283           0.0006            1.63m\n",
      "         7           0.1255          -0.0015            1.60m\n",
      "         8           0.1343          -0.0078            1.55m\n",
      "         9           0.1349           0.0005            1.54m\n",
      "        10           0.1373          -0.0051            1.51m\n",
      "        11           0.1198          -0.0001            1.48m\n",
      "        12           0.1334          -0.0048            1.43m\n",
      "        13           0.1297          -0.0002            1.43m\n",
      "        14           0.1459           0.0001            1.46m\n",
      "        15           0.1405          -0.0011            1.51m\n",
      "        16           0.1431          -0.0000            1.50m\n",
      "        17           0.1312           0.0000            1.54m\n",
      "        18           0.1342          -0.0000            1.52m\n",
      "        19           0.1291          -0.0031            1.48m\n",
      "        20           0.1274          -0.0004            1.45m\n",
      "        21           0.1331           0.0001            1.42m\n",
      "        22           0.1388           0.0000            1.38m\n",
      "        23           0.1420           0.0001            1.34m\n",
      "        24           0.1349          -0.0000            1.32m\n",
      "        25           0.1224          -0.0000            1.29m\n",
      "        26           0.1394          -0.0003            1.25m\n",
      "        27           0.1281           0.0000            1.24m\n",
      "        28           0.1384           0.0000            1.23m\n",
      "        29           0.1160          -0.0003            1.23m\n",
      "        30           0.1336          -0.0001            1.22m\n",
      "        31           0.1182          -0.0009            1.21m\n",
      "        32           0.1264          -0.0000            1.18m\n",
      "        33           0.1143          -0.0001            1.15m\n",
      "        34           0.1233          -0.0001            1.12m\n",
      "        35           0.1292          -0.0006            1.09m\n",
      "        36           0.1252          -0.0001            1.07m\n",
      "        37           0.1314          -0.0001            1.05m\n",
      "        38           0.1261          -0.0001            1.03m\n",
      "        39           0.1119          -0.0046            1.01m\n",
      "        40           0.1265          -0.0001           58.90s\n",
      "        41           0.1330          -0.0000           57.69s\n",
      "        42           0.1221          -0.0001           57.07s\n",
      "        43           0.1121          -0.0000           55.89s\n",
      "        44           0.1099           0.0004           55.13s\n",
      "        45           0.1108          -0.0003           55.31s\n",
      "        46           0.1092          -0.0002           55.41s\n",
      "        47           0.1112          -0.0000           54.99s\n",
      "        48           0.1134          -0.0002           53.67s\n",
      "        49           0.1089          -0.0001           52.23s\n",
      "        50           0.1226          -0.0002           50.86s\n",
      "        51           0.1207          -0.0001           49.41s\n",
      "        52           0.1150          -0.0000           48.30s\n",
      "        53           0.1101          -0.0003           47.34s\n",
      "        54           0.1222          -0.0002           46.30s\n",
      "        55           0.1357          -0.0003           45.09s\n",
      "        56           0.1176          -0.0000           43.95s\n",
      "        57           0.1155          -0.0001           42.72s\n",
      "        58           0.1077          -0.0002           41.65s\n",
      "        59           0.1099          -0.0002           40.66s\n",
      "        60           0.1166          -0.0002           39.69s\n",
      "        61           0.1195          -0.0002           38.69s\n",
      "        62           0.1095          -0.0026           37.65s\n",
      "        63           0.1130          -0.0001           36.55s\n",
      "        64           0.1248          -0.0001           35.44s\n",
      "        65           0.1240          -0.0000           34.32s\n",
      "        66           0.1186          -0.0002           33.25s\n",
      "        67           0.1148          -0.0001           32.35s\n",
      "        68           0.1020           0.0000           31.47s\n",
      "        69           0.1112          -0.0000           30.48s\n",
      "        70           0.1099          -0.0002           29.41s\n",
      "        71           0.1284          -0.0003           28.34s\n",
      "        72           0.1203          -0.0001           27.27s\n",
      "        73           0.1242          -0.0004           26.27s\n",
      "        74           0.1097           0.0000           25.27s\n",
      "        75           0.0973          -0.0001           24.31s\n",
      "        76           0.1163          -0.0002           23.30s\n",
      "        77           0.1038          -0.0002           22.27s\n",
      "        78           0.1066          -0.0001           21.26s\n",
      "        79           0.1223          -0.0001           20.23s\n",
      "        80           0.1096          -0.0003           19.19s\n",
      "        81           0.1101          -0.0002           18.19s\n",
      "        82           0.1201          -0.0001           17.23s\n",
      "        83           0.1160          -0.0001           16.25s\n",
      "        84           0.1003          -0.0003           15.26s\n",
      "        85           0.1031          -0.0002           14.26s\n",
      "        86           0.1060          -0.0001           13.25s\n",
      "        87           0.1083          -0.0002           12.25s\n",
      "        88           0.1087          -0.0014           11.27s\n",
      "        89           0.1155          -0.0001           10.29s\n",
      "        90           0.1188          -0.0006            9.33s\n",
      "        91           0.1108          -0.0001            8.36s\n",
      "        92           0.1137           0.0000            7.41s\n",
      "        93           0.1045           0.0000            6.47s\n",
      "        94           0.1157          -0.0001            5.53s\n",
      "        95           0.1041          -0.0001            4.59s\n",
      "        96           0.0951           0.0000            3.66s\n",
      "        97           0.1016          -0.0002            2.74s\n",
      "        98           0.1180          -0.0001            1.82s\n",
      "        99           0.1040          -0.0000            0.91s\n",
      "       100           0.1091          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.5; total time= 1.6min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1329           0.0006            1.23m\n",
      "         2           0.1259           0.0006            1.21m\n",
      "         3           0.1294           0.0006            1.18m\n",
      "         4           0.1242          -0.0014            1.13m\n",
      "         5           0.1286           0.0005            1.10m\n",
      "         6           0.1259           0.0000            1.07m\n",
      "         7           0.1232          -0.0002            1.04m\n",
      "         8           0.1244          -0.0001            1.01m\n",
      "         9           0.1358          -0.0013           59.54s\n",
      "        10           0.1288           0.0003           58.63s\n",
      "        11           0.1269          -0.0001           57.85s\n",
      "        12           0.1183           0.0000           58.12s\n",
      "        13           0.1181           0.0002           58.08s\n",
      "        14           0.1310          -0.0002           58.07s\n",
      "        15           0.1245          -0.0011           58.46s\n",
      "        16           0.1254          -0.0000           57.75s\n",
      "        17           0.1187           0.0000           56.92s\n",
      "        18           0.1168           0.0000           56.35s\n",
      "        19           0.1209          -0.0001           55.91s\n",
      "        20           0.1179          -0.0001           55.13s\n",
      "        21           0.1232          -0.0001           54.56s\n",
      "        22           0.1184          -0.0000           53.74s\n",
      "        23           0.1194          -0.0004           53.05s\n",
      "        24           0.1179          -0.0002           52.35s\n",
      "        25           0.1156          -0.0002           53.11s\n",
      "        26           0.1131          -0.0015           52.98s\n",
      "        27           0.1199           0.0000           52.86s\n",
      "        28           0.1184          -0.0000           52.67s\n",
      "        29           0.1214          -0.0001           52.56s\n",
      "        30           0.1158          -0.0001           52.35s\n",
      "        31           0.1209          -0.0003           51.52s\n",
      "        32           0.1226          -0.0002           50.39s\n",
      "        33           0.1145           0.0001           49.40s\n",
      "        34           0.1139          -0.0009           48.51s\n",
      "        35           0.1118          -0.0001           48.11s\n",
      "        36           0.1196           0.0000           47.42s\n",
      "        37           0.1117          -0.0002           46.78s\n",
      "        38           0.1104          -0.0000           46.22s\n",
      "        39           0.1183          -0.0001           45.32s\n",
      "        40           0.1224          -0.0027           44.67s\n",
      "        41           0.1098           0.0000           43.77s\n",
      "        42           0.1169          -0.0004           42.92s\n",
      "        43           0.1160          -0.0001           42.12s\n",
      "        44           0.1142          -0.0000           41.29s\n",
      "        45           0.1148          -0.0002           40.54s\n",
      "        46           0.1172          -0.0002           39.98s\n",
      "        47           0.1115          -0.0001           39.16s\n",
      "        48           0.1040          -0.0007           38.26s\n",
      "        49           0.1188          -0.0002           37.38s\n",
      "        50           0.1084          -0.0001           36.59s\n",
      "        51           0.1072          -0.0004           35.87s\n",
      "        52           0.1073          -0.0001           35.03s\n",
      "        53           0.1121          -0.0018           34.32s\n",
      "        54           0.1129          -0.0004           33.55s\n",
      "        55           0.1042           0.0001           32.90s\n",
      "        56           0.1093           0.0000           32.24s\n",
      "        57           0.1099          -0.0002           31.37s\n",
      "        58           0.0938          -0.0000           30.77s\n",
      "        59           0.1061           0.0000           30.09s\n",
      "        60           0.1056          -0.0002           29.24s\n",
      "        61           0.1100          -0.0001           28.78s\n",
      "        62           0.1073          -0.0001           28.27s\n",
      "        63           0.1020          -0.0002           27.68s\n",
      "        64           0.1098          -0.0001           27.06s\n",
      "        65           0.1054          -0.0000           26.32s\n",
      "        66           0.1030          -0.0002           25.55s\n",
      "        67           0.1045          -0.0002           24.80s\n",
      "        68           0.1102          -0.0000           23.94s\n",
      "        69           0.1054          -0.0000           23.16s\n",
      "        70           0.1043          -0.0000           22.34s\n",
      "        71           0.1031          -0.0001           21.51s\n",
      "        72           0.1096          -0.0004           20.74s\n",
      "        73           0.0918          -0.0003           19.94s\n",
      "        74           0.0940          -0.0001           19.20s\n",
      "        75           0.0974          -0.0002           18.40s\n",
      "        76           0.1097          -0.0001           17.60s\n",
      "        77           0.1045          -0.0001           16.82s\n",
      "        78           0.0967          -0.0000           16.06s\n",
      "        79           0.0992          -0.0002           15.39s\n",
      "        80           0.1019          -0.0001           14.67s\n",
      "        81           0.1020          -0.0001           13.92s\n",
      "        82           0.1006          -0.0001           13.22s\n",
      "        83           0.1038          -0.0002           12.49s\n",
      "        84           0.1018          -0.0001           11.75s\n",
      "        85           0.0909          -0.0002           11.06s\n",
      "        86           0.0973           0.0000           10.32s\n",
      "        87           0.0974          -0.0001            9.56s\n",
      "        88           0.0914          -0.0001            8.81s\n",
      "        89           0.0970          -0.0001            8.06s\n",
      "        90           0.0900          -0.0036            7.31s\n",
      "        91           0.0948          -0.0001            6.58s\n",
      "        92           0.0915          -0.0002            5.84s\n",
      "        93           0.1006          -0.0000            5.11s\n",
      "        94           0.0937          -0.0003            4.38s\n",
      "        95           0.0979          -0.0001            3.64s\n",
      "        96           0.0937          -0.0002            2.90s\n",
      "        97           0.0896          -0.0003            2.17s\n",
      "        98           0.0981          -0.0002            1.44s\n",
      "        99           0.1012          -0.0003            0.72s\n",
      "       100           0.0965          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.5; total time= 1.2min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1372           0.0007            1.04m\n",
      "         2           0.1207           0.0006            1.03m\n",
      "         3           0.1312           0.0010            1.06m\n",
      "         4           0.1312           0.0001            1.06m\n",
      "         5           0.1403           0.0004            1.06m\n",
      "         6           0.1238          -0.0000            1.10m\n",
      "         7           0.1276           0.0000            1.10m\n",
      "         8           0.1252          -0.0005            1.05m\n",
      "         9           0.1302          -0.0036            1.03m\n",
      "        10           0.1202          -0.0018            1.00m\n",
      "        11           0.1247           0.0001           59.20s\n",
      "        12           0.1140           0.0007           58.53s\n",
      "        13           0.1232          -0.0001           56.75s\n",
      "        14           0.1172          -0.0036           56.05s\n",
      "        15           0.1237          -0.0005            1.06m\n",
      "        16           0.1219           0.0002            1.11m\n",
      "        17           0.1167           0.0001            1.16m\n",
      "        18           0.1227           0.0000            1.15m\n",
      "        19           0.1208           0.0002            1.12m\n",
      "        20           0.1208           0.0000            1.09m\n",
      "        21           0.1249          -0.0000            1.06m\n",
      "        22           0.1232          -0.0006            1.04m\n",
      "        23           0.1106          -0.0003            1.03m\n",
      "        24           0.1219           0.0001            1.01m\n",
      "        25           0.1254           0.0001           59.23s\n",
      "        26           0.1166          -0.0001           58.43s\n",
      "        27           0.1181           0.0002           57.51s\n",
      "        28           0.1133          -0.0002           56.47s\n",
      "        29           0.1164          -0.0002           55.17s\n",
      "        30           0.1125          -0.0001           54.67s\n",
      "        31           0.1200           0.0001           54.15s\n",
      "        32           0.1155          -0.0001           53.84s\n",
      "        33           0.1230          -0.0001           53.04s\n",
      "        34           0.1139          -0.0008           51.92s\n",
      "        35           0.1140          -0.0000           51.37s\n",
      "        36           0.1168           0.0000           50.59s\n",
      "        37           0.1170          -0.0018           50.45s\n",
      "        38           0.1153           0.0000           49.76s\n",
      "        39           0.1123          -0.0000           49.21s\n",
      "        40           0.1157           0.0001           48.24s\n",
      "        41           0.1127          -0.0004           47.34s\n",
      "        42           0.1101           0.0000           46.45s\n",
      "        43           0.1193          -0.0001           45.62s\n",
      "        44           0.1148          -0.0000           44.95s\n",
      "        45           0.1207          -0.0001           44.40s\n",
      "        46           0.1073          -0.0001           43.61s\n",
      "        47           0.1112          -0.0000           42.66s\n",
      "        48           0.1195          -0.0001           41.58s\n",
      "        49           0.1106          -0.0000           40.67s\n",
      "        50           0.1049          -0.0001           39.73s\n",
      "        51           0.1128          -0.0006           38.77s\n",
      "        52           0.1063          -0.0003           37.96s\n",
      "        53           0.1206           0.0000           36.97s\n",
      "        54           0.1079          -0.0060           36.09s\n",
      "        55           0.1178          -0.0022           35.22s\n",
      "        56           0.1142          -0.0001           34.35s\n",
      "        57           0.1060          -0.0002           33.47s\n",
      "        58           0.1119          -0.0000           32.55s\n",
      "        59           0.1159          -0.0001           31.79s\n",
      "        60           0.1148           0.0000           30.93s\n",
      "        61           0.1207          -0.0000           30.44s\n",
      "        62           0.1059          -0.0001           29.78s\n",
      "        63           0.1221          -0.0000           28.91s\n",
      "        64           0.1066          -0.0000           28.00s\n",
      "        65           0.1110          -0.0000           27.13s\n",
      "        66           0.1109          -0.0001           26.33s\n",
      "        67           0.1144          -0.0001           25.52s\n",
      "        68           0.1059          -0.0000           24.75s\n",
      "        69           0.1085          -0.0001           23.91s\n",
      "        70           0.1114          -0.0001           23.04s\n",
      "        71           0.1181           0.0000           22.18s\n",
      "        72           0.1071          -0.0000           21.37s\n",
      "        73           0.1138          -0.0001           20.53s\n",
      "        74           0.1107          -0.0002           19.69s\n",
      "        75           0.1086          -0.0002           18.87s\n",
      "        76           0.1098           0.0000           18.05s\n",
      "        77           0.1024          -0.0001           17.25s\n",
      "        78           0.1096          -0.0001           16.44s\n",
      "        79           0.1064          -0.0000           15.64s\n",
      "        80           0.1122          -0.0001           14.85s\n",
      "        81           0.1076          -0.0001           14.08s\n",
      "        82           0.0974          -0.0001           13.30s\n",
      "        83           0.1069          -0.0001           12.53s\n",
      "        84           0.1088          -0.0001           11.77s\n",
      "        85           0.1059          -0.0005           11.01s\n",
      "        86           0.0991          -0.0000           10.25s\n",
      "        87           0.1107          -0.0008            9.49s\n",
      "        88           0.1087          -0.0010            8.74s\n",
      "        89           0.1045          -0.0001            7.99s\n",
      "        90           0.1023          -0.0004            7.25s\n",
      "        91           0.0947          -0.0002            6.53s\n",
      "        92           0.1067          -0.0002            5.81s\n",
      "        93           0.1103          -0.0001            5.10s\n",
      "        94           0.1001          -0.0001            4.37s\n",
      "        95           0.0946          -0.0004            3.64s\n",
      "        96           0.1012          -0.0001            2.91s\n",
      "        97           0.0931          -0.0000            2.18s\n",
      "        98           0.1018          -0.0002            1.45s\n",
      "        99           0.0985          -0.0001            0.73s\n",
      "       100           0.1004          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.5; total time= 1.3min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1406          -0.0000            1.46m\n",
      "         2           0.1381           0.0009            1.60m\n",
      "         3           0.1269           0.0004            1.73m\n",
      "         4           0.1322          -0.0004            1.70m\n",
      "         5           0.1234           0.0002            1.59m\n",
      "         6           0.1281           0.0003            1.48m\n",
      "         7           0.1320          -0.0001            1.40m\n",
      "         8           0.1273          -0.0015            1.34m\n",
      "         9           0.1243           0.0002            1.29m\n",
      "        10           0.1214          -0.0000            1.28m\n",
      "        11           0.1253          -0.0000            1.27m\n",
      "        12           0.1285          -0.0002            1.25m\n",
      "        13           0.1217           0.0000            1.26m\n",
      "        14           0.1209          -0.0001            1.25m\n",
      "        15           0.1248          -0.0007            1.23m\n",
      "        16           0.1214           0.0002            1.20m\n",
      "        17           0.1291          -0.0000            1.17m\n",
      "        18           0.1234           0.0001            1.15m\n",
      "        19           0.1200          -0.0002            1.12m\n",
      "        20           0.1180          -0.0066            1.11m\n",
      "        21           0.1330           0.0020            1.09m\n",
      "        22           0.1421          -0.0002            1.07m\n",
      "        23           0.1341          -0.0003            1.05m\n",
      "        24           0.1217          -0.0036            1.05m\n",
      "        25           0.1426          -0.0002            1.03m\n",
      "        26           0.1440           0.0001            1.02m\n",
      "        27           0.1245           0.0000            1.01m\n",
      "        28           0.1366          -0.0001           58.89s\n",
      "        29           0.1424          -0.0000           57.66s\n",
      "        30           0.1254          -0.0001           56.60s\n",
      "        31           0.1207          -0.0010           55.47s\n",
      "        32           0.1175          -0.0001           54.44s\n",
      "        33           0.1376          -0.0504           53.34s\n",
      "        34           0.1909           0.0000           52.13s\n",
      "        35           0.1861          -0.0002           51.07s\n",
      "        36           0.1970          -0.0001           50.05s\n",
      "        37           0.1846          -0.0002           48.93s\n",
      "        38           0.1105          -0.0006           48.00s\n",
      "        39           0.1728          -0.0004           47.01s\n",
      "        40           0.1631          -0.0002           45.99s\n",
      "        41           0.1814          -0.0000           45.06s\n",
      "        42           0.1655           0.0000           44.08s\n",
      "        43           0.1161          -0.0001           43.12s\n",
      "        44           0.1402          -0.0000           42.19s\n",
      "        45           0.1335          -0.0000           41.54s\n",
      "        46           0.1137          -0.0002           40.65s\n",
      "        47           0.1096          -0.0002           39.82s\n",
      "        48           0.1158          -0.0002           40.29s\n",
      "        49           0.1858          -0.0003           39.54s\n",
      "        50           0.1662          -0.0002           38.92s\n",
      "        51           0.1777          -0.0000           38.45s\n",
      "        52           0.1804          -0.0002           37.88s\n",
      "        53           0.1290          -0.0001           37.30s\n",
      "        54           0.1326          -0.0001           36.43s\n",
      "        55           0.1261          -0.0002           35.49s\n",
      "        56           0.1653          -0.0000           34.58s\n",
      "        57           0.1618          -0.0000           34.38s\n",
      "        58           0.1603          -0.0002           33.67s\n",
      "        59           0.1621          -0.0002           33.08s\n",
      "        60           0.1591          -0.0002           32.30s\n",
      "        61           0.1275          -0.0003           31.48s\n",
      "        62           0.1246          -0.0001           30.62s\n",
      "        63           0.1529          -0.0002           29.76s\n",
      "        64           0.1094          -0.0005           28.93s\n",
      "        65           0.1781          -0.0004           28.33s\n",
      "        66           0.1233           0.0000           27.67s\n",
      "        67           0.1538          -0.0002           27.29s\n",
      "        68           0.1039          -0.0002           26.46s\n",
      "        69           0.1660          -0.0002           25.59s\n",
      "        70           0.1678          -0.0000           24.65s\n",
      "        71           0.1268          -0.0002           23.78s\n",
      "        72           0.1712          -0.0001           22.85s\n",
      "        73           0.1711          -0.0007           21.98s\n",
      "        74           0.1065          -0.0001           21.12s\n",
      "        75           0.1746          -0.0001           20.31s\n",
      "        76           0.1714          -0.0001           19.49s\n",
      "        77           0.1710          -0.0005           18.61s\n",
      "        78           0.1500          -0.0001           17.75s\n",
      "        79           0.1266          -0.0001           16.88s\n",
      "        80           0.1543          -0.0001           16.03s\n",
      "        81           0.0960          -0.0001           15.22s\n",
      "        82           0.1203          -0.0001           14.38s\n",
      "        83           0.1486          -0.0002           13.57s\n",
      "        84           0.1168          -0.0002           12.74s\n",
      "        85           0.1168          -0.0040           11.90s\n",
      "        86           0.1221          -0.0001           11.12s\n",
      "        87           0.1037          -0.0001           10.28s\n",
      "        88           0.1226           0.0000            9.47s\n",
      "        89           0.1553          -0.0000            8.68s\n",
      "        90           0.0934          -0.0001            7.90s\n",
      "        91           0.0990           0.0000            7.12s\n",
      "        92           0.1734          -0.0002            6.35s\n",
      "        93           0.1540          -0.0014            5.55s\n",
      "        94           0.1737          -0.0001            4.75s\n",
      "        95           0.1239          -0.0002            3.94s\n",
      "        96           0.1244          -0.0002            3.14s\n",
      "        97           0.1486          -0.0000            2.35s\n",
      "        98           0.0970          -0.0001            1.57s\n",
      "        99           0.1477          -0.0001            0.78s\n",
      "       100           0.1532          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.5; total time= 1.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1343           0.0012            1.67m\n",
      "         2           0.1247           0.0011            1.79m\n",
      "         3           0.1293           0.0007            1.77m\n",
      "         4           0.1256           0.0004            1.70m\n",
      "         5           0.1255           0.0006            1.66m\n",
      "         6           0.1247           0.0002            1.65m\n",
      "         7           0.1205          -0.0018            1.64m\n",
      "         8           0.1204           0.0002            1.61m\n",
      "         9           0.1255           0.0001            1.60m\n",
      "        10           0.1243           0.0002            1.58m\n",
      "        11           0.1250          -0.0001            1.55m\n",
      "        12           0.1224          -0.0000            1.52m\n",
      "        13           0.1271          -0.0034            1.48m\n",
      "        14           0.1230          -0.0001            1.48m\n",
      "        15           0.1283          -0.0002            1.46m\n",
      "        16           0.1232          -0.0002            1.47m\n",
      "        17           0.1216          -0.0001            1.45m\n",
      "        18           0.1231          -0.0005            1.43m\n",
      "        19           0.1196           0.0000            1.43m\n",
      "        20           0.1233          -0.0001            1.43m\n",
      "        21           0.1186           0.0000            1.43m\n",
      "        22           0.1185          -0.0002            1.42m\n",
      "        23           0.1163          -0.0001            1.40m\n",
      "        24           0.1171          -0.0000            1.38m\n",
      "        25           0.1171          -0.0001            1.36m\n",
      "        26           0.1166          -0.0002            1.35m\n",
      "        27           0.1166          -0.0001            1.36m\n",
      "        28           0.1179          -0.0001            1.35m\n",
      "        29           0.1164          -0.0001            1.33m\n",
      "        30           0.1173          -0.0002            1.31m\n",
      "        31           0.1144           0.0000            1.31m\n",
      "        32           0.1140          -0.0000            1.29m\n",
      "        33           0.1137          -0.0001            1.27m\n",
      "        34           0.1135          -0.0001            1.27m\n",
      "        35           0.1164          -0.0001            1.26m\n",
      "        36           0.1161          -0.0000            1.23m\n",
      "        37           0.1152          -0.0001            1.21m\n",
      "        38           0.1165          -0.0000            1.19m\n",
      "        39           0.1122          -0.0002            1.18m\n",
      "        40           0.1125          -0.0015            1.16m\n",
      "        41           0.1154          -0.0002            1.14m\n",
      "        42           0.1128          -0.0003            1.12m\n",
      "        43           0.1160          -0.0000            1.11m\n",
      "        44           0.1154          -0.0001            1.09m\n",
      "        45           0.1150          -0.0000            1.07m\n",
      "        46           0.1125          -0.0001            1.05m\n",
      "        47           0.1112          -0.0001            1.03m\n",
      "        48           0.1114           0.0000            1.01m\n",
      "        49           0.1137          -0.0001           59.40s\n",
      "        50           0.1120          -0.0005           57.86s\n",
      "        51           0.1104          -0.0000           56.46s\n",
      "        52           0.1068          -0.0001           54.95s\n",
      "        53           0.1098          -0.0001           53.54s\n",
      "        54           0.1067          -0.0002           52.21s\n",
      "        55           0.1110          -0.0001           50.86s\n",
      "        56           0.1075          -0.0002           49.45s\n",
      "        57           0.1108          -0.0001           48.01s\n",
      "        58           0.1087          -0.0016           46.63s\n",
      "        59           0.1096          -0.0001           45.24s\n",
      "        60           0.1103          -0.0002           43.91s\n",
      "        61           0.1111          -0.0001           42.59s\n",
      "        62           0.1088          -0.0000           41.27s\n",
      "        63           0.1049          -0.0002           39.96s\n",
      "        64           0.1070          -0.0001           38.71s\n",
      "        65           0.1076          -0.0000           37.43s\n",
      "        66           0.1089          -0.0001           36.20s\n",
      "        67           0.1052          -0.0003           35.00s\n",
      "        68           0.1067          -0.0001           33.83s\n",
      "        69           0.1081          -0.0004           32.66s\n",
      "        70           0.1096          -0.0002           31.50s\n",
      "        71           0.1053           0.0001           30.36s\n",
      "        72           0.1087          -0.0001           29.21s\n",
      "        73           0.1034           0.0000           28.09s\n",
      "        74           0.1049          -0.0003           26.97s\n",
      "        75           0.1034          -0.0001           25.89s\n",
      "        76           0.1039          -0.0001           24.79s\n",
      "        77           0.1039          -0.0002           23.70s\n",
      "        78           0.1031          -0.0001           22.61s\n",
      "        79           0.1050          -0.0001           21.52s\n",
      "        80           0.1030          -0.0001           20.46s\n",
      "        81           0.1031          -0.0001           19.39s\n",
      "        82           0.1054          -0.0001           18.38s\n",
      "        83           0.1012          -0.0000           17.35s\n",
      "        84           0.0987          -0.0001           16.30s\n",
      "        85           0.1003          -0.0000           15.40s\n",
      "        86           0.1030          -0.0001           14.38s\n",
      "        87           0.0979          -0.0002           13.40s\n",
      "        88           0.1038          -0.0001           12.39s\n",
      "        89           0.1022          -0.0002           11.39s\n",
      "        90           0.0984          -0.0002           10.39s\n",
      "        91           0.0993          -0.0000            9.36s\n",
      "        92           0.1013          -0.0002            8.31s\n",
      "        93           0.1036          -0.0002            7.25s\n",
      "        94           0.0995          -0.0001            6.21s\n",
      "        95           0.0981          -0.0001            5.17s\n",
      "        96           0.1013          -0.0001            4.15s\n",
      "        97           0.0980          -0.0001            3.13s\n",
      "        98           0.1017          -0.0001            2.09s\n",
      "        99           0.0976          -0.0002            1.05s\n",
      "       100           0.0973          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.8min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1382           0.0006            1.93m\n",
      "         2           0.1306           0.0006            1.74m\n",
      "         3           0.1288           0.0007            1.59m\n",
      "         4           0.1327           0.0005            1.51m\n",
      "         5           0.1260           0.0002            1.50m\n",
      "         6           0.1280           0.0002            1.52m\n",
      "         7           0.1238           0.0004            1.51m\n",
      "         8           0.1279           0.0000            1.47m\n",
      "         9           0.1310           0.0002            1.46m\n",
      "        10           0.1241          -0.0000            1.46m\n",
      "        11           0.1241           0.0001            1.52m\n",
      "        12           0.1224          -0.0003            1.54m\n",
      "        13           0.1211          -0.0001            1.52m\n",
      "        14           0.1247          -0.0001            1.49m\n",
      "        15           0.1254           0.0000            1.46m\n",
      "        16           0.1175          -0.0001            1.43m\n",
      "        17           0.1232          -0.0001            1.40m\n",
      "        18           0.1248           0.0000            1.36m\n",
      "        19           0.1247          -0.0000            1.33m\n",
      "        20           0.1234          -0.0002            1.31m\n",
      "        21           0.1212          -0.0001            1.32m\n",
      "        22           0.1227           0.0000            1.32m\n",
      "        23           0.1190          -0.0002            1.31m\n",
      "        24           0.1164          -0.0001            1.31m\n",
      "        25           0.1191          -0.0000            1.31m\n",
      "        26           0.1202          -0.0002            1.32m\n",
      "        27           0.1151          -0.0017            1.32m\n",
      "        28           0.1184          -0.0002            1.32m\n",
      "        29           0.1129          -0.0001            1.32m\n",
      "        30           0.1164          -0.0003            1.32m\n",
      "        31           0.1164          -0.0002            1.30m\n",
      "        32           0.1136          -0.0002            1.29m\n",
      "        33           0.1134          -0.0001            1.27m\n",
      "        34           0.1162          -0.0001            1.24m\n",
      "        35           0.1163          -0.0002            1.22m\n",
      "        36           0.1140          -0.0003            1.19m\n",
      "        37           0.1098          -0.0000            1.16m\n",
      "        38           0.1168          -0.0012            1.13m\n",
      "        39           0.1110           0.0000            1.11m\n",
      "        40           0.1150          -0.0000            1.08m\n",
      "        41           0.1103          -0.0002            1.06m\n",
      "        42           0.1142          -0.0001            1.04m\n",
      "        43           0.1106          -0.0003            1.02m\n",
      "        44           0.1139          -0.0004           59.98s\n",
      "        45           0.1115          -0.0000           58.73s\n",
      "        46           0.1100          -0.0010           57.58s\n",
      "        47           0.1154          -0.0000           56.47s\n",
      "        48           0.1134          -0.0000           55.39s\n",
      "        49           0.1089          -0.0003           54.24s\n",
      "        50           0.1081          -0.0001           53.05s\n",
      "        51           0.1121          -0.0000           51.72s\n",
      "        52           0.1064          -0.0002           50.51s\n",
      "        53           0.1110          -0.0001           49.25s\n",
      "        54           0.1106          -0.0002           48.07s\n",
      "        55           0.1090          -0.0002           47.63s\n",
      "        56           0.1104          -0.0001           47.13s\n",
      "        57           0.1083          -0.0003           46.41s\n",
      "        58           0.1141          -0.0001           45.47s\n",
      "        59           0.1096          -0.0000           44.79s\n",
      "        60           0.1009          -0.0000           44.21s\n",
      "        61           0.1083          -0.0001           43.40s\n",
      "        62           0.1041          -0.0040           42.48s\n",
      "        63           0.1059          -0.0001           41.60s\n",
      "        64           0.1041          -0.0001           40.85s\n",
      "        65           0.1029          -0.0000           40.04s\n",
      "        66           0.1054          -0.0002           39.08s\n",
      "        67           0.1048          -0.0000           38.28s\n",
      "        68           0.1074          -0.0002           37.28s\n",
      "        69           0.0996          -0.0000           36.08s\n",
      "        70           0.1029          -0.0019           34.77s\n",
      "        71           0.1064          -0.0001           33.49s\n",
      "        72           0.1026          -0.0000           32.20s\n",
      "        73           0.1050          -0.0003           31.15s\n",
      "        74           0.1003          -0.0001           29.98s\n",
      "        75           0.0999          -0.0001           28.75s\n",
      "        76           0.1013          -0.0001           27.48s\n",
      "        77           0.1044          -0.0003           26.41s\n",
      "        78           0.1022          -0.0007           25.18s\n",
      "        79           0.1044           0.0001           23.99s\n",
      "        80           0.1034          -0.0002           22.81s\n",
      "        81           0.1049          -0.0001           22.06s\n",
      "        82           0.0988          -0.0002           21.19s\n",
      "        83           0.0974          -0.0013           20.05s\n",
      "        84           0.1009          -0.0001           18.87s\n",
      "        85           0.0985          -0.0001           17.74s\n",
      "        86           0.1008          -0.0000           16.55s\n",
      "        87           0.0994          -0.0000           15.38s\n",
      "        88           0.1000          -0.0001           14.25s\n",
      "        89           0.0976          -0.0001           13.06s\n",
      "        90           0.0971          -0.0000           11.86s\n",
      "        91           0.0975          -0.0001           10.67s\n",
      "        92           0.1004          -0.0002            9.50s\n",
      "        93           0.0996          -0.0001            8.32s\n",
      "        94           0.1006          -0.0001            7.10s\n",
      "        95           0.1002          -0.0002            5.90s\n",
      "        96           0.0926          -0.0002            4.72s\n",
      "        97           0.0961          -0.0002            3.53s\n",
      "        98           0.0940          -0.0002            2.35s\n",
      "        99           0.0935          -0.0001            1.17s\n",
      "       100           0.0979          -0.0002            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 2.0min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1343          -0.0000            2.71m\n",
      "         2           0.1384          -0.0019            2.10m\n",
      "         3           0.1326           0.0004            1.96m\n",
      "         4           0.1281           0.0002            1.90m\n",
      "         5           0.1271           0.0004            1.89m\n",
      "         6           0.1353           0.0002            1.84m\n",
      "         7           0.1269           0.0001            1.74m\n",
      "         8           0.1268          -0.0003            1.69m\n",
      "         9           0.1256           0.0000            1.69m\n",
      "        10           0.1248           0.0001            1.73m\n",
      "        11           0.1270          -0.0001            1.82m\n",
      "        12           0.1238          -0.0002            1.79m\n",
      "        13           0.1257          -0.0000            1.78m\n",
      "        14           0.1282          -0.0001            1.78m\n",
      "        15           0.1285          -0.0004            1.82m\n",
      "        16           0.1283           0.0001            1.79m\n",
      "        17           0.1222          -0.0001            1.77m\n",
      "        18           0.1205          -0.0001            1.72m\n",
      "        19           0.1226          -0.0001            1.69m\n",
      "        20           0.1257          -0.0001            1.65m\n",
      "        21           0.1234          -0.0000            1.62m\n",
      "        22           0.1273           0.0001            1.58m\n",
      "        23           0.1223          -0.0000            1.54m\n",
      "        24           0.1235          -0.0001            1.50m\n",
      "        25           0.1216          -0.0002            1.47m\n",
      "        26           0.1186          -0.0016            1.44m\n",
      "        27           0.1195          -0.0001            1.42m\n",
      "        28           0.1259          -0.0011            1.41m\n",
      "        29           0.1222          -0.0000            1.38m\n",
      "        30           0.1179          -0.0001            1.35m\n",
      "        31           0.1230          -0.0002            1.32m\n",
      "        32           0.1180          -0.0001            1.30m\n",
      "        33           0.1231          -0.0001            1.29m\n",
      "        34           0.1184          -0.0001            1.30m\n",
      "        35           0.1108          -0.0002            1.27m\n",
      "        36           0.1173           0.0002            1.24m\n",
      "        37           0.1151          -0.0001            1.22m\n",
      "        38           0.1197          -0.0001            1.21m\n",
      "        39           0.1191          -0.0001            1.18m\n",
      "        40           0.1159          -0.0002            1.16m\n",
      "        41           0.1210          -0.0001            1.13m\n",
      "        42           0.1159          -0.0001            1.14m\n",
      "        43           0.1133          -0.0001            1.12m\n",
      "        44           0.1169          -0.0002            1.10m\n",
      "        45           0.1145          -0.0001            1.08m\n",
      "        46           0.1183          -0.0001            1.05m\n",
      "        47           0.1123          -0.0000            1.03m\n",
      "        48           0.1146          -0.0003            1.00m\n",
      "        49           0.1123          -0.0002           59.34s\n",
      "        50           0.1129          -0.0001           58.01s\n",
      "        51           0.1108          -0.0001           56.50s\n",
      "        52           0.1107          -0.0001           54.99s\n",
      "        53           0.1084          -0.0001           53.53s\n",
      "        54           0.1101          -0.0000           52.25s\n",
      "        55           0.1080          -0.0002           50.95s\n",
      "        56           0.1122          -0.0000           49.79s\n",
      "        57           0.1106          -0.0001           48.42s\n",
      "        58           0.1089          -0.0000           47.13s\n",
      "        59           0.1081          -0.0002           45.76s\n",
      "        60           0.1058          -0.0002           44.44s\n",
      "        61           0.1101          -0.0008           43.13s\n",
      "        62           0.1056          -0.0001           41.88s\n",
      "        63           0.1076          -0.0004           40.63s\n",
      "        64           0.1076          -0.0004           39.47s\n",
      "        65           0.1088           0.0000           38.21s\n",
      "        66           0.1062          -0.0002           37.10s\n",
      "        67           0.1075          -0.0000           35.92s\n",
      "        68           0.1093           0.0000           34.78s\n",
      "        69           0.1030          -0.0007           33.51s\n",
      "        70           0.1042          -0.0002           32.40s\n",
      "        71           0.1060          -0.0000           31.18s\n",
      "        72           0.1086          -0.0001           30.02s\n",
      "        73           0.1082          -0.0000           28.89s\n",
      "        74           0.1052          -0.0001           27.80s\n",
      "        75           0.1025          -0.0000           26.68s\n",
      "        76           0.1018          -0.0001           25.57s\n",
      "        77           0.0975          -0.0001           24.52s\n",
      "        78           0.1013          -0.0002           23.42s\n",
      "        79           0.1062          -0.0001           22.30s\n",
      "        80           0.1091          -0.0001           21.18s\n",
      "        81           0.1021          -0.0001           20.10s\n",
      "        82           0.1000          -0.0002           19.03s\n",
      "        83           0.0997          -0.0301           18.05s\n",
      "        84           0.1070          -0.0001           17.03s\n",
      "        85           0.1114          -0.0001           15.96s\n",
      "        86           0.1080          -0.0001           15.03s\n",
      "        87           0.1085          -0.0001           13.97s\n",
      "        88           0.1103          -0.0001           12.88s\n",
      "        89           0.1042          -0.0000           11.81s\n",
      "        90           0.1099          -0.0001           10.75s\n",
      "        91           0.1068          -0.0002            9.65s\n",
      "        92           0.1080          -0.0002            8.75s\n",
      "        93           0.1052          -0.0001            7.66s\n",
      "        94           0.1076          -0.0001            6.56s\n",
      "        95           0.1059          -0.0001            5.46s\n",
      "        96           0.1026          -0.0003            4.37s\n",
      "        97           0.1066          -0.0002            3.28s\n",
      "        98           0.0994          -0.0000            2.18s\n",
      "        99           0.1005          -0.0000            1.09s\n",
      "       100           0.1081          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.9min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1365           0.0011            1.55m\n",
      "         2           0.1271           0.0012            1.60m\n",
      "         3           0.1259           0.0010            1.63m\n",
      "         4           0.1270           0.0005            1.75m\n",
      "         5           0.1267          -0.0007            1.75m\n",
      "         6           0.1298           0.0002            1.67m\n",
      "         7           0.1282          -0.0000            1.63m\n",
      "         8           0.1224           0.0002            1.61m\n",
      "         9           0.1217          -0.0001            1.66m\n",
      "        10           0.1223           0.0001            1.72m\n",
      "        11           0.1224           0.0001            1.71m\n",
      "        12           0.1254           0.0001            1.68m\n",
      "        13           0.1238          -0.0001            1.64m\n",
      "        14           0.1274           0.0000            1.63m\n",
      "        15           0.1197          -0.0002            1.60m\n",
      "        16           0.1233          -0.0001            1.57m\n",
      "        17           0.1198          -0.0002            1.53m\n",
      "        18           0.1183          -0.0002            1.54m\n",
      "        19           0.1190           0.0001            1.51m\n",
      "        20           0.1186          -0.0000            1.49m\n",
      "        21           0.1198          -0.0003            1.46m\n",
      "        22           0.1144          -0.0002            1.45m\n",
      "        23           0.1192          -0.0001            1.44m\n",
      "        24           0.1181          -0.0005            1.41m\n",
      "        25           0.1113          -0.0007            1.39m\n",
      "        26           0.1119          -0.0001            1.35m\n",
      "        27           0.1159          -0.0001            1.32m\n",
      "        28           0.1151          -0.0002            1.29m\n",
      "        29           0.1115          -0.0000            1.27m\n",
      "        30           0.1148          -0.0020            1.25m\n",
      "        31           0.1152          -0.0000            1.22m\n",
      "        32           0.1173           0.0001            1.19m\n",
      "        33           0.1148          -0.0005            1.17m\n",
      "        34           0.1138          -0.0002            1.15m\n",
      "        35           0.1125          -0.0001            1.13m\n",
      "        36           0.1126          -0.0001            1.11m\n",
      "        37           0.1136           0.0000            1.08m\n",
      "        38           0.1132          -0.0003            1.06m\n",
      "        39           0.1124          -0.0001            1.04m\n",
      "        40           0.1104          -0.0001            1.01m\n",
      "        41           0.1086          -0.0002           59.37s\n",
      "        42           0.1133          -0.0001           58.16s\n",
      "        43           0.1077          -0.0003           56.86s\n",
      "        44           0.1095          -0.0001           55.86s\n",
      "        45           0.1111          -0.0001           54.77s\n",
      "        46           0.1101          -0.0000           53.94s\n",
      "        47           0.1090          -0.0001           53.65s\n",
      "        48           0.1118          -0.0002           53.35s\n",
      "        49           0.1076          -0.0008           52.51s\n",
      "        50           0.1051          -0.0003           51.59s\n",
      "        51           0.1038          -0.0003           50.90s\n",
      "        52           0.1089          -0.0002           50.03s\n",
      "        53           0.1081          -0.0001           49.04s\n",
      "        54           0.1032          -0.0002           47.80s\n",
      "        55           0.1060          -0.0001           46.63s\n",
      "        56           0.1082          -0.0002           45.55s\n",
      "        57           0.1080          -0.0001           44.62s\n",
      "        58           0.1058          -0.0002           43.76s\n",
      "        59           0.1048          -0.0002           43.02s\n",
      "        60           0.1013          -0.0020           42.35s\n",
      "        61           0.1094          -0.0001           41.49s\n",
      "        62           0.1091          -0.0000           40.43s\n",
      "        63           0.1041          -0.0001           39.27s\n",
      "        64           0.0996           0.0000           38.17s\n",
      "        65           0.1056          -0.0001           37.13s\n",
      "        66           0.1030          -0.0002           36.13s\n",
      "        67           0.1056          -0.0001           35.00s\n",
      "        68           0.1018          -0.0001           33.86s\n",
      "        69           0.1011          -0.0002           32.68s\n",
      "        70           0.1030          -0.0002           31.53s\n",
      "        71           0.1026          -0.0003           30.41s\n",
      "        72           0.1020          -0.0000           29.38s\n",
      "        73           0.1022          -0.0029           28.35s\n",
      "        74           0.0964          -0.0000           27.24s\n",
      "        75           0.0996          -0.0000           26.15s\n",
      "        76           0.1006          -0.0000           25.11s\n",
      "        77           0.1023          -0.0002           24.07s\n",
      "        78           0.0958          -0.0001           23.04s\n",
      "        79           0.1038          -0.0002           22.21s\n",
      "        80           0.1011          -0.0001           21.28s\n",
      "        81           0.0976          -0.0002           20.36s\n",
      "        82           0.1014          -0.0002           19.35s\n",
      "        83           0.0958          -0.0002           18.29s\n",
      "        84           0.0960           0.0000           17.24s\n",
      "        85           0.0969          -0.0001           16.21s\n",
      "        86           0.1009          -0.0000           15.21s\n",
      "        87           0.0942          -0.0001           14.21s\n",
      "        88           0.0992          -0.0002           13.16s\n",
      "        89           0.0971          -0.0001           12.13s\n",
      "        90           0.0976          -0.0002           11.04s\n",
      "        91           0.0980          -0.0000            9.93s\n",
      "        92           0.0980          -0.0001            8.82s\n",
      "        93           0.0943          -0.0001            7.71s\n",
      "        94           0.0963          -0.0000            6.61s\n",
      "        95           0.0938          -0.0001            5.52s\n",
      "        96           0.0938          -0.0001            4.41s\n",
      "        97           0.0943          -0.0001            3.31s\n",
      "        98           0.0959          -0.0001            2.20s\n",
      "        99           0.0945          -0.0001            1.10s\n",
      "       100           0.0934          -0.0002            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.9min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1319           0.0012            1.72m\n",
      "         2           0.1232           0.0011            1.63m\n",
      "         3           0.1285           0.0006            1.67m\n",
      "         4           0.1264           0.0007            1.64m\n",
      "         5           0.1240           0.0005            1.64m\n",
      "         6           0.1272           0.0003            1.65m\n",
      "         7           0.1236          -0.0001            1.63m\n",
      "         8           0.1258           0.0001            1.60m\n",
      "         9           0.1185           0.0000            1.57m\n",
      "        10           0.1252           0.0003            1.54m\n",
      "        11           0.1282          -0.0001            1.53m\n",
      "        12           0.1247          -0.0000            1.56m\n",
      "        13           0.1267          -0.0002            1.55m\n",
      "        14           0.1181          -0.0001            1.54m\n",
      "        15           0.1214           0.0001            1.56m\n",
      "        16           0.1224          -0.0023            1.57m\n",
      "        17           0.1178          -0.0001            1.59m\n",
      "        18           0.1184          -0.0000            1.57m\n",
      "        19           0.1189           0.0000            1.55m\n",
      "        20           0.1198          -0.0000            1.54m\n",
      "        21           0.1181          -0.0003            1.54m\n",
      "        22           0.1152          -0.0001            1.54m\n",
      "        23           0.1137          -0.0000            1.53m\n",
      "        24           0.1168           0.0001            1.51m\n",
      "        25           0.1128          -0.0001            1.48m\n",
      "        26           0.1136          -0.0001            1.47m\n",
      "        27           0.1189          -0.0013            1.45m\n",
      "        28           0.1144          -0.0004            1.44m\n",
      "        29           0.1161          -0.0000            1.42m\n",
      "        30           0.1136          -0.0002            1.41m\n",
      "        31           0.1106          -0.0001            1.41m\n",
      "        32           0.1135          -0.0003            1.39m\n",
      "        33           0.1098          -0.0004            1.38m\n",
      "        34           0.1135          -0.0000            1.36m\n",
      "        35           0.1130          -0.0001            1.34m\n",
      "        36           0.1118          -0.0003            1.32m\n",
      "        37           0.1135          -0.0003            1.29m\n",
      "        38           0.1159           0.0000            1.29m\n",
      "        39           0.1139          -0.0001            1.28m\n",
      "        40           0.1096          -0.0003            1.29m\n",
      "        41           0.1100          -0.0003            1.28m\n",
      "        42           0.1061          -0.0000            1.28m\n",
      "        43           0.1165          -0.0001            1.30m\n",
      "        44           0.1100          -0.0001            1.29m\n",
      "        45           0.1086          -0.0001            1.27m\n",
      "        46           0.1103           0.0000            1.25m\n",
      "        47           0.1079          -0.0011            1.23m\n",
      "        48           0.1092           0.0000            1.20m\n",
      "        49           0.1073          -0.0001            1.18m\n",
      "        50           0.1116          -0.0001            1.17m\n",
      "        51           0.1086          -0.0001            1.15m\n",
      "        52           0.1114          -0.0000            1.12m\n",
      "        53           0.1074          -0.0001            1.10m\n",
      "        54           0.1084          -0.0002            1.08m\n",
      "        55           0.1065           0.0001            1.06m\n",
      "        56           0.1030          -0.0016            1.03m\n",
      "        57           0.1075          -0.0001            1.01m\n",
      "        58           0.1066          -0.0001           59.03s\n",
      "        59           0.1090           0.0000           57.34s\n",
      "        60           0.1090          -0.0002           55.60s\n",
      "        61           0.1051          -0.0000           53.89s\n",
      "        62           0.1074          -0.0025           52.25s\n",
      "        63           0.1060          -0.0003           50.65s\n",
      "        64           0.1063          -0.0001           49.14s\n",
      "        65           0.1042          -0.0001           47.69s\n",
      "        66           0.1054          -0.0001           46.11s\n",
      "        67           0.1022          -0.0002           44.52s\n",
      "        68           0.1048          -0.0001           42.97s\n",
      "        69           0.1008          -0.0002           41.41s\n",
      "        70           0.1050          -0.0001           40.07s\n",
      "        71           0.1064           0.0000           38.71s\n",
      "        72           0.1016          -0.0002           37.33s\n",
      "        73           0.0991          -0.0001           35.88s\n",
      "        74           0.0985          -0.0001           34.44s\n",
      "        75           0.0990          -0.0003           33.02s\n",
      "        76           0.0991          -0.0001           31.73s\n",
      "        77           0.1012          -0.0004           30.34s\n",
      "        78           0.1012          -0.0017           28.93s\n",
      "        79           0.1036          -0.0003           27.54s\n",
      "        80           0.0961          -0.0002           26.17s\n",
      "        81           0.1002          -0.0002           24.82s\n",
      "        82           0.0979          -0.0000           23.49s\n",
      "        83           0.0951          -0.0002           22.21s\n",
      "        84           0.0928          -0.0001           20.88s\n",
      "        85           0.1002          -0.0001           19.55s\n",
      "        86           0.0969          -0.0001           18.20s\n",
      "        87           0.0988          -0.0001           16.85s\n",
      "        88           0.0954          -0.0001           15.52s\n",
      "        89           0.0960           0.0000           14.20s\n",
      "        90           0.0946          -0.0001           12.90s\n",
      "        91           0.0905          -0.0010           11.63s\n",
      "        92           0.0924          -0.0001           10.32s\n",
      "        93           0.0943          -0.0001            9.01s\n",
      "        94           0.0953          -0.0001            7.71s\n",
      "        95           0.0963           0.0000            6.42s\n",
      "        96           0.0903          -0.0001            5.13s\n",
      "        97           0.0961          -0.0001            3.84s\n",
      "        98           0.0963          -0.0001            2.55s\n",
      "        99           0.0885          -0.0002            1.27s\n",
      "       100           0.0976          -0.0003            0.00s\n",
      "[CV] END classifier__max_depth=3, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 2.2min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1337           0.0012            1.21m\n",
      "         2           0.1318           0.0010            1.22m\n",
      "         3           0.1303           0.0010            1.22m\n",
      "         4           0.1226          -0.0007            1.25m\n",
      "         5           0.1306           0.0004            1.26m\n",
      "         6           0.1255           0.0002            1.26m\n",
      "         7           0.1270           0.0003            1.29m\n",
      "         8           0.1279           0.0005            1.25m\n",
      "         9           0.1296           0.0003            1.28m\n",
      "        10           0.1306          -0.0001            1.29m\n",
      "        11           0.1252          -0.0001            1.27m\n",
      "        12           0.1255           0.0001            1.25m\n",
      "        13           0.1220           0.0000            1.24m\n",
      "        14           0.1312           0.0001            1.23m\n",
      "        15           0.1253          -0.0001            1.21m\n",
      "        16           0.1273          -0.0000            1.17m\n",
      "        17           0.1291          -0.0001            1.15m\n",
      "        18           0.1238           0.0001            1.12m\n",
      "        19           0.1287          -0.0004            1.09m\n",
      "        20           0.1230          -0.0000            1.06m\n",
      "        21           0.1256          -0.0000            1.04m\n",
      "        22           0.1240          -0.0000            1.01m\n",
      "        23           0.1214          -0.0004           59.34s\n",
      "        24           0.1208          -0.0000           57.84s\n",
      "        25           0.1265          -0.0001           56.44s\n",
      "        26           0.1255          -0.0000           55.14s\n",
      "        27           0.1244          -0.0000           54.00s\n",
      "        28           0.1236          -0.0001           53.12s\n",
      "        29           0.1218           0.0002           52.40s\n",
      "        30           0.1208           0.0001           51.60s\n",
      "        31           0.1205          -0.0001           50.48s\n",
      "        32           0.1248          -0.0000           49.61s\n",
      "        33           0.1197          -0.0001           48.78s\n",
      "        34           0.1218          -0.0001           47.81s\n",
      "        35           0.1204          -0.0002           46.86s\n",
      "        36           0.1173          -0.0001           45.82s\n",
      "        37           0.1225           0.0000           44.90s\n",
      "        38           0.1172          -0.0001           44.05s\n",
      "        39           0.1170          -0.0001           43.31s\n",
      "        40           0.1232          -0.0001           42.66s\n",
      "        41           0.1271          -0.0001           42.00s\n",
      "        42           0.1259          -0.0000           41.43s\n",
      "        43           0.1220          -0.0001           40.86s\n",
      "        44           0.1166          -0.0000           40.16s\n",
      "        45           0.1236          -0.0000           39.42s\n",
      "        46           0.1213           0.0000           38.67s\n",
      "        47           0.1198          -0.0002           37.95s\n",
      "        48           0.1150          -0.0002           37.18s\n",
      "        49           0.1170          -0.0001           36.39s\n",
      "        50           0.1214          -0.0001           35.62s\n",
      "        51           0.1176          -0.0001           34.86s\n",
      "        52           0.1201          -0.0001           34.46s\n",
      "        53           0.1199          -0.0000           34.07s\n",
      "        54           0.1169          -0.0002           33.86s\n",
      "        55           0.1191          -0.0001           33.57s\n",
      "        56           0.1198          -0.0001           32.98s\n",
      "        57           0.1197          -0.0000           32.23s\n",
      "        58           0.1186          -0.0001           31.59s\n",
      "        59           0.1187          -0.0001           31.05s\n",
      "        60           0.1183          -0.0001           31.06s\n",
      "        61           0.1176          -0.0000           30.31s\n",
      "        62           0.1182          -0.0001           29.51s\n",
      "        63           0.1152          -0.0000           28.62s\n",
      "        64           0.1175          -0.0002           27.75s\n",
      "        65           0.1170          -0.0002           26.86s\n",
      "        66           0.1187          -0.0002           25.99s\n",
      "        67           0.1139          -0.0001           25.26s\n",
      "        68           0.1191          -0.0000           24.69s\n",
      "        69           0.1197          -0.0001           23.99s\n",
      "        70           0.1240          -0.0001           23.29s\n",
      "        71           0.1139          -0.0002           22.47s\n",
      "        72           0.1211          -0.0001           21.64s\n",
      "        73           0.1173          -0.0001           20.87s\n",
      "        74           0.1194          -0.0001           20.10s\n",
      "        75           0.1167          -0.0000           19.40s\n",
      "        76           0.1146          -0.0001           18.82s\n",
      "        77           0.1209          -0.0000           18.10s\n",
      "        78           0.1161          -0.0001           17.30s\n",
      "        79           0.1164          -0.0001           16.49s\n",
      "        80           0.1145          -0.0001           15.67s\n",
      "        81           0.1165          -0.0000           14.88s\n",
      "        82           0.1131          -0.0001           14.05s\n",
      "        83           0.1165          -0.0001           13.25s\n",
      "        84           0.1186          -0.0001           12.47s\n",
      "        85           0.1165          -0.0001           11.69s\n",
      "        86           0.1185          -0.0001           10.91s\n",
      "        87           0.1107          -0.0001           10.14s\n",
      "        88           0.1133          -0.0001            9.35s\n",
      "        89           0.1149          -0.0001            8.54s\n",
      "        90           0.1148          -0.0001            7.76s\n",
      "        91           0.1163          -0.0001            6.96s\n",
      "        92           0.1179          -0.0000            6.17s\n",
      "        93           0.1180          -0.0001            5.39s\n",
      "        94           0.1183          -0.0002            4.61s\n",
      "        95           0.1153          -0.0001            3.83s\n",
      "        96           0.1150           0.0000            3.06s\n",
      "        97           0.1110          -0.0003            2.29s\n",
      "        98           0.1202          -0.0000            1.52s\n",
      "        99           0.1208          -0.0001            0.76s\n",
      "       100           0.1157          -0.0005            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.3min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1298           0.0012            1.02m\n",
      "         2           0.1321           0.0010            1.01m\n",
      "         3           0.1352           0.0007            1.10m\n",
      "         4           0.1328           0.0003            1.13m\n",
      "         5           0.1282           0.0005            1.16m\n",
      "         6           0.1292          -0.0000            1.14m\n",
      "         7           0.1243           0.0004            1.18m\n",
      "         8           0.1334           0.0003            1.25m\n",
      "         9           0.1280           0.0001            1.29m\n",
      "        10           0.1241           0.0003            1.29m\n",
      "        11           0.1274           0.0001            1.29m\n",
      "        12           0.1281           0.0001            1.32m\n",
      "        13           0.1212          -0.0000            1.36m\n",
      "        14           0.1297          -0.0000            1.33m\n",
      "        15           0.1293          -0.0001            1.28m\n",
      "        16           0.1251           0.0000            1.25m\n",
      "        17           0.1278          -0.0001            1.22m\n",
      "        18           0.1191          -0.0001            1.18m\n",
      "        19           0.1298          -0.0002            1.17m\n",
      "        20           0.1225          -0.0001            1.16m\n",
      "        21           0.1266           0.0000            1.17m\n",
      "        22           0.1267           0.0000            1.15m\n",
      "        23           0.1222           0.0000            1.15m\n",
      "        24           0.1235           0.0000            1.15m\n",
      "        25           0.1253          -0.0000            1.15m\n",
      "        26           0.1258           0.0001            1.14m\n",
      "        27           0.1258           0.0001            1.14m\n",
      "        28           0.1194          -0.0002            1.12m\n",
      "        29           0.1249           0.0000            1.09m\n",
      "        30           0.1256          -0.0000            1.07m\n",
      "        31           0.1250          -0.0001            1.04m\n",
      "        32           0.1230          -0.0000            1.02m\n",
      "        33           0.1236          -0.0000            1.00m\n",
      "        34           0.1226          -0.0001           58.84s\n",
      "        35           0.1287          -0.0002           57.51s\n",
      "        36           0.1170          -0.0001           56.20s\n",
      "        37           0.1209          -0.0001           54.88s\n",
      "        38           0.1200          -0.0001           53.88s\n",
      "        39           0.1188          -0.0000           52.71s\n",
      "        40           0.1220          -0.0002           51.59s\n",
      "        41           0.1229           0.0000           50.38s\n",
      "        42           0.1209          -0.0001           49.09s\n",
      "        43           0.1234          -0.0001           47.88s\n",
      "        44           0.1254           0.0000           46.70s\n",
      "        45           0.1198          -0.0000           45.61s\n",
      "        46           0.1242          -0.0009           44.58s\n",
      "        47           0.1246          -0.0000           43.42s\n",
      "        48           0.1197           0.0000           42.34s\n",
      "        49           0.1222          -0.0001           41.32s\n",
      "        50           0.1210          -0.0001           40.30s\n",
      "        51           0.1248          -0.0000           39.45s\n",
      "        52           0.1226          -0.0000           38.78s\n",
      "        53           0.1192          -0.0008           38.05s\n",
      "        54           0.1260          -0.0000           37.40s\n",
      "        55           0.1214          -0.0000           36.69s\n",
      "        56           0.1216          -0.0001           35.80s\n",
      "        57           0.1230          -0.0000           34.87s\n",
      "        58           0.1198          -0.0000           33.96s\n",
      "        59           0.1191          -0.0000           33.17s\n",
      "        60           0.1238          -0.0000           32.22s\n",
      "        61           0.1243          -0.0001           31.44s\n",
      "        62           0.1262          -0.0001           30.58s\n",
      "        63           0.1140          -0.0001           29.62s\n",
      "        64           0.1175          -0.0001           28.72s\n",
      "        65           0.1223          -0.0000           27.81s\n",
      "        66           0.1224          -0.0000           26.89s\n",
      "        67           0.1218          -0.0001           26.01s\n",
      "        68           0.1204          -0.0001           25.23s\n",
      "        69           0.1171          -0.0001           24.47s\n",
      "        70           0.1206          -0.0000           23.73s\n",
      "        71           0.1207          -0.0001           23.01s\n",
      "        72           0.1187          -0.0001           22.16s\n",
      "        73           0.1196          -0.0001           21.32s\n",
      "        74           0.1232          -0.0001           20.48s\n",
      "        75           0.1192          -0.0001           19.63s\n",
      "        76           0.1218          -0.0000           18.87s\n",
      "        77           0.1196          -0.0000           18.07s\n",
      "        78           0.1253          -0.0002           17.22s\n",
      "        79           0.1173          -0.0001           16.39s\n",
      "        80           0.1207          -0.0000           15.55s\n",
      "        81           0.1212          -0.0001           14.71s\n",
      "        82           0.1160          -0.0001           13.89s\n",
      "        83           0.1187          -0.0000           13.08s\n",
      "        84           0.1188          -0.0001           12.26s\n",
      "        85           0.1183          -0.0001           11.47s\n",
      "        86           0.1139          -0.0002           10.67s\n",
      "        87           0.1163          -0.0001            9.88s\n",
      "        88           0.1222          -0.0000            9.09s\n",
      "        89           0.1158          -0.0000            8.30s\n",
      "        90           0.1199           0.0002            7.53s\n",
      "        91           0.1198          -0.0000            6.75s\n",
      "        92           0.1215          -0.0000            5.98s\n",
      "        93           0.1198          -0.0000            5.21s\n",
      "        94           0.1186          -0.0001            4.56s\n",
      "        95           0.1136          -0.0001            3.84s\n",
      "        96           0.1151          -0.0001            3.11s\n",
      "        97           0.1147          -0.0000            2.34s\n",
      "        98           0.1109          -0.0001            1.56s\n",
      "        99           0.1157          -0.0001            0.79s\n",
      "       100           0.1227          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1346           0.0009            1.06m\n",
      "         2           0.1311           0.0009            1.20m\n",
      "         3           0.1217          -0.0006            1.14m\n",
      "         4           0.1327           0.0006            1.11m\n",
      "         5           0.1308           0.0005            1.14m\n",
      "         6           0.1244           0.0004            1.14m\n",
      "         7           0.1282           0.0001            1.14m\n",
      "         8           0.1298           0.0002            1.17m\n",
      "         9           0.1295           0.0001            1.16m\n",
      "        10           0.1333           0.0001            1.15m\n",
      "        11           0.1226          -0.0001            1.14m\n",
      "        12           0.1276           0.0000            1.13m\n",
      "        13           0.1282          -0.0000            1.12m\n",
      "        14           0.1239           0.0001            1.10m\n",
      "        15           0.1294          -0.0000            1.10m\n",
      "        16           0.1294          -0.0000            1.09m\n",
      "        17           0.1273          -0.0001            1.10m\n",
      "        18           0.1257          -0.0000            1.09m\n",
      "        19           0.1327          -0.0000            1.10m\n",
      "        20           0.1236          -0.0001            1.09m\n",
      "        21           0.1262           0.0000            1.11m\n",
      "        22           0.1351          -0.0001            1.12m\n",
      "        23           0.1228          -0.0001            1.14m\n",
      "        24           0.1184          -0.0001            1.15m\n",
      "        25           0.1260          -0.0001            1.16m\n",
      "        26           0.1318          -0.0000            1.17m\n",
      "        27           0.1286          -0.0002            1.17m\n",
      "        28           0.1276          -0.0001            1.16m\n",
      "        29           0.1205          -0.0001            1.13m\n",
      "        30           0.1256          -0.0001            1.11m\n",
      "        31           0.1267          -0.0003            1.08m\n",
      "        32           0.1228          -0.0010            1.08m\n",
      "        33           0.1253          -0.0001            1.09m\n",
      "        34           0.1231          -0.0001            1.07m\n",
      "        35           0.1177          -0.0001            1.06m\n",
      "        36           0.1257           0.0000            1.06m\n",
      "        37           0.1248           0.0001            1.04m\n",
      "        38           0.1253          -0.0001            1.04m\n",
      "        39           0.1173          -0.0001            1.02m\n",
      "        40           0.1271          -0.0001            1.00m\n",
      "        41           0.1257          -0.0001           59.20s\n",
      "        42           0.1237          -0.0000           58.71s\n",
      "        43           0.1222          -0.0001           58.30s\n",
      "        44           0.1236          -0.0001           57.38s\n",
      "        45           0.1216          -0.0001           57.31s\n",
      "        46           0.1218          -0.0001           56.74s\n",
      "        47           0.1240          -0.0001           56.37s\n",
      "        48           0.1263          -0.0001           55.91s\n",
      "        49           0.1236          -0.0001           55.16s\n",
      "        50           0.1202          -0.0000           54.09s\n",
      "        51           0.1201          -0.0001           53.05s\n",
      "        52           0.1245          -0.0000           51.92s\n",
      "        53           0.1199          -0.0001           51.14s\n",
      "        54           0.1189          -0.0001           50.35s\n",
      "        55           0.1208          -0.0002           49.60s\n",
      "        56           0.1241          -0.0001           48.47s\n",
      "        57           0.1185          -0.0000           47.17s\n",
      "        58           0.1224          -0.0000           45.89s\n",
      "        59           0.1171          -0.0002           44.69s\n",
      "        60           0.1213          -0.0001           43.49s\n",
      "        61           0.1209          -0.0001           42.31s\n",
      "        62           0.1220           0.0001           41.04s\n",
      "        63           0.1150          -0.0001           39.72s\n",
      "        64           0.1237          -0.0001           38.42s\n",
      "        65           0.1227          -0.0001           37.12s\n",
      "        66           0.1189          -0.0000           35.89s\n",
      "        67           0.1239          -0.0001           34.65s\n",
      "        68           0.1170          -0.0001           33.41s\n",
      "        69           0.1201          -0.0002           32.22s\n",
      "        70           0.1185          -0.0001           31.04s\n",
      "        71           0.1205          -0.0001           29.85s\n",
      "        72           0.1191          -0.0001           28.68s\n",
      "        73           0.1141          -0.0001           27.55s\n",
      "        74           0.1199          -0.0000           26.42s\n",
      "        75           0.1210          -0.0000           25.29s\n",
      "        76           0.1210          -0.0001           24.19s\n",
      "        77           0.1221          -0.0001           23.07s\n",
      "        78           0.1177          -0.0001           22.03s\n",
      "        79           0.1161          -0.0001           21.02s\n",
      "        80           0.1214          -0.0001           19.95s\n",
      "        81           0.1197          -0.0000           18.88s\n",
      "        82           0.1195          -0.0000           17.84s\n",
      "        83           0.1175          -0.0001           16.79s\n",
      "        84           0.1174          -0.0002           15.79s\n",
      "        85           0.1197          -0.0001           14.83s\n",
      "        86           0.1245           0.0000           13.90s\n",
      "        87           0.1208          -0.0000           12.89s\n",
      "        88           0.1146          -0.0001           11.91s\n",
      "        89           0.1139          -0.0001           10.91s\n",
      "        90           0.1133          -0.0001            9.93s\n",
      "        91           0.1156          -0.0001            8.97s\n",
      "        92           0.1139          -0.0001            7.98s\n",
      "        93           0.1176          -0.0001            6.99s\n",
      "        94           0.1157          -0.0001            5.99s\n",
      "        95           0.1158          -0.0001            5.00s\n",
      "        96           0.1150          -0.0001            4.01s\n",
      "        97           0.1154          -0.0001            3.01s\n",
      "        98           0.1187          -0.0001            2.01s\n",
      "        99           0.1122          -0.0001            1.00s\n",
      "       100           0.1185          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.8min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1328           0.0006            1.34m\n",
      "         2           0.1290           0.0008            1.23m\n",
      "         3           0.1346           0.0005            1.14m\n",
      "         4           0.1322           0.0007            1.15m\n",
      "         5           0.1274           0.0002            1.15m\n",
      "         6           0.1318           0.0004            1.11m\n",
      "         7           0.1249           0.0003            1.09m\n",
      "         8           0.1290           0.0001            1.10m\n",
      "         9           0.1270           0.0003            1.12m\n",
      "        10           0.1241           0.0003            1.10m\n",
      "        11           0.1285           0.0000            1.07m\n",
      "        12           0.1263           0.0001            1.04m\n",
      "        13           0.1237           0.0001            1.01m\n",
      "        14           0.1229           0.0000           58.94s\n",
      "        15           0.1234          -0.0001           57.44s\n",
      "        16           0.1307          -0.0001           55.84s\n",
      "        17           0.1200          -0.0001           54.71s\n",
      "        18           0.1296          -0.0001           53.97s\n",
      "        19           0.1237          -0.0005           52.71s\n",
      "        20           0.1250          -0.0001           51.63s\n",
      "        21           0.1258          -0.0000           50.77s\n",
      "        22           0.1264          -0.0001           49.90s\n",
      "        23           0.1212          -0.0001           48.87s\n",
      "        24           0.1247          -0.0001           48.33s\n",
      "        25           0.1252           0.0000           47.99s\n",
      "        26           0.1229          -0.0001           47.49s\n",
      "        27           0.1177          -0.0001           46.66s\n",
      "        28           0.1246          -0.0001           45.76s\n",
      "        29           0.1248          -0.0002           45.01s\n",
      "        30           0.1223           0.0000           44.09s\n",
      "        31           0.1239          -0.0001           43.38s\n",
      "        32           0.1210          -0.0001           42.63s\n",
      "        33           0.1202          -0.0001           41.82s\n",
      "        34           0.1225          -0.0000           41.04s\n",
      "        35           0.1212          -0.0001           40.33s\n",
      "        36           0.1168          -0.0001           39.56s\n",
      "        37           0.1273           0.0000           39.01s\n",
      "        38           0.1237          -0.0000           38.46s\n",
      "        39           0.1252          -0.0001           37.83s\n",
      "        40           0.1180          -0.0001           37.20s\n",
      "        41           0.1163          -0.0001           36.53s\n",
      "        42           0.1248          -0.0000           35.84s\n",
      "        43           0.1174          -0.0001           35.14s\n",
      "        44           0.1240          -0.0002           34.48s\n",
      "        45           0.1211          -0.0002           33.92s\n",
      "        46           0.1244          -0.0001           33.22s\n",
      "        47           0.1233          -0.0001           32.58s\n",
      "        48           0.1193          -0.0001           31.97s\n",
      "        49           0.1222          -0.0001           31.31s\n",
      "        50           0.1253          -0.0001           30.66s\n",
      "        51           0.1194          -0.0000           29.98s\n",
      "        52           0.1162          -0.0000           29.34s\n",
      "        53           0.1190          -0.0001           28.71s\n",
      "        54           0.1232          -0.0001           28.02s\n",
      "        55           0.1144          -0.0001           27.36s\n",
      "        56           0.1199          -0.0001           26.72s\n",
      "        57           0.1161          -0.0001           26.07s\n",
      "        58           0.1235          -0.0001           25.39s\n",
      "        59           0.1207          -0.0001           24.75s\n",
      "        60           0.1241          -0.0001           24.10s\n",
      "        61           0.1134          -0.0001           23.45s\n",
      "        62           0.1190          -0.0001           22.82s\n",
      "        63           0.1180          -0.0000           22.17s\n",
      "        64           0.1145          -0.0000           21.51s\n",
      "        65           0.1177          -0.0001           20.92s\n",
      "        66           0.1181          -0.0001           20.31s\n",
      "        67           0.1190          -0.0002           19.69s\n",
      "        68           0.1157          -0.0001           19.07s\n",
      "        69           0.1155          -0.0000           18.44s\n",
      "        70           0.1176          -0.0001           17.83s\n",
      "        71           0.1146          -0.0001           17.20s\n",
      "        72           0.1201          -0.0001           16.57s\n",
      "        73           0.1173          -0.0001           15.97s\n",
      "        74           0.1179          -0.0002           15.38s\n",
      "        75           0.1205          -0.0000           14.76s\n",
      "        76           0.1186          -0.0001           14.15s\n",
      "        77           0.1152          -0.0001           13.55s\n",
      "        78           0.1174          -0.0001           12.94s\n",
      "        79           0.1156          -0.0001           12.35s\n",
      "        80           0.1142          -0.0001           11.74s\n",
      "        81           0.1198          -0.0001           11.15s\n",
      "        82           0.1106          -0.0002           10.56s\n",
      "        83           0.1129          -0.0001            9.95s\n",
      "        84           0.1170          -0.0001            9.37s\n",
      "        85           0.1195          -0.0001            8.78s\n",
      "        86           0.1170          -0.0001            8.18s\n",
      "        87           0.1159          -0.0001            7.60s\n",
      "        88           0.1154          -0.0001            7.01s\n",
      "        89           0.1122           0.0000            6.42s\n",
      "        90           0.1153          -0.0001            5.85s\n",
      "        91           0.1150          -0.0001            5.25s\n",
      "        92           0.1111          -0.0002            4.67s\n",
      "        93           0.1117          -0.0002            4.08s\n",
      "        94           0.1180          -0.0001            3.49s\n",
      "        95           0.1202          -0.0003            2.91s\n",
      "        96           0.1169          -0.0001            2.32s\n",
      "        97           0.1130          -0.0001            1.74s\n",
      "        98           0.1128          -0.0001            1.16s\n",
      "        99           0.1126          -0.0002            0.58s\n",
      "       100           0.1135          -0.0000            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.0min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1297           0.0011           56.51s\n",
      "         2           0.1295           0.0009           55.64s\n",
      "         3           0.1304           0.0008           54.62s\n",
      "         4           0.1259           0.0005           55.55s\n",
      "         5           0.1314           0.0003           57.29s\n",
      "         6           0.1339           0.0001           58.27s\n",
      "         7           0.1277           0.0003           59.23s\n",
      "         8           0.1293          -0.0001           58.16s\n",
      "         9           0.1246           0.0002           56.61s\n",
      "        10           0.1304           0.0000           55.43s\n",
      "        11           0.1268          -0.0002           54.29s\n",
      "        12           0.1302           0.0001           52.92s\n",
      "        13           0.1233          -0.0001           52.04s\n",
      "        14           0.1293          -0.0000           50.88s\n",
      "        15           0.1248           0.0000           50.07s\n",
      "        16           0.1335          -0.0000           49.60s\n",
      "        17           0.1286           0.0001           48.46s\n",
      "        18           0.1217          -0.0001           47.73s\n",
      "        19           0.1274          -0.0001           47.10s\n",
      "        20           0.1313           0.0000           46.44s\n",
      "        21           0.1248          -0.0001           45.73s\n",
      "        22           0.1290          -0.0000           45.19s\n",
      "        23           0.1283          -0.0000           44.65s\n",
      "        24           0.1254           0.0000           44.10s\n",
      "        25           0.1304          -0.0000           43.38s\n",
      "        26           0.1243          -0.0001           42.77s\n",
      "        27           0.1204          -0.0000           42.37s\n",
      "        28           0.1187          -0.0001           41.66s\n",
      "        29           0.1254          -0.0001           41.13s\n",
      "        30           0.1236          -0.0002           40.43s\n",
      "        31           0.1255          -0.0001           39.90s\n",
      "        32           0.1267          -0.0000           39.35s\n",
      "        33           0.1233          -0.0001           38.67s\n",
      "        34           0.1208          -0.0000           38.15s\n",
      "        35           0.1278          -0.0001           37.66s\n",
      "        36           0.1237          -0.0001           37.12s\n",
      "        37           0.1235          -0.0001           36.54s\n",
      "        38           0.1224          -0.0001           35.93s\n",
      "        39           0.1218          -0.0000           35.44s\n",
      "        40           0.1211          -0.0001           34.84s\n",
      "        41           0.1191          -0.0001           34.15s\n",
      "        42           0.1230          -0.0002           33.50s\n",
      "        43           0.1200          -0.0001           32.93s\n",
      "        44           0.1235          -0.0002           32.27s\n",
      "        45           0.1240          -0.0000           31.62s\n",
      "        46           0.1181          -0.0001           31.00s\n",
      "        47           0.1177          -0.0001           30.36s\n",
      "        48           0.1179          -0.0000           29.74s\n",
      "        49           0.1215          -0.0001           29.11s\n",
      "        50           0.1211          -0.0001           28.50s\n",
      "        51           0.1190          -0.0001           27.85s\n",
      "        52           0.1176          -0.0001           27.26s\n",
      "        53           0.1197          -0.0001           26.69s\n",
      "        54           0.1178          -0.0001           26.10s\n",
      "        55           0.1216          -0.0010           25.44s\n",
      "        56           0.1204          -0.0000           24.85s\n",
      "        57           0.1155          -0.0000           24.27s\n",
      "        58           0.1208           0.0000           23.63s\n",
      "        59           0.1207          -0.0000           23.07s\n",
      "        60           0.1203          -0.0001           22.55s\n",
      "        61           0.1220          -0.0001           22.13s\n",
      "        62           0.1268          -0.0001           21.87s\n",
      "        63           0.1235          -0.0001           21.45s\n",
      "        64           0.1196          -0.0001           21.03s\n",
      "        65           0.1204          -0.0001           20.62s\n",
      "        66           0.1187          -0.0001           20.53s\n",
      "        67           0.1171           0.0000           20.23s\n",
      "        68           0.1208          -0.0001           19.75s\n",
      "        69           0.1161          -0.0001           19.26s\n",
      "        70           0.1189          -0.0002           18.67s\n",
      "        71           0.1181          -0.0000           18.16s\n",
      "        72           0.1181          -0.0001           17.62s\n",
      "        73           0.1164          -0.0002           17.08s\n",
      "        74           0.1205          -0.0001           16.55s\n",
      "        75           0.1143          -0.0001           16.28s\n",
      "        76           0.1176          -0.0000           15.76s\n",
      "        77           0.1162          -0.0001           15.23s\n",
      "        78           0.1118          -0.0001           14.68s\n",
      "        79           0.1170          -0.0000           14.15s\n",
      "        80           0.1154          -0.0001           13.62s\n",
      "        81           0.1172          -0.0001           13.04s\n",
      "        82           0.1171          -0.0000           12.38s\n",
      "        83           0.1159           0.0000           11.81s\n",
      "        84           0.1145          -0.0001           11.21s\n",
      "        85           0.1174          -0.0000           10.53s\n",
      "        86           0.1146          -0.0001            9.83s\n",
      "        87           0.1201          -0.0002            9.12s\n",
      "        88           0.1141          -0.0001            8.41s\n",
      "        89           0.1130          -0.0003            7.70s\n",
      "        90           0.1216          -0.0001            7.00s\n",
      "        91           0.1122          -0.0002            6.29s\n",
      "        92           0.1142          -0.0001            5.59s\n",
      "        93           0.1186          -0.0000            4.90s\n",
      "        94           0.1148          -0.0001            4.21s\n",
      "        95           0.1179          -0.0001            3.54s\n",
      "        96           0.1136          -0.0001            2.85s\n",
      "        97           0.1152          -0.0001            2.14s\n",
      "        98           0.1130          -0.0001            1.43s\n",
      "        99           0.1141          -0.0000            0.71s\n",
      "       100           0.1154          -0.0000            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=4, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.2min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1305          -0.0001            2.18m\n",
      "         2           0.1305           0.0012            2.13m\n",
      "         3           0.1293           0.0003            2.12m\n",
      "         4           0.1276           0.0009            2.02m\n",
      "         5           0.1268           0.0005            2.08m\n",
      "         6           0.1277           0.0004            2.09m\n",
      "         7           0.1281           0.0004            2.11m\n",
      "         8           0.1293           0.0001            2.01m\n",
      "         9           0.1269           0.0000            1.93m\n",
      "        10           0.1245          -0.0011            1.82m\n",
      "        11           0.1298           0.0001            1.74m\n",
      "        12           0.1260           0.0002            1.66m\n",
      "        13           0.1256          -0.0000            1.59m\n",
      "        14           0.1257          -0.0000            1.52m\n",
      "        15           0.1233           0.0001            1.47m\n",
      "        16           0.1327          -0.0001            1.42m\n",
      "        17           0.1329          -0.0001            1.37m\n",
      "        18           0.1314           0.0001            1.33m\n",
      "        19           0.1270           0.0002            1.28m\n",
      "        20           0.1254          -0.0001            1.26m\n",
      "        21           0.1245           0.0000            1.24m\n",
      "        22           0.1297          -0.0000            1.22m\n",
      "        23           0.1216           0.0000            1.19m\n",
      "        24           0.1248          -0.0000            1.16m\n",
      "        25           0.1231          -0.0000            1.13m\n",
      "        26           0.1293           0.0001            1.12m\n",
      "        27           0.1255           0.0000            1.12m\n",
      "        28           0.1294          -0.0001            1.10m\n",
      "        29           0.1265          -0.0001            1.07m\n",
      "        30           0.1226          -0.0001            1.05m\n",
      "        31           0.1224          -0.0001            1.03m\n",
      "        32           0.1249          -0.0000            1.01m\n",
      "        33           0.1248          -0.0001           59.47s\n",
      "        34           0.1261          -0.0001           58.39s\n",
      "        35           0.1211          -0.0001           57.32s\n",
      "        36           0.1233          -0.0001           56.01s\n",
      "        37           0.1228          -0.0001           54.74s\n",
      "        38           0.1255          -0.0001           53.37s\n",
      "        39           0.1225           0.0000           52.20s\n",
      "        40           0.1285           0.0000           51.00s\n",
      "        41           0.1228          -0.0000           49.69s\n",
      "        42           0.1243          -0.0000           48.58s\n",
      "        43           0.1237          -0.0000           47.42s\n",
      "        44           0.1203          -0.0001           46.31s\n",
      "        45           0.1226          -0.0001           45.36s\n",
      "        46           0.1205          -0.0001           44.21s\n",
      "        47           0.1154          -0.0001           43.13s\n",
      "        48           0.1238          -0.0002           42.15s\n",
      "        49           0.1215          -0.0001           41.08s\n",
      "        50           0.1207          -0.0000           40.09s\n",
      "        51           0.1251          -0.0001           39.12s\n",
      "        52           0.1204          -0.0000           38.11s\n",
      "        53           0.1232          -0.0001           37.19s\n",
      "        54           0.1173          -0.0001           36.24s\n",
      "        55           0.1185          -0.0001           35.23s\n",
      "        56           0.1200          -0.0001           34.34s\n",
      "        57           0.1214          -0.0001           33.40s\n",
      "        58           0.1169          -0.0001           32.41s\n",
      "        59           0.1207          -0.0000           31.55s\n",
      "        60           0.1180          -0.0001           30.62s\n",
      "        61           0.1214          -0.0001           29.70s\n",
      "        62           0.1194          -0.0000           28.87s\n",
      "        63           0.1244          -0.0001           27.98s\n",
      "        64           0.1149          -0.0001           27.12s\n",
      "        65           0.1201          -0.0001           26.30s\n",
      "        66           0.1181          -0.0001           25.45s\n",
      "        67           0.1189          -0.0001           24.61s\n",
      "        68           0.1206          -0.0002           23.87s\n",
      "        69           0.1240          -0.0001           23.04s\n",
      "        70           0.1215          -0.0002           22.26s\n",
      "        71           0.1209          -0.0001           21.47s\n",
      "        72           0.1181          -0.0001           20.66s\n",
      "        73           0.1185          -0.0001           19.89s\n",
      "        74           0.1164          -0.0001           19.09s\n",
      "        75           0.1174          -0.0001           18.31s\n",
      "        76           0.1190          -0.0000           17.56s\n",
      "        77           0.1202          -0.0001           16.77s\n",
      "        78           0.1195          -0.0000           16.01s\n",
      "        79           0.1204          -0.0001           15.25s\n",
      "        80           0.1182          -0.0001           14.49s\n",
      "        81           0.1191          -0.0001           13.74s\n",
      "        82           0.1124          -0.0001           12.99s\n",
      "        83           0.1155          -0.0001           12.24s\n",
      "        84           0.1206          -0.0001           11.50s\n",
      "        85           0.1202          -0.0001           10.74s\n",
      "        86           0.1169          -0.0001           10.02s\n",
      "        87           0.1204          -0.0001            9.29s\n",
      "        88           0.1145          -0.0001            8.55s\n",
      "        89           0.1158          -0.0000            7.83s\n",
      "        90           0.1139          -0.0001            7.10s\n",
      "        91           0.1166          -0.0000            6.37s\n",
      "        92           0.1197          -0.0001            5.66s\n",
      "        93           0.1150          -0.0001            4.94s\n",
      "        94           0.1204          -0.0001            4.22s\n",
      "        95           0.1144          -0.0001            3.51s\n",
      "        96           0.1139          -0.0001            2.80s\n",
      "        97           0.1165          -0.0000            2.10s\n",
      "        98           0.1190          -0.0001            1.40s\n",
      "        99           0.1188          -0.0001            0.70s\n",
      "       100           0.1176          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.2min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1317           0.0012            1.12m\n",
      "         2           0.1332           0.0010            1.01m\n",
      "         3           0.1314          -0.0006           58.55s\n",
      "         4           0.1293           0.0001            1.01m\n",
      "         5           0.1244           0.0003           58.05s\n",
      "         6           0.1288           0.0005           57.13s\n",
      "         7           0.1343           0.0003           57.07s\n",
      "         8           0.1297           0.0003           56.35s\n",
      "         9           0.1299           0.0000           57.11s\n",
      "        10           0.1297           0.0003           57.19s\n",
      "        11           0.1241          -0.0001           56.83s\n",
      "        12           0.1209           0.0001           56.38s\n",
      "        13           0.1218          -0.0001           55.08s\n",
      "        14           0.1269           0.0001           53.97s\n",
      "        15           0.1278           0.0000           53.30s\n",
      "        16           0.1317          -0.0001           52.00s\n",
      "        17           0.1188          -0.0002           50.96s\n",
      "        18           0.1240           0.0000           51.54s\n",
      "        19           0.1295           0.0000           50.74s\n",
      "        20           0.1284          -0.0001           49.87s\n",
      "        21           0.1241          -0.0000           49.19s\n",
      "        22           0.1200          -0.0001           48.21s\n",
      "        23           0.1215           0.0001           47.54s\n",
      "        24           0.1235          -0.0001           46.90s\n",
      "        25           0.1300          -0.0001           46.12s\n",
      "        26           0.1233          -0.0001           45.64s\n",
      "        27           0.1180          -0.0001           44.79s\n",
      "        28           0.1239          -0.0001           43.92s\n",
      "        29           0.1200          -0.0000           43.45s\n",
      "        30           0.1200           0.0002           42.70s\n",
      "        31           0.1292          -0.0001           42.32s\n",
      "        32           0.1196          -0.0001           42.05s\n",
      "        33           0.1256           0.0001           41.87s\n",
      "        34           0.1219          -0.0001           41.31s\n",
      "        35           0.1238           0.0000           40.68s\n",
      "        36           0.1217          -0.0001           40.08s\n",
      "        37           0.1172          -0.0000           39.55s\n",
      "        38           0.1239           0.0000           39.14s\n",
      "        39           0.1193          -0.0001           38.79s\n",
      "        40           0.1268          -0.0001           38.56s\n",
      "        41           0.1184          -0.0001           38.03s\n",
      "        42           0.1254          -0.0001           37.55s\n",
      "        43           0.1234           0.0000           37.05s\n",
      "        44           0.1236          -0.0001           36.38s\n",
      "        45           0.1188           0.0000           35.78s\n",
      "        46           0.1163          -0.0002           35.06s\n",
      "        47           0.1211          -0.0001           34.70s\n",
      "        48           0.1253           0.0000           34.11s\n",
      "        49           0.1170          -0.0000           33.44s\n",
      "        50           0.1229          -0.0001           32.90s\n",
      "        51           0.1193          -0.0000           32.25s\n",
      "        52           0.1158          -0.0000           31.67s\n",
      "        53           0.1233          -0.0001           30.99s\n",
      "        54           0.1132          -0.0000           30.32s\n",
      "        55           0.1201          -0.0001           29.78s\n",
      "        56           0.1164          -0.0001           29.07s\n",
      "        57           0.1141          -0.0001           28.41s\n",
      "        58           0.1223          -0.0000           27.87s\n",
      "        59           0.1244          -0.0001           27.57s\n",
      "        60           0.1188          -0.0000           27.03s\n",
      "        61           0.1171          -0.0000           26.50s\n",
      "        62           0.1191          -0.0001           25.87s\n",
      "        63           0.1193          -0.0001           25.34s\n",
      "        64           0.1165          -0.0001           24.75s\n",
      "        65           0.1173          -0.0006           24.16s\n",
      "        66           0.1164          -0.0001           23.48s\n",
      "        67           0.1223          -0.0001           22.77s\n",
      "        68           0.1138          -0.0001           22.09s\n",
      "        69           0.1200          -0.0001           21.38s\n",
      "        70           0.1173          -0.0001           20.72s\n",
      "        71           0.1226          -0.0002           20.15s\n",
      "        72           0.1196          -0.0002           19.84s\n",
      "        73           0.1171          -0.0001           19.27s\n",
      "        74           0.1157          -0.0001           18.57s\n",
      "        75           0.1126          -0.0001           17.93s\n",
      "        76           0.1184          -0.0001           17.41s\n",
      "        77           0.1143          -0.0000           16.90s\n",
      "        78           0.1172          -0.0001           16.43s\n",
      "        79           0.1181          -0.0000           15.85s\n",
      "        80           0.1193           0.0000           15.26s\n",
      "        81           0.1144          -0.0001           14.68s\n",
      "        82           0.1177          -0.0001           14.06s\n",
      "        83           0.1151          -0.0001           13.39s\n",
      "        84           0.1111          -0.0001           12.72s\n",
      "        85           0.1161           0.0000           12.04s\n",
      "        86           0.1142          -0.0002           11.33s\n",
      "        87           0.1173          -0.0000           10.72s\n",
      "        88           0.1131          -0.0001           10.00s\n",
      "        89           0.1171          -0.0001            9.27s\n",
      "        90           0.1145          -0.0001            8.52s\n",
      "        91           0.1133          -0.0000            7.73s\n",
      "        92           0.1121          -0.0000            6.95s\n",
      "        93           0.1161          -0.0001            6.12s\n",
      "        94           0.1154          -0.0001            5.29s\n",
      "        95           0.1158          -0.0001            4.43s\n",
      "        96           0.1152          -0.0001            3.55s\n",
      "        97           0.1174          -0.0002            2.67s\n",
      "        98           0.1152          -0.0001            1.79s\n",
      "        99           0.1155          -0.0002            0.90s\n",
      "       100           0.1093          -0.0002            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.6min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1302           0.0010            2.11m\n",
      "         2           0.1314           0.0007            2.12m\n",
      "         3           0.1299           0.0004            2.08m\n",
      "         4           0.1303           0.0005            2.16m\n",
      "         5           0.1275           0.0005            2.17m\n",
      "         6           0.1308           0.0002            2.19m\n",
      "         7           0.1276           0.0002            2.15m\n",
      "         8           0.1285           0.0003            2.12m\n",
      "         9           0.1277           0.0002            2.08m\n",
      "        10           0.1300           0.0000            2.09m\n",
      "        11           0.1272          -0.0001            2.09m\n",
      "        12           0.1280           0.0000            2.07m\n",
      "        13           0.1255          -0.0000            2.05m\n",
      "        14           0.1296          -0.0001            2.01m\n",
      "        15           0.1267           0.0001            1.99m\n",
      "        16           0.1254          -0.0001            1.96m\n",
      "        17           0.1279           0.0002            1.92m\n",
      "        18           0.1245          -0.0007            1.90m\n",
      "        19           0.1275          -0.0001            1.86m\n",
      "        20           0.1264           0.0000            1.85m\n",
      "        21           0.1268          -0.0001            1.81m\n",
      "        22           0.1274          -0.0000            1.78m\n",
      "        23           0.1242          -0.0001            1.75m\n",
      "        24           0.1258          -0.0001            1.73m\n",
      "        25           0.1233          -0.0001            1.71m\n",
      "        26           0.1238          -0.0001            1.69m\n",
      "        27           0.1236          -0.0000            1.67m\n",
      "        28           0.1255          -0.0000            1.64m\n",
      "        29           0.1208          -0.0001            1.62m\n",
      "        30           0.1223          -0.0001            1.59m\n",
      "        31           0.1300          -0.0002            1.58m\n",
      "        32           0.1243          -0.0001            1.57m\n",
      "        33           0.1242          -0.0001            1.55m\n",
      "        34           0.1195          -0.0001            1.53m\n",
      "        35           0.1188          -0.0004            1.51m\n",
      "        36           0.1249          -0.0001            1.49m\n",
      "        37           0.1214          -0.0000            1.46m\n",
      "        38           0.1255          -0.0000            1.44m\n",
      "        39           0.1217          -0.0001            1.42m\n",
      "        40           0.1243           0.0000            1.39m\n",
      "        41           0.1257          -0.0001            1.37m\n",
      "        42           0.1210          -0.0000            1.34m\n",
      "        43           0.1224          -0.0002            1.32m\n",
      "        44           0.1206          -0.0001            1.30m\n",
      "        45           0.1141          -0.0002            1.28m\n",
      "        46           0.1228           0.0000            1.25m\n",
      "        47           0.1182           0.0002            1.23m\n",
      "        48           0.1204          -0.0001            1.21m\n",
      "        49           0.1238          -0.0000            1.19m\n",
      "        50           0.1239          -0.0001            1.17m\n",
      "        51           0.1184          -0.0001            1.14m\n",
      "        52           0.1209          -0.0002            1.12m\n",
      "        53           0.1214          -0.0000            1.09m\n",
      "        54           0.1199          -0.0000            1.07m\n",
      "        55           0.1157          -0.0001            1.04m\n",
      "        56           0.1208          -0.0002            1.02m\n",
      "        57           0.1170          -0.0001            1.00m\n",
      "        58           0.1169          -0.0001           58.60s\n",
      "        59           0.1195          -0.0001           57.08s\n",
      "        60           0.1183          -0.0002           55.81s\n",
      "        61           0.1166          -0.0000           54.46s\n",
      "        62           0.1188           0.0000           53.05s\n",
      "        63           0.1160          -0.0001           51.60s\n",
      "        64           0.1168          -0.0001           50.12s\n",
      "        65           0.1195          -0.0001           48.65s\n",
      "        66           0.1189          -0.0002           47.23s\n",
      "        67           0.1211           0.0000           45.90s\n",
      "        68           0.1214          -0.0001           44.48s\n",
      "        69           0.1200          -0.0002           43.04s\n",
      "        70           0.1232          -0.0001           41.62s\n",
      "        71           0.1173          -0.0000           40.14s\n",
      "        72           0.1197          -0.0000           38.66s\n",
      "        73           0.1214          -0.0002           37.21s\n",
      "        74           0.1160          -0.0001           35.85s\n",
      "        75           0.1172          -0.0001           34.43s\n",
      "        76           0.1207          -0.0001           33.04s\n",
      "        77           0.1185          -0.0000           31.59s\n",
      "        78           0.1185          -0.0006           30.35s\n",
      "        79           0.1199          -0.0001           28.91s\n",
      "        80           0.1178          -0.0002           27.57s\n",
      "        81           0.1172          -0.0001           26.19s\n",
      "        82           0.1182          -0.0001           24.79s\n",
      "        83           0.1202           0.0001           23.39s\n",
      "        84           0.1127          -0.0001           22.01s\n",
      "        85           0.1179          -0.0001           20.63s\n",
      "        86           0.1190          -0.0001           19.28s\n",
      "        87           0.1194          -0.0001           17.91s\n",
      "        88           0.1162          -0.0001           16.52s\n",
      "        89           0.1191          -0.0001           15.12s\n",
      "        90           0.1132          -0.0001           13.74s\n",
      "        91           0.1198          -0.0001           12.35s\n",
      "        92           0.1149          -0.0001           10.99s\n",
      "        93           0.1146          -0.0002            9.63s\n",
      "        94           0.1132          -0.0001            8.26s\n",
      "        95           0.1127          -0.0002            6.87s\n",
      "        96           0.1162          -0.0000            5.49s\n",
      "        97           0.1094          -0.0001            4.11s\n",
      "        98           0.1127          -0.0001            2.74s\n",
      "        99           0.1094          -0.0002            1.37s\n",
      "       100           0.1169          -0.0000            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 2.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1331           0.0007            2.12m\n",
      "         2           0.1294           0.0011            2.10m\n",
      "         3           0.1321           0.0007            2.04m\n",
      "         4           0.1340           0.0002            2.06m\n",
      "         5           0.1324           0.0005            2.10m\n",
      "         6           0.1235           0.0003            2.52m\n",
      "         7           0.1296          -0.0002            2.66m\n",
      "         8           0.1281           0.0004            2.58m\n",
      "         9           0.1298           0.0001            2.53m\n",
      "        10           0.1290          -0.0001            2.43m\n",
      "        11           0.1235           0.0002            2.34m\n",
      "        12           0.1252          -0.0001            2.33m\n",
      "        13           0.1230           0.0000            2.30m\n",
      "        14           0.1266          -0.0000            2.27m\n",
      "        15           0.1253           0.0000            2.22m\n",
      "        16           0.1231          -0.0000            2.18m\n",
      "        17           0.1272           0.0001            2.14m\n",
      "        18           0.1212          -0.0001            2.10m\n",
      "        19           0.1192          -0.0001            2.05m\n",
      "        20           0.1282          -0.0002            2.02m\n",
      "        21           0.1264          -0.0001            1.98m\n",
      "        22           0.1239          -0.0000            1.95m\n",
      "        23           0.1293          -0.0000            1.92m\n",
      "        24           0.1251          -0.0001            1.88m\n",
      "        25           0.1220          -0.0060            1.86m\n",
      "        26           0.1267          -0.0001            1.84m\n",
      "        27           0.1231          -0.0001            1.81m\n",
      "        28           0.1241          -0.0001            1.79m\n",
      "        29           0.1234          -0.0001            1.76m\n",
      "        30           0.1239          -0.0000            1.73m\n",
      "        31           0.1200          -0.0000            1.71m\n",
      "        32           0.1288          -0.0002            1.68m\n",
      "        33           0.1265          -0.0001            1.66m\n",
      "        34           0.1240          -0.0000            1.63m\n",
      "        35           0.1248          -0.0000            1.63m\n",
      "        36           0.1229          -0.0002            1.61m\n",
      "        37           0.1236          -0.0002            1.58m\n",
      "        38           0.1211          -0.0001            1.54m\n",
      "        39           0.1238          -0.0002            1.52m\n",
      "        40           0.1207          -0.0001            1.50m\n",
      "        41           0.1239          -0.0001            1.48m\n",
      "        42           0.1231          -0.0000            1.46m\n",
      "        43           0.1190          -0.0001            1.43m\n",
      "        44           0.1231          -0.0000            1.41m\n",
      "        45           0.1233          -0.0001            1.38m\n",
      "        46           0.1236          -0.0002            1.36m\n",
      "        47           0.1166          -0.0001            1.33m\n",
      "        48           0.1201          -0.0000            1.31m\n",
      "        49           0.1272          -0.0000            1.29m\n",
      "        50           0.1226          -0.0000            1.27m\n",
      "        51           0.1189          -0.0001            1.24m\n",
      "        52           0.1212          -0.0001            1.21m\n",
      "        53           0.1248          -0.0001            1.18m\n",
      "        54           0.1211           0.0000            1.15m\n",
      "        55           0.1165          -0.0001            1.12m\n",
      "        56           0.1147          -0.0001            1.10m\n",
      "        57           0.1181          -0.0000            1.07m\n",
      "        58           0.1179          -0.0001            1.04m\n",
      "        59           0.1170          -0.0002            1.02m\n",
      "        60           0.1205          -0.0001           59.21s\n",
      "        61           0.1230          -0.0001           57.57s\n",
      "        62           0.1189          -0.0000           55.95s\n",
      "        63           0.1154          -0.0001           54.44s\n",
      "        64           0.1212          -0.0001           52.85s\n",
      "        65           0.1213          -0.0002           51.33s\n",
      "        66           0.1146          -0.0001           49.76s\n",
      "        67           0.1119          -0.0002           48.18s\n",
      "        68           0.1169          -0.0000           46.71s\n",
      "        69           0.1170          -0.0001           45.28s\n",
      "        70           0.1189          -0.0001           43.75s\n",
      "        71           0.1162          -0.0001           42.22s\n",
      "        72           0.1166          -0.0001           40.72s\n",
      "        73           0.1194          -0.0001           39.20s\n",
      "        74           0.1200          -0.0001           37.70s\n",
      "        75           0.1186           0.0000           36.22s\n",
      "        76           0.1217          -0.0001           34.76s\n",
      "        77           0.1158          -0.0001           33.29s\n",
      "        78           0.1146          -0.0001           31.79s\n",
      "        79           0.1143          -0.0001           30.28s\n",
      "        80           0.1179          -0.0000           28.79s\n",
      "        81           0.1163          -0.0001           27.46s\n",
      "        82           0.1214          -0.0001           26.13s\n",
      "        83           0.1163           0.0000           24.66s\n",
      "        84           0.1192          -0.0001           23.17s\n",
      "        85           0.1156          -0.0001           21.61s\n",
      "        86           0.1195          -0.0001           20.03s\n",
      "        87           0.1211          -0.0001           18.52s\n",
      "        88           0.1135          -0.0001           17.01s\n",
      "        89           0.1171          -0.0002           15.50s\n",
      "        90           0.1162          -0.0001           14.01s\n",
      "        91           0.1184          -0.0001           12.54s\n",
      "        92           0.1136          -0.0001           11.08s\n",
      "        93           0.1152          -0.0001            9.63s\n",
      "        94           0.1127          -0.0001            8.21s\n",
      "        95           0.1172          -0.0001            6.81s\n",
      "        96           0.1159          -0.0001            5.42s\n",
      "        97           0.1129          -0.0001            4.04s\n",
      "        98           0.1125          -0.0001            2.68s\n",
      "        99           0.1146          -0.0000            1.34s\n",
      "       100           0.1163          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 2.3min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1330           0.0010            1.35m\n",
      "         2           0.1307           0.0008            1.30m\n",
      "         3           0.1314           0.0006            1.29m\n",
      "         4           0.1299           0.0006            1.32m\n",
      "         5           0.1280           0.0004            1.62m\n",
      "         6           0.1299           0.0002            1.53m\n",
      "         7           0.1261           0.0003            1.54m\n",
      "         8           0.1306          -0.0002            1.63m\n",
      "         9           0.1285           0.0000            1.59m\n",
      "        10           0.1236           0.0001            1.52m\n",
      "        11           0.1338          -0.0002            1.48m\n",
      "        12           0.1261           0.0001            1.44m\n",
      "        13           0.1320           0.0001            1.38m\n",
      "        14           0.1193          -0.0001            1.33m\n",
      "        15           0.1276          -0.0000            1.28m\n",
      "        16           0.1274          -0.0001            1.23m\n",
      "        17           0.1226          -0.0001            1.21m\n",
      "        18           0.1243          -0.0001            1.18m\n",
      "        19           0.1241          -0.0001            1.14m\n",
      "        20           0.1252          -0.0000            1.12m\n",
      "        21           0.1289           0.0000            1.09m\n",
      "        22           0.1256          -0.0001            1.06m\n",
      "        23           0.1292          -0.0000            1.03m\n",
      "        24           0.1235          -0.0001            1.00m\n",
      "        25           0.1206          -0.0025           58.47s\n",
      "        26           0.1255           0.0000           57.13s\n",
      "        27           0.1257          -0.0001           55.61s\n",
      "        28           0.1242           0.0000           54.22s\n",
      "        29           0.1209          -0.0001           53.05s\n",
      "        30           0.1194          -0.0025           51.70s\n",
      "        31           0.1173          -0.0001           50.44s\n",
      "        32           0.1265           0.0001           49.40s\n",
      "        33           0.1269          -0.0001           48.21s\n",
      "        34           0.1215           0.0001           47.10s\n",
      "        35           0.1225          -0.0001           46.15s\n",
      "        36           0.1237          -0.0000           45.05s\n",
      "        37           0.1230          -0.0000           44.07s\n",
      "        38           0.1216          -0.0001           43.18s\n",
      "        39           0.1259          -0.0001           42.16s\n",
      "        40           0.1204          -0.0000           41.19s\n",
      "        41           0.1220          -0.0001           40.48s\n",
      "        42           0.1215           0.0000           39.48s\n",
      "        43           0.1271          -0.0001           38.64s\n",
      "        44           0.1220           0.0000           37.82s\n",
      "        45           0.1233          -0.0001           36.92s\n",
      "        46           0.1260          -0.0001           36.08s\n",
      "        47           0.1237          -0.0001           35.29s\n",
      "        48           0.1231          -0.0001           34.44s\n",
      "        49           0.1229          -0.0000           33.67s\n",
      "        50           0.1217          -0.0001           32.81s\n",
      "        51           0.1208          -0.0001           31.98s\n",
      "        52           0.1218          -0.0001           31.19s\n",
      "        53           0.1211          -0.0003           30.50s\n",
      "        54           0.1240          -0.0001           29.72s\n",
      "        55           0.1239          -0.0001           28.98s\n",
      "        56           0.1204          -0.0000           28.27s\n",
      "        57           0.1248          -0.0001           27.50s\n",
      "        58           0.1275          -0.0001           26.77s\n",
      "        59           0.1183          -0.0001           26.08s\n",
      "        60           0.1190          -0.0001           25.29s\n",
      "        61           0.1214          -0.0000           24.52s\n",
      "        62           0.1192          -0.0002           23.87s\n",
      "        63           0.1196          -0.0001           23.17s\n",
      "        64           0.1160          -0.0001           22.41s\n",
      "        65           0.1188          -0.0001           21.78s\n",
      "        66           0.1176          -0.0001           21.12s\n",
      "        67           0.1170          -0.0000           20.44s\n",
      "        68           0.1196          -0.0001           19.82s\n",
      "        69           0.1156          -0.0002           19.14s\n",
      "        70           0.1133          -0.0001           18.49s\n",
      "        71           0.1208          -0.0001           17.86s\n",
      "        72           0.1175          -0.0002           17.22s\n",
      "        73           0.1196          -0.0001           16.55s\n",
      "        74           0.1214          -0.0001           15.93s\n",
      "        75           0.1120          -0.0001           15.29s\n",
      "        76           0.1229          -0.0002           14.66s\n",
      "        77           0.1166           0.0000           14.05s\n",
      "        78           0.1165          -0.0001           13.42s\n",
      "        79           0.1172          -0.0001           12.80s\n",
      "        80           0.1177          -0.0001           12.19s\n",
      "        81           0.1195          -0.0002           11.55s\n",
      "        82           0.1161          -0.0002           10.93s\n",
      "        83           0.1226          -0.0001           10.32s\n",
      "        84           0.1202          -0.0001            9.69s\n",
      "        85           0.1171          -0.0001            9.08s\n",
      "        86           0.1169           0.0000            8.47s\n",
      "        87           0.1154          -0.0001            7.85s\n",
      "        88           0.1215          -0.0001            7.24s\n",
      "        89           0.1141          -0.0001            6.65s\n",
      "        90           0.1198          -0.0000            6.04s\n",
      "        91           0.1192          -0.0001            5.43s\n",
      "        92           0.1130          -0.0001            4.83s\n",
      "        93           0.1152          -0.0002            4.22s\n",
      "        94           0.1155          -0.0002            3.61s\n",
      "        95           0.1139          -0.0001            3.01s\n",
      "        96           0.1176          -0.0000            2.40s\n",
      "        97           0.1137          -0.0000            1.80s\n",
      "        98           0.1146          -0.0001            1.20s\n",
      "        99           0.1099          -0.0001            0.60s\n",
      "       100           0.1120          -0.0001            0.00s\n",
      "[CV] END classifier__max_depth=2, classifier__min_samples_split=2, classifier__n_estimators=100, classifier__subsample=0.75; total time= 1.0min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.1317           0.0011            1.25m\n",
      "         2           0.1330           0.0006            1.19m\n",
      "         3           0.1307           0.0005            1.27m\n",
      "         4           0.1322           0.0004            1.26m\n",
      "         5           0.1248          -0.0005            1.23m\n",
      "         6           0.1314           0.0004            1.20m\n",
      "         7           0.1278           0.0002            1.14m\n",
      "         8           0.1258           0.0001            1.15m\n",
      "         9           0.1284          -0.0000            1.11m\n",
      "        10           0.1303           0.0003            1.09m\n",
      "        11           0.1304           0.0000            1.07m\n",
      "        12           0.1272           0.0001            1.04m\n",
      "        13           0.1270           0.0002            1.04m\n",
      "        14           0.1290           0.0000            1.02m\n",
      "        15           0.1260          -0.0000            1.00m\n",
      "        16           0.1249          -0.0000           59.42s\n",
      "        17           0.1244           0.0000           58.05s\n",
      "        18           0.1229          -0.0000           57.31s\n",
      "        19           0.1243          -0.0001           56.39s\n",
      "        20           0.1253          -0.0001           55.40s\n",
      "        21           0.1273           0.0001           54.81s\n",
      "        22           0.1256          -0.0000           53.71s\n",
      "        23           0.1254          -0.0000           52.81s\n",
      "        24           0.1273           0.0001           52.14s\n",
      "        25           0.1268          -0.0001           51.18s\n",
      "        26           0.1259           0.0001           50.70s\n",
      "        27           0.1247          -0.0001           49.82s\n",
      "        28           0.1285          -0.0001           49.00s\n",
      "        29           0.1294          -0.0001           48.38s\n",
      "        30           0.1248          -0.0001           47.40s\n",
      "        31           0.1244          -0.0001           46.83s\n",
      "        32           0.1272          -0.0001           46.09s\n",
      "        33           0.1248          -0.0001           45.33s\n",
      "        34           0.1277          -0.0001           44.78s\n",
      "        35           0.1274          -0.0000           43.93s\n",
      "        36           0.1189          -0.0001           43.32s\n",
      "        37           0.1183          -0.0001           42.54s\n",
      "        38           0.1256           0.0000           41.74s\n",
      "        39           0.1222          -0.0001           41.18s\n",
      "        40           0.1196          -0.0001           40.41s\n",
      "        41           0.1255           0.0000           39.75s\n",
      "        42           0.1231          -0.0001           39.03s\n",
      "        43           0.1237          -0.0001           38.28s\n",
      "        44           0.1220          -0.0001           37.73s\n",
      "        45           0.1239          -0.0001           36.95s\n",
      "        46           0.1225          -0.0001           36.33s\n",
      "        47           0.1215          -0.0001           35.65s\n",
      "        48           0.1220          -0.0001           34.90s\n",
      "        49           0.1225          -0.0000           34.32s\n",
      "        50           0.1238          -0.0001           33.56s\n",
      "        51           0.1227          -0.0002           32.90s\n",
      "        52           0.1225          -0.0001           32.67s\n",
      "        53           0.1204          -0.0001           32.20s\n",
      "        54           0.1203          -0.0000           31.50s\n",
      "        55           0.1248          -0.0000           30.76s\n",
      "        56           0.1248          -0.0001           30.20s\n",
      "        57           0.1176          -0.0000           29.53s\n",
      "        58           0.1209          -0.0001           29.01s\n",
      "        59           0.1183          -0.0001           28.25s\n",
      "        60           0.1213          -0.0000           27.56s\n",
      "        61           0.1159          -0.0004           26.85s\n",
      "        62           0.1191          -0.0001           26.10s\n",
      "        63           0.1223          -0.0001           25.47s\n",
      "        64           0.1198          -0.0000           24.72s\n",
      "        65           0.1216          -0.0001           24.07s\n",
      "        66           0.1190          -0.0001           23.37s\n",
      "        67           0.1213          -0.0000           22.65s\n",
      "        68           0.1168          -0.0001           22.00s\n",
      "        69           0.1206          -0.0001           21.26s\n",
      "        70           0.1205          -0.0001           20.58s\n",
      "        71           0.1200          -0.0000           19.87s\n",
      "        72           0.1204          -0.0001           19.18s\n",
      "        73           0.1196          -0.0001           18.50s\n",
      "        74           0.1197          -0.0001           17.80s\n",
      "        75           0.1138          -0.0001           17.17s\n",
      "        76           0.1161          -0.0001           16.46s\n",
      "        77           0.1208           0.0000           15.76s\n",
      "        78           0.1202           0.0000           15.09s\n",
      "        79           0.1236           0.0000           14.38s\n",
      "        80           0.1230          -0.0001           13.71s\n",
      "        81           0.1170          -0.0001           13.01s\n",
      "        82           0.1182          -0.0001           12.31s\n",
      "        83           0.1184          -0.0001           11.63s\n",
      "        84           0.1210          -0.0001           10.93s\n",
      "        85           0.1170          -0.0001           10.25s\n",
      "        86           0.1159          -0.0001            9.56s\n",
      "        87           0.1193          -0.0002            8.86s\n",
      "        88           0.1207          -0.0000            8.19s\n",
      "        89           0.1167          -0.0001            7.50s\n",
      "        90           0.1176          -0.0001            6.81s\n",
      "        91           0.1162          -0.0000            6.14s\n",
      "        92           0.1182          -0.0001            5.45s\n",
      "        93           0.1169          -0.0001            4.77s\n",
      "        94           0.1192          -0.0000            4.09s\n",
      "        95           0.1181          -0.0001            3.40s\n",
      "        96           0.1143          -0.0001            2.73s\n",
      "        97           0.1168          -0.0000            2.04s\n",
      "        98           0.1174          -0.0000            1.36s\n",
      "        99           0.1166          -0.0001            0.68s\n",
      "       100           0.1179          -0.0004            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__subsample': 0.75,\n",
       " 'classifier__n_estimators': 100,\n",
       " 'classifier__min_samples_split': 2,\n",
       " 'classifier__max_depth': 2}"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = randSCV.fit(X,y)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the searched best parameters for predciting\n",
    "best_search = search.best_params_\n",
    "best_predict = search.predict_proba(X)[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8049643685575002"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y,best_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "preds = best_predict\n",
    "fpr, tpr, threshold = metrics.roc_curve(y, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0067824 , 0.00733788, 0.        , 0.        , 0.00182872,\n",
       "       0.00190064, 0.00484241, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00855003, 0.        , 0.        , 0.00205215, 0.        ,\n",
       "       0.00566793, 0.0081773 , 0.        , 0.00168187, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00219241,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00218014, 0.        , 0.        ,\n",
       "       0.01846545, 0.        , 0.00709783, 0.00196148, 0.00897937,\n",
       "       0.01223393, 0.04607058, 0.00178384, 0.00771862, 0.02805513,\n",
       "       0.        , 0.        , 0.0043397 , 0.00251078, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00490504, 0.01229844, 0.        , 0.00391884, 0.        ,\n",
       "       0.        , 0.        , 0.00192981, 0.        , 0.        ,\n",
       "       0.        , 0.00141535, 0.        , 0.00178158, 0.        ,\n",
       "       0.        , 0.01633841, 0.        , 0.        , 0.        ,\n",
       "       0.03262091, 0.01215175, 0.        , 0.00522349, 0.        ,\n",
       "       0.        , 0.00216565, 0.16673227, 0.        , 0.        ,\n",
       "       0.        , 0.00181013, 0.        , 0.00121731, 0.        ,\n",
       "       0.00165472, 0.00201696, 0.        , 0.        , 0.        ,\n",
       "       0.00456541, 0.00143858, 0.01047689, 0.        , 0.        ,\n",
       "       0.00263435, 0.        , 0.        , 0.00315178, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02200507, 0.        , 0.        , 0.        , 0.0023744 ,\n",
       "       0.06775371, 0.02081749, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0079738 , 0.00151049,\n",
       "       0.00577893, 0.        , 0.00142227, 0.        , 0.01066794,\n",
       "       0.        , 0.        , 0.00118614, 0.00160169, 0.        ,\n",
       "       0.01616853, 0.00142933, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00161614, 0.        , 0.        , 0.00169954,\n",
       "       0.00385104, 0.00407847, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01580486, 0.        , 0.00845885, 0.00152813,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00145143,\n",
       "       0.        , 0.        , 0.        , 0.00642491, 0.        ,\n",
       "       0.0052372 , 0.        , 0.00290626, 0.        , 0.        ,\n",
       "       0.        , 0.0015709 , 0.00175582, 0.00182783, 0.        ,\n",
       "       0.00206524, 0.        , 0.        , 0.00372432, 0.        ,\n",
       "       0.00141023, 0.01271536, 0.00247602, 0.00242359, 0.00386767,\n",
       "       0.00147226, 0.00140173, 0.        , 0.        , 0.        ,\n",
       "       0.00151496, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01555649, 0.        , 0.00166992, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00537942,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00213411, 0.001533  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00145818, 0.        , 0.00161701, 0.        ,\n",
       "       0.        , 0.00154013, 0.00363974, 0.        , 0.01230954,\n",
       "       0.00486895, 0.00241625, 0.        , 0.        , 0.        ,\n",
       "       0.00243003, 0.00160818, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00908071, 0.        , 0.00819378, 0.        ,\n",
       "       0.        , 0.00158178, 0.00811859, 0.        , 0.00127797,\n",
       "       0.        , 0.        , 0.00163594, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00248902, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00503675, 0.00476122,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00357038, 0.        , 0.0071348 , 0.        , 0.        ,\n",
       "       0.        , 0.00153474, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00145008, 0.        , 0.01517323,\n",
       "       0.        , 0.        , 0.00163742, 0.        , 0.        ,\n",
       "       0.        , 0.00131596, 0.00168903, 0.        , 0.        ,\n",
       "       0.        , 0.00394309, 0.        , 0.00298305, 0.00136467,\n",
       "       0.00514553, 0.0028863 , 0.        , 0.        , 0.00176912,\n",
       "       0.        , 0.        , 0.        , 0.00760132, 0.00157769,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00182341, 0.01047351, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00169256, 0.00862156, 0.00213001, 0.00160189, 0.        ,\n",
       "       0.        , 0.0155033 , 0.        , 0.00142077, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00368356,\n",
       "       0.        , 0.        , 0.        , 0.00265439, 0.        ,\n",
       "       0.        , 0.00110358, 0.00243629, 0.00169914, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02790189,\n",
       "       0.        , 0.00413061, 0.        , 0.        , 0.00354578,\n",
       "       0.        , 0.        , 0.        , 0.00430478, 0.00229911,\n",
       "       0.        , 0.00702998])"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_[1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = search.best_estimator_[1].feature_importances_\n",
    "pd.Series(feature_importances, index=final_cols).sort_values()[-10:].plot(kind='barh', figsize=(7,10))\n",
    "plt.xlabel('feature importance')\n",
    "plt.title('Feature importance by clusters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e13e641850>"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ANZ_KINDER distribution in relevant clusters\n",
    "x1=customers_cleaned.iloc[customers_cleaned[customers_cleaned['Cluster'] == 1].index]['ANZ_KINDER']\n",
    "x2=customers_cleaned.iloc[customers_cleaned[customers_cleaned['Cluster'] == 3].index]['ANZ_KINDER']\n",
    "x3=customers_cleaned.iloc[customers_cleaned[customers_cleaned['Cluster'] == 4].index]['ANZ_KINDER']\n",
    "\n",
    "# x1=customers_cleaned.iloc[customers_cleaned.index]['ANZ_KINDER']\n",
    "# x2=customers_cleaned.iloc[customers_cleaned.index]['ANZ_KINDER']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "width = 0.35 \n",
    "\n",
    "p1 = plt.hist(x1, width=width, label='Cluster 1')\n",
    "p2 = plt.hist(x2, width=width, label='Cluster 3')\n",
    "p3 = plt.hist(x2, width=width, label='Cluster 4')\n",
    "\n",
    "plt.title('Distribution of ANZ_KINDER among interested clusters')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Attribute value')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "+ https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "+ https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "+ https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "+ https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "+ https://stackoverflow.com/questions/28501072/how-to-check-which-version-of-nltk-scikit-learn-installed\n",
    "+ https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py\n",
    "+ https://www.anyscale.com/blog/how-to-speed-up-scikit-learn-model-training\n",
    "+ https://stackoverflow.com/questions/54646709/sklearn-pipeline-get-feature-names-after-onehotencode-in-columntransformer\n",
    "+ https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "47c0fc4e0d038ae915347f3e0652d8d3ec9061f5399eb83a3b36288bc2a7b85d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
